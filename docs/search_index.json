[["index.html", "STAT 101 [WSMiP UŁ] Treść wykładu z przedmiotu Statystyka (Statystyka i demografia) [WERSJA ROBOCZA: Nie kopiuj, nie cytuj ani nie rozpowszechniaj bez zgody.] Opis kursu", " STAT 101 [WSMiP UŁ] Treść wykładu z przedmiotu Statystyka (Statystyka i demografia) [WERSJA ROBOCZA: Nie kopiuj, nie cytuj ani nie rozpowszechniaj bez zgody.] Michał Pierzgalski 2021-01-10 Opis kursu Proszę zapoznać się z syllabusem kursu: STAT101 "],["o-mnie.html", "O mnie", " O mnie Jestem adiunktem na Wydziale Studiów Międzynarodowych i Politologicznych Uniwersytetu Łódzkiego. Moje badania obejmują tematykę systemów wyborczych i zachowań wyborczych. Interesuję się również metodologią badań i ilościową analizą danych. "],["kontakt.html", "Kontakt", " Kontakt Email: michal.pierzgalski@uni.lodz.pl Strona domowa: https://pierzgal.github.io/michalpierzgalski/ Dyżur dla studentów (2020/2021) Za pośrednictwem aplikacji MS Teams, po uprzednim ustaleniu terminu w korespondencji elektronicznej (tylko email w domenie @uni.lodz.pl). WAŻNE! Studentów proszę o kontakt tylko za pośrednictwem aplikacji MS Teams lub poczty elektronicznej w domenie @uni.lodz.pl oraz @edu.uni.lodz.pl. W tytule emaila proszę podać nazwę kursu, grupę, kierunek studiów, itp. Studenci w kontakcie z pracownikami Uniwersytetu Łódzkiego mają obowiązek posługiwania się adresami w domenach UŁ i tylko za pomocą tych adresów email może być prowadzona korespondencja na linii student - nauczyciel. Na maile od studentów odpisuję tylko w piątki i poniedziałki lub podczas moich dyżurów dydaktycznych. "],["uwagi.html", "Uwagi", " Uwagi "],["uwaga-dotycząca-kalkulatorów-1.html", "UWAGA dotycząca kalkulatorów (1)", " UWAGA dotycząca kalkulatorów (1) Na zajęcia/egzamin warto nabyć prosty kalkulator naukowy (np. Casio FX-82ES Plus, ok. 45 PLN), który posiada, przede wszystkim, możliwość podnoszenia wartości do dowolnej potęgi \\(x^n\\), nawiasy \\((...)\\), symbol silni \\(n! = 1 \\times 2 \\times ... \\times (n - 1) \\times n\\), ułamki zwykłe \\(\\frac{[.]}{[.]}\\) oraz funckję zamiany ułamka zwykłego na dziesiętny oznaczoną zwykle \\([S \\rightarrow D]\\). Te funkcje przyśpieszają operacje na bardzo dużych/małych liczbach i ułatwiają korzystanie z wzorów statystycznych. "],["uwaga-dotycząca-kalkulatorów-2.html", "UWAGA dotycząca kalkulatorów (2)", " UWAGA dotycząca kalkulatorów (2) Domyślnie, kalkulator naukowy podaje bardzo małe/duże wartości w tzw. notacji naukowej: np. gdy prawdopodobieństwo zdarzenia \\(A = 0.0000126\\), kalkulator wyświetli \\(1.26 \\times 10^{-5}\\). Zauważ, że \\(1.26 \\times 10^{0} = 1.26\\) oraz \\(1.26 \\times 10^5 = 126000\\) "],["uwaga-dotycząca-zapisu-ułamków-dziesiętnych.html", "UWAGA dotycząca zapisu ułamków dziesiętnych", " UWAGA dotycząca zapisu ułamków dziesiętnych W materiałach elektronicznych udostępnianych studentom używam jako separatora dziesiętnego kropki (zamiast przecinka), np. \\(12.5 = 12\\frac{1}{2}\\). "],["wykład-1-wprowadzenie.html", "1 Wykład 1. Wprowadzenie ", " 1 Wykład 1. Wprowadzenie "],["co-to-jest-statystyka.html", "1.1 Co to jest statystyka?", " 1.1 Co to jest statystyka? Statystyka to dyscyplina naukowa, której przedmiotem zainteresowania są zagadnienia, organizacji, analizy, interpretacji i prezentacji danych. "],["motywacja-dwa-powody-dla-których-warto-uczyć-się-statystyki-i-metod-analizy-danych.html", "1.2 Motywacja - dwa powody, dla których warto uczyć się statystyki i metod analizy danych?", " 1.2 Motywacja - dwa powody, dla których warto uczyć się statystyki i metod analizy danych? W badaniach społecznych (w politologii, socjologii, psychologii lub ekonomii) stosuje się metody statystyczne do szukania odpowiedzi na pytania badawcze lub w testowaniu hipotez badawczych. Statystyka jest podstawowym elementem warsztatu studiujących nauki społeczne. Statystyka i powiązane z nią dyscypliny takie jak Data Science (nauka o danych: statystyka + informatyka) lub uczenie maszynowe (Machine Learning) pozwalają nam lepiej rozumieć nowoczesne technologie (np. computational photography), które nie tylko ułatwiają nam życie, ale też wywierają wpływ na życie społeczne i polityczne (np. tzw. mikrotargeting1 (microtargeting), który polega na dobieraniu przez algorytmy komputerowe mediów społecznościowych indywidualnego przekazu dla pojedynczych wyborców.). Zob. np. Mikrotargetowanie i datakracja: https://wszystkoconajwazniejsze.pl/jan-sliwa-mikrotargetowanie-i-datakracja/↩︎ "],["przypomnienie-niektórych-pojęć-z-matematyki.html", "1.3 Przypomnienie niektórych pojęć z matematyki", " 1.3 Przypomnienie niektórych pojęć z matematyki 1.3.1 Przegląd elementów algebry 1.3.1.1 Równoważność Istnieją dwa różne typy równości: ** równania ** i ** tożsamości **. Równość \\(=\\) to nie to samo, co tożsamość \\(\\equiv\\). Symbol \\(\\equiv\\) pierwotnie oznaczał „jest identycznie równy\". Tożsamość to rodzaj równości, która jest zawsze prawdziwa, np .: \\((a+b)^2 \\equiv a^2+2ab+b^2.\\) 1.3.1.2 Różnice - symbol Delta Grecka litera \\(\\Delta\\) (duża delta) jest symbolem używanym do oznaczenia różnicy w mierzonej wielkości, zwykle w dwóch różnych momentach. 1.3.1.3 Sumy - symbol Sigma Użytecznym skrótem oznaczającym sumę jest grecka litera \\(\\Sigma\\) (duża sigma). Załóżmy, że chcemy dodać zestaw pięciu liczb reprezentowanych przez \\(x1, x2, x3, x4, x5\\). W notacji skróconej zapisalibyśmy sumę jako \\(x1 + x2 + x3 + x4 + x5 = \\sum_{i=1}^{5} x_i\\) gdzie indeks dolny i przy x reprezentuje dowolną liczbę w zestawie. Na przykład, jeśli w systemie jest pięć mas, \\(m1, m2, m3, m4, m5\\), całkowitą masę systemu \\(M = m1 + m2 + m3 + m4 + m5\\) można wyrazić jako \\(M = \\sum_{i=1}^{5} m_i\\) 1.3.1.4 Wartość bezwzględna Znak wartości bezwzględnej x jest zawsze dodatni, niezależnie od znaku x. Na przykład, jeśli x = -5, to | x | = 5; jeśli x = 8, to | x | = 8. 1.3.1.5 Podstawowe operacje algebraiczne Kiedy wykonywane są operacje algebraiczne, obowiązują prawa arytmetyki. Symbole, takie jak x, y i z, są zwykle używane do reprezentowania nieokreślonych wielkości, zwanych niewiadomymi (lub zmiennymi). Rozważmy równanie \\(8x = 32\\) Jeśli chcemy obliczyć x, możemy podzielić (lub pomnożyć) każdą stronę równanie przez ten sam czynnik bez niszczenia równości. W tym przypadku, jeśli podzielimy obie strony przez 8, otrzymamy \\(\\frac{8x}{8} = \\frac{32}{8}\\) \\(x = 4\\) Ponadto, \\(x + 2 = 8\\) W tego typu wyrażeniach możemy dodać lub odjąć tę samą ilość z każdej strony. Jeśli odejmiemy 2 z każdej strony, otrzymamy \\(x + 2 - 2 = 8 - 2\\) \\(x = 6\\) I wreszcie równanie, \\(\\frac{x}{5} = 9\\) Dzieląc obie strony przez 5, \\((\\frac{x}{5}) \\times 5 = 9 \\times 5\\) \\(x = 45\\) We wszystkich przypadkach, jakakolwiek operacja jest wykonywana po lewej stronie równość należy ją również wykonać po prawej stronie. 1.3.1.6 Kilka przydatnych reguł arytmetycznych Poniższe zasady dotyczące mnożenia, dzielenia, dodawania i odejmowania należy przypomnieć ułamki, gdzie a, b, c i d to cztery liczby: Rule Example Multiplying \\((\\frac{a}{b})(\\frac{c}{d}) = \\frac{ac}{bd}\\) Dividing \\((\\frac{a/b}{c/d}) = \\frac{ad}{bc}\\) Adding \\((\\frac{a}{b}) \\pm (\\frac{c}{d}) = \\frac{ad \\pm bc}{bd}\\) 1.3.1.7 Potęgi Mamy następujące reguły: \\(x^nx^m = x^{n+m}\\) \\(\\frac{x^n}{x^m} = x^{n-m}\\) \\(x^{\\frac{1}{n}} = \\sqrt[n]{x}\\) \\((x^n)^m = x^{nm}\\) 1.3.1.8 Logarytmy Załóżmy, że wielkość x jest wyrażona jako potęga pewnej wielkości a: \\(x = a^y\\) Liczba a nazywana jest podstawą. Logarytm x w odniesieniu do podstawy a jest równy wykładnikowi, do którego należy podnieść podstawę, aby spełnić wyrażenie \\(x = a^y\\): \\(y = \\log_a x\\) W praktyce dwie najczęściej używane bazy to podstawa 10, nazywana wspólną podstawą logarytmu, oraz podstawa \\(e = 2,718 282\\), nazywana stałą Eulera lub podstawą logarytmu naturalnego. Dla dowolnej podstawy: \\(\\log{(ab)} = \\log a + \\log b\\) \\(\\log{a/b} = \\log a + \\log b\\) \\(\\log{a^n} = n \\log a\\) Ponadto, \\(\\ln e\\) \\(\\ln e^a = a\\) \\(\\ln(1/a) = -\\ln a\\) 1.3.1.9 Wyciąganie wspólnego czynnika przed nawias (Factoring) Oto kilka przydatnych wzorów do faktoryzacji równania: \\(ax + ay + az = a(x + y + z)\\) \\(a^2 + 2ab + b^2 = (a + b)^2\\) \\(a^2 + b^2 = (a + b)(a - b)\\) 1.3.1.10 Równania liniowe Ogólna postać równania liniowego \\(y = mx + b\\) gdzie m i b są stałymi. To równanie jest określane jako liniowe, ponieważ wykres y względem x jest linią prostą. Stała b, zwana punktem przecięcia z osią y, reprezentuje wartość y, przy której prosta przecina oś y. Stała m jest równa nachyleniu prostej. Jeżeli dowolne dwa punkty na prostej są określone współrzędnymi (x1, y1) i (x2, y2), to nachylenie prostej można wyrazić jako \\(Nachylenie = \\frac{y_2 - y_1}{x_2 - x_1} = \\frac{\\Delta{y}}{\\Delta{x}}\\) Zauważ, że m i b mogą mieć wartości dodatnie lub ujemne. Jeśli \\(m &gt; 0\\), linia prosta ma dodatnie nachylenie. Jeśli \\(m &lt; 0\\), prosta ma ujemne nachylenie. Układy równań Rozważmy równanie \\(3x + 5y = 15\\), które ma dwie niewiadome, x i y. Takie równanie nie ma unikalnego rozwiązania. Na przykład, \\((x = 0, y = 3)\\), \\((x = 5, y = 0)\\), i (\\(x = 2, y = \\frac{9}{5}\\)) są wszystkimi parami rozwiązań tego równania. Jeśli problem ma dwie niewiadome, unikalne rozwiązanie jest możliwe tylko wtedy, gdy mamy dwa równania. Ogólnie rzecz biorąc, jeśli problem ma n niewiadomych, jego rozwiązanie wymaga n równań. Aby rozwiązać dwa równoczesne równania z udziałem dwóch niewiadomych, x i y, rozwiązujemy jedno z równań dla x w odniesieniu do y i podstawiamy to wyrażenie do drugiego równania. 1.3.2 Funkcje Funkcja ze zbioru A do innego zbioru B to przypisanie jakiegoś elementu B do każdego elementu w A. Funkcja to reguła, która przypisuje każdemu wejściu (input) dokładnie jedno wyjście (output). Nazywamy wyjście obrazem wejścia. Zbiór wszystkich danych wejściowych dla funkcji nosi nazwę dziedziny. Zbiór wszystkich dopuszczalnych danych wyjściowych nazywany jest przeciwdziedziną. W matematyce funkcja jest relacją binarną między dwoma zbiorami, która wiąże każdy element pierwszego zbioru z dokładnie jednym elementem drugiego zbioru. Figure 1.1. Function2 Figure 1.2. Function3 Model matematyczny to abstrakcyjna koncepcja, za pomocą której używamy języka matematycznego do opisania zjawisk w otaczającym nas świecie. Modele opisują nasze przekonania na temat funkcjonowania świata. W modelowaniu matematycznym przekładamy te przekonania na język matematyki. Funkcja może służyć jako prosty rodzaj modelu matematycznego. Pamiętaj, że funkcja to po prostu reguła f, która wyraża zależność jednej zmiennej wielkości y od innej zmiennej wielkości x. Możemy myśleć o regule (podanej jako wykres, formuła lub tabela wartości) jako reprezentacji jakiegoś związku przyczynowo-skutkowego - jeśli x, to y - między dwiema zmiennymi wielkościami. W przypadku modelu matematycznego często szukamy wzoru algebraicznego, który dokładnie oddaje obserwowane zachowanie i może być użyty do prognozowania zachowania, którego jeszcze nie zaobserwowano. 1.3.3 Trzy podstawowe pojęcia rachunku różniczkowego Granica funkcji; Pochodna; Całka. 1.3.4 Granica funkcji Granica (limes) funkcji - nieformalnie, wielkość do której wartości danej funkcji zbliżają się nieograniczenie dla argumentów dostatecznie bliskich wybranemu punktowi. Dla funkcji \\(f(x)\\) napiszemy: \\[\\lim_{x \\rightarrow c}f(x)=L\\] Powyższy zapis oznacza, że dla ciągu argumentów funkcji \\(f(x)\\) dążącego do wartości \\(c\\), liczba \\(L\\) jest granicą funkcji \\(f(x)\\). \\[\\lim_{x \\rightarrow \\infty}\\frac{1}{x}=0\\] \\[\\lim_{x \\rightarrow 0}\\frac{1}{x}=\\infty\\] In mathematics, a limit is the value that a function (or sequence) “approaches” as the input (or index) “approaches” some value. Limits are essential to calculus and mathematical analysis, and are used to define e.g. derivatives, and integrals. In formulas, a limit of a function is usually written as \\[\\lim_{x \\to c}f(x)=L\\] and is read as “the limit of f of x as x approaches c equals L”. The fact that a function f approaches the limit L as x approaches c is usually denoted by a right arrow \\(\\to\\), as in: \\[f(x)\\to L{\\text{ as }}x\\to c\\] which reads \\(f(x)\\) tends to \\(L\\) as \\(x\\) tends to \\(c\\). Figure 1.3. Limits4 1.3.5 Pochodna funkcji First, a function must be specified that relates one variable to another (e.g., a coordinate as a function of time). Suppose one of the variables is called y (the dependent variable), and the other x (the independent variable). We might have a function relationship such as \\(y(x) = ax^2 + bx + c\\) If a, b, and c are specified constants, y can be calculated for any value of x. We usually deal with continuous functions, that is, those for which y varies “smoothly” with x. The derivative of y with respect to x is defined as the limit as \\(\\Delta x\\) approaches zero of the slopes of chords drawn between two points on the y versus x curve. Mathematically, we write this definition as \\[\\frac{dy}{dx} = \\lim_{\\Delta x \\to\\ 0} \\frac{\\Delta y}{\\Delta x} = \\lim_{\\Delta x \\to\\ 0} \\frac{y(x + \\Delta x) - y(x)}{\\Delta x}\\] where \\(\\Delta y = y_2 - y_1\\) and \\(\\Delta x = x_2 - x_1\\). Note that \\(dy/dx\\) does not mean \\(dy\\) divided by \\(dx\\), but rather is simply a notation of the limiting process of the derivative (differentiation operator). A useful expression to remember when \\(y = ax^n\\), where a is a constant and n is any positive or negative number (integer or fraction), is \\(\\frac{dy}{dx} = nax^{n-1}\\) Figure 1.4. Derivative - visual representation5 1.3.6 Całka funkcji We think of integration as the inverse of differentiation. As an example, consider the expression 1.1 \\(f(x) = \\frac{dy}{dx} = 3ax^2 + b\\) which was the result of differentiating the function 1.2 \\(y(x) = ax^3 = bx + c\\) We can write equation 1.1 as \\(dy = f(x)dx = (3ax^2 + b)dx\\) and obtain \\(y(x)\\) by “summing” over all values of x. Mathematically, we write this inverse operation as \\[y(x) = \\int f(x) dx\\] \\[ y(x) = \\int (3az^2 + b)dx = ax^3 + bx + c\\] where c is a constant of the integration. This type of integral is called an indefinite integral because its value depends on the choice of c. 1.3.7 Całka jako pole - intuicyjne wyjaśnienie For a general continuous function f(x), the integral can be described as the area under the curve bounded by f(x) and the x axis, between two specified values of x, say, \\(x1\\) and \\(x2\\), as in the Figure 1.5. The area of the blue element in Figure 1.5 is approximately \\(f(x_i) \\Delta x_i\\). If we sum all these area elements between \\(x1\\) and \\(x2\\) and take the limit of this sum as \\(\\Delta x_i \\to 0\\), we obtain the true area under the curve bounded by f(x) and the x axis, between the limits \\(x1\\) and \\(x2\\): \\[Area = \\lim_{\\Delta x_i \\to\\ 0} \\sum_i f(x_i)\\Delta x_i = \\int_{x_1}^{x_2} f(x)dx\\] Integrals of this type are called definite integrals. Figure 1.5. Definite integral as an area under a curve6 Figure 1.6. Definite integral as an area under a curve7 Figure 1.7. Definite integral as an area under a curve8 1.3.7.1 Summary Figure 1.8. Summary of basic calulus concepts9 Retrieved from: Sets and Functions. https://mathigon.org/course/sets-and-functions/function-properties↩︎ Retrieved from: Loup Vaillant. http://loup-vaillant.fr/tutorials/from-imperative-to-functional↩︎ Retrieved from: Math24. https://www.math24.net/definition-limit-function/↩︎ Retrieved from: Wikimedia. https://commons.wikimedia.org/wiki/File:Derivative_-_geometric_meaning.svg↩︎ Retrieved from: Serway, R. A., &amp; Jewett, J. W. (2018). Physics for scientists and engineers with modern physics. Cengage learning.↩︎ Retrieved from: Active Calculus. https://activecalculus.org/single/sec-4-3-definite-integral.html↩︎ Retrieved from: Active Calculus. https://activecalculus.org/single/sec-4-3-definite-integral.html↩︎ Retrieved from: Derivatives on Unequally Spaced Grids. http://cococubed.asu.edu/code_pages/fdcoef.shtml↩︎ "],["elementy-teorii-zbiorów.html", "1.4 Elementy teorii zbiorów", " 1.4 Elementy teorii zbiorów Zob. wykład 4. "],["wykład-2-wstęp-do-badań-ilościowych.html", "2 Wykład 2. Wstęp do badań ilościowych ", " 2 Wykład 2. Wstęp do badań ilościowych "],["myślenie-krytyczne.html", "2.1 Myślenie krytyczne", " 2.1 Myślenie krytyczne … proces oceny twierdzeń, formułowania sądów i wniosków na podstawie przekonujących dowodów zebranych w sposób, który pozwala obiektywnie ocenić, że uzyskane dowody są najwyższej jakości i gwarantują wiarygodność procesu wnioskowania. 2.1.1 Myślenie krytyczne: Prawdziwość jakiego twierdzenia poddano ocenie? Jakie są dostępne dowody, które potwierdzają/przeczą prawdziwości ocenianego twierdzenia? Jakie są alternatywne możliwości interpretacji dostępnych dowodów? Jakie dodatkowe dowody mogłyby pomóc w testowaniu prawdziwości ocenianego twierdzenia? Jakie wnioski wydają się najbardziej rozsądne i uzasadnione w oparciu o dostępne dowody? "],["pytanie-badawcze-i-hipotezy.html", "2.2 Pytanie badawcze i hipotezy", " 2.2 Pytanie badawcze i hipotezy Badanie naukowe poprzedza sformułowanie pytania badawczego, które jest konsekwencją ciekawości naukowca wynikającej po prostu z chęci lepszego zrozumienia otaczającego świata. Zwykle, na potrzeby analizy naukowej, badacze doprecyzowują treść pytań badawczych formułując tzw. hipotezy, które są po prostu spodziewanymi odpowiedziami na postawione pytania badawcze. Hipotezy badawcze mają więc postać zdań twierdzących i muszą być weryfikowalne na gruncie zebranych dowodów. "],["podstawowe-pojęcia.html", "2.3 Podstawowe pojęcia", " 2.3 Podstawowe pojęcia Dane odnoszą się do zbioru wartości, które są zwykle uporządkowane według zmiennych i jednostek obserwowanych (członków próby/populacji). Przykładem danych jest macierz danych w programie do obsługi arkuszy kalkulacyjnych, takim jak Arkusze Google. Zbiór obserwacji co najmniej jednej zmiennej. Zmienna: cecha, której wartość może zmieniać się w zależności od obserwacji. Kiedy chcemy mówić o wpływie czynnika na cechę będącą przedmiotem zainteresowania, identyfikujemy ten czynnik (zmienną) jako zmienną niezależną (często nazywaną predyktorem lub zmienną objaśniającą), a zmienną zależną (często nazywana zmienną odpowiedź). Populacja: Cały zbiór osób lub obiektów, o których potrzebne są informacje, nazywany jest populacją będącą przedmiotem zainteresowania. Próbka: Próba to podzbiór populacji wybrany do badania. Parametr to wartość, zwykle wartość liczbowa, opisująca populację. Parametr jest zwykle wyprowadzany z pomiarów osobników w populacji. Statystyka to wartość, zwykle wartość liczbowa, opisująca próbkę. Statystyka jest zwykle wyprowadzana z pomiarów osobników w próbce. Większość badań statystycznych prowadzi się na wybranych z populacji próbach. Nie wolno utożsamiać wielkości np. średniego dochodu netto per capita, która policzona została na podstawie próby, z jej prawdziwą, ale nieznaną, wartością w populacji. Wartość z próby jest jedynie oszacowaniem, estymacją, prawdziwej wielkości dochodu przeciętnego. Mierniki stosowane do oszacowania np. wartości średniej zmiennej \\(x\\) i obliczane na podstawie danych z próby nazywamy estymatorami nieznanych wartości parametrów populacji. "],["statystyki-opisowe-i-wnioskowanie-statystyczne.html", "2.4 Statystyki opisowe i wnioskowanie statystyczne", " 2.4 Statystyki opisowe i wnioskowanie statystyczne Statystyka opisowa: gałąź statystyk, która obejmuje metody porządkowania i podsumowywania danych. Narzędzia statystyczne pomagają nam analizować dane w celu opisania ich głównych cech - eksploracyjna analiza danych. Oto dwie podstawowe strategie, które pomagają nam przeprowadzić eksplorację zbioru danych: Zacznij od zbadania każdej zmiennej osobno. Następnie przejdź do badania zależności między zmiennymi. Rozpocznij od wykresu lub wykresów. Następnie dodaj liczbowe podsumowania określonych cech danych - np. pomiar tendencji centralnej. Statystyka inferencyjna (wnioskowanie statystyczne): gałąź statystyki polegająca na uogólnianiu wyników z próby na populację, z której próbka została wybrana, i ocenie wiarygodności takich uogólnień. 2.4.1 Zmienne i stałe Stałe - cechy, właściwości, które są niezmienne (np. stała grawitacji \\(G\\)). Zmienne - cechy, które mogą przyjmować różne stany/poziomy/wartości (symbolicznie oznaczane zwykle z użyciem liter \\(X, Y, Z\\)) 2.4.2 Konstrukty i definicje operacyjne 10 Konstrukty lub pojęcia to logiczne struktury lub wyobrażenia o czymś powstałe w czyimś umyśle. Niektóre zmienne, takie jak wzrost, waga i kolor oczu, są dobrze zdefiniowanymi, konkretnymi bytami lub właściwościami obiektów, które można obserwować i mierzyć bezpośrednio. Z drugiej strony, wiele badanych zmiennyvh to jakościowe charakterystyki, których ludzie używają do opisania zjawisk lub ludzi. Na przykład mówimy, że uczeń dobrze sobie radzi w szkole, ponieważ jest inteligentny. Lub mówimy, że ktoś jest niespokojny w sytuacjach społecznych lub że ktoś wydaje się być głodny. Zmienne takie jak inteligencja, lęk i głód są nazywane konstruktami, a ponieważ są niematerialne i nie można ich bezpośrednio zaobserwować, często nazywane się je konstruktami hipotetycznymi. Konstrukty to wewnętrzne atrybuty lub cechy, których nie można bezpośrednio zaobserwować, ale są przydatne do opisywania obiektów i wyjaśniania zachowań. Definicja operacyjna identyfikuje procedurę pomiarową (zestaw operacji) służącą do pomiaru zjawiska lub zachowania i wykorzystuje uzyskane pomiary jako definicję i miernik hipotetycznej konstrukcji. Zauważ, że definicja operacyjna składa się z dwóch komponentów. Po pierwsze, opisuje zestaw operacji służących do pomiaru danego konstruktu lub pojęcia. Po drugie, definiuje ten konstrukt lub pojęcie w kategoriach uzyskanych pomiarów. Definicje operacyjne wyjaśniają sens danego terminu (pojęcia) przez podanie operacji, które umożliwiają precyzyjne określenie stanów/poziomów/wartości charakteryzujących dane pojęcie. 2.4.2.1 Konceptualizacja i operacjonalizacja Konceptualizacja jest procesem myślowym, za pomocą którego rozmyte i nieprecyzyjne konstrukcje (pojęcia) oraz ich składowe komponenty są definiowane w sposób konkretny i precyzyjny. Proces konceptualizacji jest ważny ze względu na nieprecyzyjność, niejasność i niejednoznaczność wielu konstruktów nauk społecznych. Definiując konstrukty, takie jak uprzedzenie lub współczucie, musimy zrozumieć, że czasami konstrukcje te nie są rzeczywiste lub mogą po prostu być wytworami w naszym umyśle. Po zdefiniowaniu konstruktu teoretycznego, można zapytać jak go zmierzyć? Operacjonalizacja odnosi się do procesu opracowywania wskaźników do pomiaru tych konstruktów. Na przykład, jeśli nieobserwowalny konstrukt teoretyczny, taki jak status społeczno-ekonomiczny, jest zdefiniowany jako poziom dochodu rodziny, można go zoperacjonalizować za pomocą następującego wskaźnika: jaki jest twój roczny dochód rodziny? Biorąc pod uwagę wysoki poziom subiektywności i nieprecyzyjność dotyczący rozmaitych konstruktów nauk społecznych, zwykle mierzymy te konstrukty (z wyjątkiem niektórych zmiennych demograficznych, takich jak wiek, płeć, wykształcenie i dochód) przy użyciu wielu wskaźników. 2.4.3 Zbieranie danych Generalnie dane można uzyskać na różne sposoby: Z opublikowanego źródła; Z zaprojektowanego eksperymentu; Z badania obserwacyjnego (np. sondaże opinii, quasi-eksperymenty); Z jakościowych badań terenowych: m.in. etnografia (np. etnografia włosko-ameryk. miasteczka Cornerville), wywiad jakościowy, grupy focusowe lub studium przypadku. Ponadto możesz uzyskać dane za pomocą symulacji: Symulacja polega na zastosowaniu modelu matematycznego lub fizycznego do odtworzenia warunków sytuacji lub procesu. Zbieranie danych często wiąże się z wykorzystaniem komputerów. Symulacje pozwalają badać sytuacje, których stworzenie w prawdziwym życiu jest niepraktyczne lub wręcz niebezpieczne, a często pozwala zaoszczędzić czas i pieniądze. Na przykład producenci samochodów wykorzystują symulacje z manekinami do badania skutków wypadków na ludzi. Podczas tego kursu będziesz miał okazję korzystać z apletów, które symulują procesy statystyczne na komputerze. 2.4.3.1 Dobór jednostek eksperymentalnych random sampling vs. non-random sampling (uzasadniony tylko w niektórych badaniach eksperymentalnych); random assignment (przydział jednostek do grup porównawczych). Pobrane z: Gravetter, F.J., Wallnau, L.B., Forzano, L.A.B. i Witnauer, J.E., 2020. Essentials of statistics for the Behavioral sciences. Cengage Learning.↩︎ "],["metody-doboru-próbywyklad-22.html", "2.5 Metody doboru próby11", " 2.5 Metody doboru próby11 Spis powszechny to liczba lub miara całej populacji. Spis ludności dostarcza kompletnych informacji, ale często jest kosztowny i trudny do wykonania. Badania częściowe, przeprowadzane na podzbiorze populacji (tj. na próbie/próbce statystycznej) jest częściej stosowane w badaniach ilościowych. Aby zebrać nieobciążone (obiektywne) dane, badacz musi upewnić się, że próbka jest reprezentatywna dla populacji. Aby wnioski dotyczące populacji były prawidłowe, należy zastosować odpowiednie techniki pobierania próbek. Pamiętaj, że gdy badanie jest prowadzone z błędnymi danymi, wyniki są wątpliwe. Nawet przy najlepszych metodach próbkowania może wystąpić błąd próbkowania. Błąd próbkowania to różnica między wynikami próby a wynikami populacji. Próba losowa to taka, w której każdy członek populacji ma równe szanse bycia wybranym do próby. Prosta próba losowa to próba należąca do zbioru możliwych prób, z których każda próba tej samej wielkości ma takie same szanse na wybranie. Larson, R. and Farber, B., 2019. Elementary statistics. Pearson Education Canada.↩︎ "],["badania-na-próbie.html", "2.6 Badania na próbie", " 2.6 Badania na próbie W praktyce badawczej, większość badań przeprowadza się na próbie wybranej z populacji. Próba to podzbiór populacji statystycznej. Elementy do próby wybieramy tak, aby struktura próby odzwierciedlała cechy populacji (jeżeli w populacji ok. 10% osób, to osoby z wyższym wykształceniem, to podobny procent takich osób powinien być w próbie), co pozwala na uogólnienie wniosków sformułowanych na podstawie analizy populacji. Zasadność uogólnienia wniosków z próby wynika z teorii prawdopodobieństwa. Badacz może stwierdzić, że dany wniosek odnosi się nie tylko do próby, ale też do populacji, z której tę próbę wybrano. Mówi się, że próba statystytczna musi być reprezentatywna - tylko wtedy analiza statystyczna ma sens i jest wiarygodna. Nie jest łatwo ocenić, czy wybrana próba jest reprezentatywna - jest to przyczyną błędów np. w sondażach opinii publicznej. Badaniem zasadności uogólnień z próby zajmuje się statystyka matematyczna (inferential statistics). 2.6.1 Próba losowa prosta (próba reprezentatywna) … wybrana jest z populacji w taki sposób, który gwarantuje, że każda inna, tej samej wielkości, próba losowa prosta ma jednakową szansę wyboru. 2.6.1.1 Operat losowania W Polsce: baza PESEL, baza gospodarstw domowych GUS (wymaga dodatkowo wylosowania respondenta(ów) spośród osób wchodzących w skałd gospodarstwa). 2.6.2 Podstawowe typy ‘próbkowania’ (random sampling) ‘prosta’ próba losowa (simple random sample); próbkowanie warstwowe (stratified sampling); dobór klastrowy (cluster sampling); próby składające się z ‘ochotników’ (metoda nierzetelna!) "],["próba-losowa-wyklad-23.html", "2.7 Próba losowa 12", " 2.7 Próba losowa 12 Przy doborze próby nie można przecenić znaczenia losowości. W myśleniu statystycznym oczekujemy, że losowa próbka będzie miała w przybliżeniu te same właściwości co populacja. Ponadto, zwykle im większy rozmiar próbki, tym bardziej właściwości próbki są zbliżone do właściwości populacji. Na przykład, aby oszacować średni wzrost dorosłych mężczyzn, wybranie próby spośród graczy NBA byłoby wysoce stronnicze. Generalnie próbki nielosowe są generowane, gdy w procesie selekcji występuje błąd. Takie próbki są bezużyteczne do celów statystycznych, ponieważ próbka nie jest reprezentatywna dla populacji. Prosta próba losowa to taka, w której każdy osobnik w populacji ma takie samo prawdopodobieństwo wyboru. Aby spełnić ten wymóg, stosowana metoda pobierania próbek musi być wolna od błędów w odniesieniu do mierzonej właściwości. Liczby losowe generowane komputerowo (zwane również liczbami pseudolosowymi) mogą być używane do wybierania losowych próbek: najpierw przypisujemy liczbę do każdej osoby w populacji, a następnie używamy komputerowego generatora liczb losowych, aby wybrać próbę. Poniżej przedstawiono typowe typy błędów próbkowania. 2.7.1 Obciążenie badania (bias) - błędy próbkowania i błędy systematyczne W statystyce błędy próbkowania powstają, gdy charakterystyka statystyczna populacji jest szacowana na podstawie podzbioru lub próby tej populacji. Ponieważ próba nie obejmuje wszystkich członków populacji, statystyki dotyczące próby, takie jak średnie i kwartyle, zasadniczo różnią się od charakterystyk całej populacji, które są znane jako parametry. Na przykład, jeśli mierzy się wzrost tysiąca osób z kraju liczącego milion osób, średni wzrost tysiąca zwykle nie jest taki sam, jak średni wzrost wszystkich miliona ludzi w kraju. Ponieważ pobieranie próbek jest zwykle wykonywane w celu określenia cech całej populacji, różnica między próbą a wartościami populacji jest uważana za błąd. Systematyczny błąd jest przewidywalny i zwykle stały lub proporcjonalny do prawdziwej wartości. Jeśli można zidentyfikować przyczynę systematycznego błędu, zwykle można ją wyeliminować. Systematyczne błędy wynikają z niedoskonałej kalibracji przyrządów pomiarowych lub niedoskonałych metod obserwacji lub ingerencji środowiska w proces pomiarowy i zawsze wpływają na wyniki eksperymentu w przewidywalnym kierunku. 2.7.1.1 Wybrane źródła błędów w badaniach statystycznych Błąd wykluczenia, gdy część populacji jest wykluczona z procesu pobierania próbek. Stronniczość odpowiedzi, w której sformułowanie kwestionariusza nie jest neutralne, ale raczej sugeruje lub prowokuje określoną odpowiedź. Błąd braku odpowiedzi, w którym osoby o wspólnej charakterystyce niechętnie udzielają odpowiedź na pytania (Zauważ, że nie jest to przeciwieństwo błędu odpowiedzi). Błąd samoselekcji (lub błąd dobrowolnej odpowiedzi), w którym osoby wybierają siebie (lub zgłaszają się na ochotnika) do próby. Wiele z tych błędów wynika z wygodnego pobierania próbek, w którym próbki są pobierane od osób tylko dlatego, że znajdują się w pobliżu lub są łatwo dostępne. Selection bias, tj. błąd selekcji - jest to błąd wynikający z selekcji osób, grup lub danych do analizy w taki sposób, że nie jest osiągnięty wystarczający poziom losowości, co powoduje, że uzyskana próba nie jest reprezentatywna dla populacji, która ma być analizowana. Czasami nazywa się to efektem selekcji. Sformułowanie „błąd selekcji\" najczęściej odnosi się do zniekształcenia analizy statystycznej, wynikającego ze sposobu zbierania próbek. Jeśli nie weźmie się pod uwagę błędu selekcji, niektóre wnioski z badania mogą być fałszywe. 2.7.2 Dobór próby W praktyce trudno jest zapewnić dobór próby losowej. Opracowano kilka metod pobierania próbek w określonych sytuacjach. Oto niektóre z najczęstszych. Systematyczne pobieranie próbek: W systematycznym pobieraniu próbek próbka jest systematycznie wybierana z listy. Na przykład możemy wybrać co setne nazwisko w książce telefonicznej. Próbkowanie warstwowe: W próbkowaniu warstwowym populacja jest najpierw dzielona na nienakładające się (rozłączne) grupy (lub warstwy), a następnie próbka jest wybierana proporcjonalnie z każdej grupy. Na przykład, aby wybrać próbkę zarejestrowanych wyborców, możemy podzielić populację na grupy - biali, Afroamerykanie, Latynosi i inni - a następnie losowo wybrać zarejestrowanych wyborców, wybierając z każdej grupy liczbę proporcjonalną do wielkość tej grupy w populacji. Próbkowanie klastrowe: W losowaniu klastrów populacja jest dzielona na grupy (lub klastry), a następnie wybierana jest próba losowa klastrów. Na przykład, aby przeprowadzić ankietę wśród mieszkańców Los Angeles, najpierw losowo wybieramy zbiór budynków mieszkalnych (grupy), a następnie przeprowadzamy wywiady z każdym mieszkańcem wybranych budynków. Ten rodzaj pobierania próbek zmniejsza czas i koszty ankietera w podróży z miejsca na miejsce. Pobrane z: Stewart, J., Redlin, L. and Watson, S., 2013. Precalculus. Cengage Learning.↩︎ "],["rozkłady-danych.html", "2.8 Rozkłady danych", " 2.8 Rozkłady danych Pierwszym krokiem w analizie danych zebranych na temat zmiennej jest przyjrzenie się obserwowanym wartościom za pomocą wykresów i podsumowań liczbowych. Celem jest opisanie kluczowych cech rozkładu zmiennej. Najważniejszym krokiem eksploracyjnej analizy danych jest oszacowanie rozkładu obserwacji na zmiennej. Rozkład zmiennej opisuje, jak obserwacje mieszczą się (rozkładają) w zakresie możliwych wartości. Rozkład zbioru danych to tabela, wykres lub formuła, która zawiera wartości obserwacji i częstotliwość ich występowania. Ważną cechą rozkładu danych jest jego kształt. Kształt rozkładu często odgrywa rolę w określaniu odpowiedniej metody analizy statystycznej. Do oszacowania rozkładu danych wykorzystujemy narzędzia do wizualizacji danych takie jak histogram lub wykres pudełkowy. Rozkład częstości to zbiór obserwacji uzyskanych poprzez posortowanie obserwacji w klasy i pokazanie ich częstotliwości występowania w każdej z klas: Rozkład (częstość) danych - określa możliwe obserwacje (liczby, kategorie) i wskazuje, jak często występują. Rozkład częstości to tabela podsumowująca, w której dane są uporządkowane liczbowo w klasach lub przedziałach. Rozkład częstotliwości względnych uzyskuje się, dzieląc częstotliwość absolutne w każdej klasie przez całkowitą sumę wartości. Z tego można uzyskać rozkład procentowy mnożąc każdą względną częstotliwość przez 100%. Rozkład częstości dla danych kategorialnych (jakościowych): Tabela, która wyświetla możliwe kategorie wraz z powiązanymi częstotliwościami i/lub częstotliwościami względnymi. Częstość: częstość dla określonej kategorii to liczba przypadków, w których kategoria pojawia się w zbiorze danych. Względna częstotliwość dla określonej kategorii to odsetek obserwacji należących do tej kategorii. "],["podstawowe-etapy-badania-społecznegowyklad-24.html", "2.9 Podstawowe etapy badania społecznego13", " 2.9 Podstawowe etapy badania społecznego13 Systematyczne testowanie naszych wyobrażeń o naturze rzeczywistości społecznej często wymaga starannie zaplanowanych i przeprowadzonych badań - można wyróżnić następujące etapy badania: Problem do zbadania sprowadza się do testowalnej hipotezy (na przykład „Rodziny niepełne generują więcej przestępstw niż rodziny z dwoma rodzicami\"). Opracowywany jest odpowiedni zestaw narzędzi (np. kwestionariusz lub harmonogram wywiadów). Dane są zbierane (to znaczy badacz może udać się w teren i np. przeprowadzić ankietę). Dane są analizowane pod kątem ich związku z przyjętymi hipotezami. Wyniki analizy są interpretowane i upubliczniane (na przykład za pomocą wykładu, artykułu w czasopiśmie lub informacji prasowej). Retrieved from: Fox, J.A., Levin, J. and Forde, D.R., 2017. Elementary Statistics in Social Research.↩︎ "],["badanie-statystyczne-niezbędne-kroki.html", "2.10 Badanie statystyczne - niezbędne kroki", " 2.10 Badanie statystyczne - niezbędne kroki Zidentyfikuj interesującą (-e) zmienną (-e) (przedmiot zainteresowania) i populację objętą badaniem. Opracuj szczegółowy plan zbierania danych. Jeśli używasz próbki, upewnij się, że jest ona reprezentatywna dla populacji. Zbierz dane. Opisz dane przy użyciu opisowych technik statystycznych. Zinterpretuj dane i podejmij decyzje dotyczące populacji na podstawie wyników wnioskowania statystycznego. Zidentyfikuj możliwe błędy. "],["badania-obserwacyjne-i-eksperymentalnewyklad-25.html", "2.11 Badania obserwacyjne i eksperymentalne14", " 2.11 Badania obserwacyjne i eksperymentalne14 Badanie statystyczne można zwykle podzielić na badanie obserwacyjne lub eksperymenty. W badaniu obserwacyjnym badacz nie wpływa na odpowiedzi. W eksperymencie badacz celowo interweniuje (poddanie badanych działaniu jakiegoś bodźca) przed zarejestrowaniem odpowiedzi. Najogólniej: W badaniu obserwacyjnym badacz obserwuje i mierzy interesujące cechy części populacji, ale nie zmienia istniejących warunków. Na przykład, można przeprowadzić badanie preferencji politycznych wyborców z wykorzystaniem odpowiedniej ankiety (sondaże opinii). Wykonując eksperyment, stosuje się bodziec (treatment) do części populacji, zwanej grupą eksperymentalną (treatment lub experimental group), i obserwuje się odpowiedzi. Inną część populacji można wykorzystać jako grupę kontrolną, w której nie stosuje się żadnego bodźca lub interwencji eksperymentalnej. W wielu przypadkach jednostkom z grupy kontrolnej podaje się placebo, które jest nieszkodliwym, fałszywym bodźcem, który ma imitować prawdziwą interwencję eksperymentalną Następnie można porównać i zbadać odpowiedzi grupy badanej i grupy kontrolnej. Na przykład przeprowadzono eksperyment, w którym diabetycy codziennie przyjmowali ekstrakt z cynamonu, podczas gdy grupa kontrolna go nie przyjmowała. Po 40 dniach diabetycy, którzy brali cynamon, zmniejszyli ryzyko chorób serca, podczas gdy grupa kontrolna nie doświadczyła żadnych zmian. (Źródło: Diabetes Care) Retrieved from: Larson, R., Farber, E. and Farber, E., 2009. Elementary statistics: Picturing the world. Pearson Prentice Hall.↩︎ "],["statystyczny-projekt-badań-przykład-prostego-eksperymentu-wyklad-26.html", "2.12 Statystyczny projekt badań - przykład prostego eksperymentu 15", " 2.12 Statystyczny projekt badań - przykład prostego eksperymentu 15 Projekt badań eksperymentalnych - przegląd Pobrane z: Gravetter, F.J., Wallnau, L.B., Forzano, L.A.B. i Witnauer, J.E., 2020. Essentials of statistics for the Behavioral sciences. Cengage Learning.↩︎ "],["projekt-eksperymentu-wyklad-27.html", "2.13 Projekt eksperymentu 16", " 2.13 Projekt eksperymentu 16 W badaniach obserwacyjnych badacz nie ma kontroli nad czynnikami wpływającymi na badaną własność - badacz jest jedynie obserwatorem. Nieistotne lub niezamierzone zmienne, które systematycznie wpływają na badaną właściwość, nazywane są zmiennymi zakłócającymi (confounding variables lub lurking variables). Mówi się, że takie zmienne zakłócają wyniki badania. Poniższe przykłady pokazują, jak to się może stać. Aby wyeliminować lub znacznie zmniejszyć wpływ zmiennych zakłócających, badacze często przeprowadzają eksperymenty, aby takie zmienne można było kontrolować. W badaniu eksperymentalnym wybiera się dwie grupy: grupę eksperymentalną (w której osoby są poddane działaniu bodźca, np. nowa substancja lecznicza) i grupę kontrolną (w której osoby nie są poddane interwencji eksperymentalnej). Jednostki w eksperymencie nazywane są podmiotami (lub jednostkami eksperymentalnymi). Celem jest zmierzenie odpowiedzi osobników na bodziec - to znaczy, czy interwencja eksperymentalna wywołuje efekt, czy nie. Następnym krokiem jest upewnienie się, że obie grupy są jak najbardziej podobne, z wyjątkiem ekspozycji na bodziec. Jeśli dwie grupy są podobne, wówczas wszelkie różnice statystyczne w odpowiedzi między grupami można z pewnością przypisać działaniu danego bodźca. Częstym czynnikiem zakłócającym jest efekt placebo, w którym pacjenci, którzy sądzą, że np. otrzymują testowany lek, zgłaszają poprawę (postrzeganą lub rzeczywistą), mimo że otrzymali, tylko placebo - np. symulowane lub fałszywe leczenie. Aby kontrolować efekt placebo, badacz może zastosować metodę, w której badani nie wiedzą, czy są w grupie leczonej, czy kontrolnej, lub, w którym badacze również nie mają dostępu do tych informacji podczas przebieg eksperymentu. Replikacja, powtórzenie eksperymentu, może również wzmocnić wiarygodność wyników. Pobrane z: Stewart, J., Redlin, L. and Watson, S., 2013. Precalculus. Cengage Learning.↩︎ "],["przykłady-badań-empirycznych.html", "2.14 Przykłady badań empirycznych", " 2.14 Przykłady badań empirycznych Czy przykłady badań politologicznych krótko opisane niżej to: badania eksperymentalne badania obserwacyjne (?) "],["przykłady-badanie-1.html", "2.15 Przykłady - badanie 1", " 2.15 Przykłady - badanie 1 Politolodzy porównali stosunek obywateli różnych państw UE do imigrantów z krajów Afryki Północnej. Badacze do pomiaru postaw osób badanch posłużyli się kwestionariuszem ankiety z odpowiednio zaprojektowanymi pytaniami zamkniętymi. Analizę przeprowadzono na losowych próbach mieszkańców krajów uczestniczących w badaniu. "],["przykłady-badanie-2.html", "2.16 Przykłady - badanie 2", " 2.16 Przykłady - badanie 2 Politolodzy przeprowadzili badanie tzw. odchylenia od proporcjonalności w wyborach z użyciem wskaźnika dysproporcjonalności Gallaghera dla elekcji do wszystkich rad gmin miejskich 2014. \\(GHI = \\sqrt{\\Sigma_{i=1}^n(s_i - v_i)^2}\\) "],["przykłady-badanie-3.html", "2.17 Przykłady - badanie 3", " 2.17 Przykłady - badanie 3 Zespół psychologów i politologów przeprowadził badanie wpływu tzw. negatywnych reklam politycznych na skłonność do uczestnictwa w wyborach prezydenckich. Badacze zaprosili grupę osób z populacji uprawnionych do głosowania do uczestnictwa w badaniu (prawdziwy cel badania nie został im ujawniony). Wybraną grupę losowo podzielono na dwa zbiory A i B (randomizacja). Grupę A zaproszono do pokoju 1, grupę B do pokoju 2, w których: wykonano pomiar skłonności do głosowania na sztuczej skali Likerta (11 poziomów), następnie wyświetalno reklamy, w tym reklamy polityczne (przy czym, tylko grupa A obejrzała m.in. tzw. negatywną reklamę polityczną), ponownie wykonano pomiar skłonności do głosowania, sprawdzono zmianę (\\(\\Delta y\\)) skłonności do głosowania osób badanych w grupie A i B, porównano zmianę skłonności dla grupy A i B z użyciem: wykresów pudełkowych. "],["eksperyment.html", "2.18 Eksperyment", " 2.18 Eksperyment Badanie, w którym manipulujemy poziomami zmiennej objaśniającej, aby zaobserwować jej wpływ na zmienną objaśnianą: zmienna objaśniająca \\(\\rightarrow\\) zmienna objaśniana 2.18.1 Klasyczny plan eksperymentalny Etap I: Wybór próby do eksperymentu (np. random sampling z interesującej badacza populacji) Etap II: Losowy rozdział badanych obiektów do grup porównawczych (randomizacja) Etap III: Eksperyment (zob. tabela) Podział Grupa Pomiar początkowy (pretest) Interwencja (Treatment) Pomiar końcowy (posttest) Różnica R Eksp. \\(O_1\\) \\(X\\) \\(O_2\\) \\(O_2 - O_1\\) R Kontrol. \\(O_3\\) np. placebo \\(O_4\\) \\(O_4 - O_3\\) "],["badania-quasi-eksperymentalne-eksperymenty-naturalne.html", "2.19 Badania quasi-eksperymentalne (eksperymenty naturalne)", " 2.19 Badania quasi-eksperymentalne (eksperymenty naturalne) 2.19.0.1 Przykład: tzw. efekt behawioralny systemu wyborczego 2.19.0.2 Pretest Analiza rozkładów wartości: wskaźników strategicznego zachowania takich jak: (‘the vote share of the non-top-two parties’, lub ‘the Effective Number of Electoral Parties (ENEP)’), oraz frekwencji wyborczej w gminach, w których stosowano: 1) SMD, 2) MMD lub 3) OLPR. TREATMENT: Zmiana prawa wyborczego w 2011 pociągająca za sobą wprowadzenie SMD we wszystkich gminach niebędących miastami na prawach powiatu. 2.19.0.3 Posttest Analiza rozkładów wartości badanych wskaźników w gminach, w których: SMD \\(\\rightarrow\\) SMD MMD \\(\\rightarrow\\) SMD lub SMD/MMD \\(\\rightarrow\\) SMD/MMD SMD/MMD \\(\\rightarrow\\) OLPR albo OLPR \\(\\rightarrow\\) OLPR OLPR \\(\\rightarrow\\) SMD 2.19.0.4 Analiza wyników Porównanie zmiany (pretest – posttest) w grupach kontrolnej i eksperymentalnej. "],["przykłady-badanie-4.html", "2.20 Przykłady - badanie 4", " 2.20 Przykłady - badanie 4 Zbadano wpływ wielkości okręgów wyborczych w systemach wyborczych reprezentacji proporcjonalnej na poziom dysproporcjonalności z wykorzystaniem symulacji komputerowej Monte Carlo zaprojektowanej z użyciem języka programowania R. SYMULATOR "],["wykład-3-wstęp-do-statystyki-statystyka-opisowa.html", "3 Wykład 3. Wstęp do statystyki - statystyka opisowa ", " 3 Wykład 3. Wstęp do statystyki - statystyka opisowa "],["zmienne-i-stałe-1.html", "3.1 Zmienne i stałe", " 3.1 Zmienne i stałe Stałe - cechy, właściwości, które są niezmienne (np. stała grawitacji \\(G\\)). Zmienne - cechy, które mogą przyjmować różne stany/poziomy/wartości (symbolicznie oznaczane zwykle z użyciem liter \\(X, Y, Z\\)) "],["wybór-obiektówjednostek-do-badania.html", "3.2 Wybór obiektów/jednostek do badania", " 3.2 Wybór obiektów/jednostek do badania Badania na populacji statystycznej Badania na próbie statystycznej "],["badania-na-próbie-1.html", "3.3 Badania na próbie", " 3.3 Badania na próbie W praktyce badawczej, większość badań przeprowadza się na próbie wybranej z populacji. Próba to podzbiór populacji statystycznej. Elementy do próby wybieramy tak, aby struktura próby odzwierciedlała cechy populacji (jeżeli w populacji ok. 10% osób, to osoby z wyższym wykształceniem, to podobny procent takich osób powinien być w próbie), co pozwala na uogólnienie wniosków sformułowanych na podstawie analizy populacji. Zasadność uogólnienia wniosków z próby wynika z teorii prawdopodobieństwa. Badacz może stwierdzić, że dany wniosek odnosi się nie tylko do próby, ale też do populacji, z której tę próbę wybrano. Mówi się, że próba statystytczna musi być reprezentatywna - tylko wtedy analiza statystyczna ma sens i jest wiarygodna. Nie jest łatwo ocenić, czy wybrana próba jest reprezentatywna - jest to przyczyną błędów np. w sondażach opinii publicznej. Badaniem zasadności uogólnień z próby zajmuje się statystyka matematyczna (inferential statistics). 3.3.1 Próba losowa prosta (próba reprezentatywna) … wybrana jest z populacji w taki sposób, który gwarantuje, że każda inna, tej samej wielkości, próba losowa prosta ma jednakową szansę wyboru. 3.3.2 Operat losowania 3.3.2.1 W Polsce: baza PESEL, baza gospodarstw domowych GUS (wymaga dodatkowo wylosowania respondenta(ów) spośród osób wchodzących w skałd gospodarstwa). 3.3.3 Podstawowe typy ‘próbkowania’ (random sampling) ‘prosta’ próba losowa (simple random sample); próbkowanie warstwowe (stratified sampling); dobór klastrowy (cluster sampling); próby składające się z ‘ochotników’ (metoda nierzetelna!) "],["obciążenie-badania-bias.html", "3.4 Obciążenie badania (bias)", " 3.4 Obciążenie badania (bias) M.in.: non-response bias, selection bias, measurement bias. "],["pomiar-definicja.html", "3.5 Pomiar - definicja", " 3.5 Pomiar - definicja Pomiar to procedura, w której przyporządkowuje się, zgodnie z określonymi zasadami, wartości liczbowe, stany lub kategorie właściwościom empirycznym badanych obiektów. Badanie naukowe zwykle wymaga przeprowadzenia pomiaru wartości zmiennych na etapie zbierania danych. Np. jeżeli pytamy respondenta w badaniu ankietowym o jego dochód do dyspozycji, to dokonujemy pomiaru zmiennej “Dochód do dyspozycji respondenta”. Pomiar zmiennej wymaga określenia jednostki (w tym przypadku dochody mierzymy np. w PLN, lub w Euro) oraz znajomości tzw. poziomu pomiaru (w przypadku pomiaru dochodów jest to tzw. pomiar na poziomie skali ilorazowej). Np. możemy się umówić, że będziemy mierzyć na 11 punktowej skali (0, 1, 2, 3, …, 10) autoidentyfikację, respondentów biorących udział w sondażu, na skali Lewica (0) - Prawica (10). \\[\\text{(Lewica) } 0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 \\text{ (Prawica)}\\] 3.5.0.0.1 Poziomy pomiaru Poziom pomiaru można określić jako ilościowy (dane liczbowe na skali interwałowej lub ilorazowej), lub jakościowy (zmienne porządkowe lub nominalne). Dane nominalne i porządkowe przedstawia się jako łańcuchy/ciągi znaków alfanumerycznych. Zmienna może być traktowana jako nominalna (nominalny poziom pomiaru), gdy jej wartości reprezentują kategorie bez wewnętrznego rangowania (w zbiorze możliwych wartości zmiennej jest określona tylko relacja równoważności, brakuje relacji porządku); na przykład wydział, na którym są zatrudnieni pracownicy. Przykładami zmiennych nominalnych są: region, kod pocztowy lub wyznanie; Zmienna może być traktowana jako porządkowa, gdy jej wartościom można przypisać rangi, na przykład poziomy zadowolenia z usługi od bardzo niezadowolonego do bardzo zadowolonego. Przykładami zmiennych porządkowych mogą być oceny opinii reprezentujące stopień satysfakcji lub przekonania, skala ocen w szkole, oraz oceny preferencji. Zmienna może być traktowana jako zmienna interwałowa (przedziałowa), gdy pozwala na formułowanie, obok twierdzeń o równości lub różności wartości tej zmiennej, oraz twierdzeń typu, “większy niż” i “mniejszy niż”, również twierdzeń o równości przedziałów (np. przedziały [0 stopni \\(C\\), 10 stopni \\(C\\)], oraz \\([10^{\\circ}C\\), \\(20^{\\circ}C]\\) są równe, mają tę samą szerokość). Zmienne mierzone na skali interwałowej nie mają bezwzględnego punktu zerowego. Punkt zero jest wybrany umownie, tak jak np. w przypadku skali Fahrenheita. Rozważmy trzy obiekty: A, B i C, mające temperaturę odpowiednio 20’ 40’ i 60’ Celsjusza. Można powiedzieć, że różnica między temperaturą przedmiotu A i przedmiotu B jest taka sama, jak różnica między temperaturą przedmiotu B i przedmiotu C. Można również powiedzieć, że różnica między temperaturą przedmiotu A i przedmiotu C (mierzoną np. w stopniach Celsjusza) jest dwa razy większa niż różnica między temperaturą przedmiotu A i przedmiotu B. Nie można natomiast powiedzieć, że B ma temperaturę dwukrotnie wyższą niż A, ani że C ma temperaturę trzykrotnie wyższą niż A - takie twierdzenie jest uprawnione tylko w przypadku zmiennych mierzonych na skali stosunkowej. Zmienną przedziałową z arbitralnie określonym punktem zerowym jest również czas kalendarzowy. Skala przedziałowa umożliwia porównywanie różnic między wartościami zmiennej w badanej grupie przedmiotów, a co za tym idzie istnieje możliwość obliczania średniej arytmetycznej tych wartości, ich wariancji, odchylenia standardowego i, w konsekwencji, współczynników korelacji między wartościami badanych cech. Jednak, ze względu na umowność punktu zerowego nie jest dozwolone ustalanie stosunków między wartościami zmiennej. Wykonywanie arytmetycznych operacji dodawania i odejmowania jest dopuszczalne na wartościach skali przedziałowej. Skala ilorazowa (stosunkowa) dopuszcza ponadto wykonywanie na wartościach skali operacji dzielenia i mnożenia Jedyną dopuszczalną operacją matematyczną na wartościach skali nominalnej i porządkowej jest zliczanie zdarzeń (tzn. tego, ile relacji mniejszości, większości i równości określono na wartościach np. skali porządkowej). “Naturalnym” początkiem skali ilorazowej jest wartość zerowa (zero ogranicza lewostronnie zakres skali). Przykłady zmiennych ilorazowych: cena w zł, temperatura w Kalwinach (temperatura w stopniach Celsjusza jest na skali interwałowej), napięcie elektryczne, inflacja, bezrobocie, masa, czas wykonywania danej czynności (np. rozwiązanie ćwiczenia, bieg na 100 m). W ostatnim przypadku początek czynności jest naturalnym punktem zerowym, a sekunda pracy badanego jednostką miary. Zmienne interwałowe i stosunkowe łącznie określa się jako zmienne ilościowe. Zmienne można typologizować nie tylko jako nominalne, porządkowe itd. Zmienne ilościowe dzieli się też na: Zmienna, która przyjmuje tylko niektóre wartości (skończoną lub nieskończoną, ale przeliczalną liczbę wartości). Taką zmienną jest np. liczba osób w grupie studenckiej, liczba przedmiotów wyprodukowanych na danym stanowisku pracy w ciągu jednej zmiany, liczba wyborców głosujących na kandydata \\(x\\) itp. Zmienna, która przyjmuje wszystkie wartości z pewnego przedziału liczbowego - tych wartości jest nieprzeliczalnie wiele. Zmienną losową ciągłą jest np.: wzrost, waga, wiek poszczególnych osób, ilość energii elektrycznej zużywanej dziennie przez gospodarstwo domowe, dochód gospodarstwa rolniczego, itp. Zmienne skokowe przedstawia się graficznie na wykresie jako punkty, natomiast zmienne ciągłe jako krzywe lub odcinki. "],["trafność-i-rzetelność-pomiarów.html", "3.6 Trafność i rzetelność pomiarów", " 3.6 Trafność i rzetelność pomiarów "],["trafność-i-rzetelność.html", "3.7 Trafność i rzetelność", " 3.7 Trafność i rzetelność Rzetelność to spójność pomiarów (precyzja pomiaru). Powtarzając pomiar/badanie uzyskujemy ten sam lub bardzo zbliżony wynik. Trafność to stopień w jakim wskaźnik mierzy to, do pomiaru czego został zaprojektowany. "],["poziomy-pomiaru-1.html", "3.8 Poziomy pomiaru", " 3.8 Poziomy pomiaru Typ Jakościowy Jakościowy Ilościowy Ilościowy Podtyp Nominalny Porządkowy Interwałowy Ilorazowy Cecha Wyróżnione kategorie (np. płeć) Uporządkowane kategorie (np. skala ocen, wskaźnik IQ) Odległości między kategoriami mają sens (np. kalendarz (daty), temperatura C, F) Istnieje zero bezwzględne (waga, temperatura K, liczba wypadków samochodowych itp.) Dopuszczalne operacje \\(=, \\neq\\) \\(&gt;, &lt;\\) \\(+, -\\) \\(\\times, \\div\\) Levels of measurement "],["zmienne-dyskretne-i-ciągłe.html", "3.9 Zmienne dyskretne i ciągłe", " 3.9 Zmienne dyskretne i ciągłe Continuous and Discrete "],["związki-przyczynowo-skutkowe-i-korelacyjne-między-zmiennymi.html", "3.10 Związki przyczynowo-skutkowe i korelacyjne między zmiennymi", " 3.10 Związki przyczynowo-skutkowe i korelacyjne między zmiennymi Korelacja (współwystępowanie dwóch zmiennych) to nie to samo co przyczynowość (coś wynika z czegoś). Nie ma przyczynowości bez korelacji, ale korelacja nie oznacza jeszcze przyczynowości. 3.10.0.1 Przykład “W zimie obserwujemy więcej infekcji wirusowych. Kiedyś uważano wręcz, że to wyziębienie („przeziębienie”) po prostu powoduje chorobę. Dzisiaj wiemy, że przyczyną są infekcje (głównie wirusowe). Ale czy wyziębienie ułatwia zachorowanie? To wydaje się logiczne, ale może w zimie ludzie przebywają więcej w pomieszczeniach, często w grupach, co ułatwia transfer patogenów. Większą zachorowalność na grypę obserwuje się w rejonach tropikalnych podczas pory deszczowej, a jest tam przecież bardzo ciepło. Albo wysuszone zimnym powietrzem błony śluzowe są bardziej narażone na atak wirusa?\" (Źródło: https://www.damianparol.com/czy-rekiny-jedza-lody-czyli-korelacja-a-przyczynowosc/) Źródło: Introduction to Statistics and Data Analysis, Roxy Peck, Chris Olsen, Jay L. Devore (2016) 3.10.1 Zmienne zakłócające (‘confounding lub lurking’ variables) Źródło: https://spot.pcc.edu/~evega/section-4.html "],["poziom-pomiaru-2.html", "3.11 Poziom pomiaru (2)", " 3.11 Poziom pomiaru (2) Typ zmiennej wpływa na wybór mierników statystycznych. Jeśli chodzi o miary tendencji centralnej i miary rozproszenia: zmienne nomianalne (można wyzanczyć tylko dominantę); zmienne porządkowe (dominanta, mediana, rozstęp międzykwartylowy) zmienne ilościowe (dominanta, mediana, rozstęp międzykwartylowy, średnie, odchylenie standardowe) "],["poziom-pomiaru-3.html", "3.12 Poziom pomiaru (3)", " 3.12 Poziom pomiaru (3) Zwykle, w przypadku zmiennej porządkowej, która przyjmuje niewiele poziomów (przyjmijmy, że mniej niż 5) stosujemy, jednak, tylko dominantę. Czasami, np. skale ocen, dla zmiennych porządkowych zwyczajowo używa się też w opisie statystycznym średnich, ale należy mieć świadomość, że takie postępowanie nie jest w pełni zasadne matematycznie. "],["tabelaryczna-prezentacja-rozkładów-danych.html", "3.13 Tabelaryczna prezentacja rozkładów danych", " 3.13 Tabelaryczna prezentacja rozkładów danych Dane nieuporządkowane (tzw. szereg szczegółowy) Dane uporządkowane (tzw. szereg rozdzielczy lub tzw. rozkład częstości zmiennej) "],["szereg-szczegółowy.html", "3.14 Szereg szczegółowy", " 3.14 Szereg szczegółowy \\(X = \\{4,4,4,4,8,8,8,2\\}\\) Lp. \\(x_i\\) 1 4 2 4 3 4 4 4 5 8 6 8 7 8 8 2 - - \\(n = 8\\) "],["szereg-rozdzielczy-rozkład-częstości-punktowy.html", "3.15 Szereg rozdzielczy (rozkład częstości) punktowy", " 3.15 Szereg rozdzielczy (rozkład częstości) punktowy \\(X = \\{4,4,4,4,8,8,8,2\\}\\) Lp. \\(x_i\\) Częstość \\(f_i\\) Częstość względna (frakcja) \\(p_i = f_i/n\\) 1 2 1 1/8 2 4 4 1/2 3 8 3 3/8 \\(\\Sigma\\) - \\(n\\) = 8 1 UWAGA: Częstość względną można interpretować jako prawdopodobieństwo statystyczne wystąpienia danej wartość zmiennej. "],["szereg-rozdzielczy-rozkład-częstości-z-przedziałami-klasowymi.html", "3.16 Szereg rozdzielczy (rozkład częstości) z przedziałami klasowymi", " 3.16 Szereg rozdzielczy (rozkład częstości) z przedziałami klasowymi Ten typ szeregu jest wykorzystywany tylko, wtedy, gdy można przyjąć, że badana zmienna (np. pole powierzchni, wzrost, dochody w PLN (?) itp.) jest ciągła. Dla zmiennych dyskretnych stosujemy szereg rozdzielczy punktowy. UWAGA: przedziały klasowe zwykle są tej samej długości (jak w tabeli na następnym slajdzie), ale nie zawsze. Dane: \\(X \\in [1, 100]\\) "],["szereg-rozdzielczy-rozkład-częstości-dla-danych-pogrupowanych.html", "3.17 Szereg rozdzielczy (Rozkład częstości dla danych pogrupowanych)", " 3.17 Szereg rozdzielczy (Rozkład częstości dla danych pogrupowanych) … z przedziałami klasowymi (przykład) Lp. Przedział klasowy (bin) \\(h_k\\) dla \\(x_i\\) Częstość \\(f_i\\) Częstość względna (frakcja) \\(p_i = f_i/n\\) Gęstość \\(d_i = p_i/\\Delta x_i\\) 1 [1, 6) 12 12/120 = 0.1 0.1/(6 - 1) = 0.02 2 [6, 11) 6 0.05 0.01 … … … … … 20 [96, 101) 3 0.025 0.005 \\(\\Sigma\\) - \\(n\\) = 120 1 - Tzw. gęstość jest bardzo ważną wielkością w statystce matematycznej - zob. np. pojęcie funkcji gęstości. "],["miary-tendencji-centralnej-miary-rozproszenia-dyspersji-oraz-mierniki-siły-związku-między-zmiennymi.html", "3.18 Miary tendencji centralnej, miary rozproszenia (dyspersji) oraz mierniki siły związku między zmiennymi", " 3.18 Miary tendencji centralnej, miary rozproszenia (dyspersji) oraz mierniki siły związku między zmiennymi W badaniach statystycznych wykorzystuje się wiele typów mierników. We wprowadzeniu do statystyki należy wspomnieć o trzech istotnych rodzajach wskaźników opisowych: miary tendencji centralnej, miary rozproszenia (dyspersji), miary związku (korelacji) między zmiennymi. Należy znać następujące podstawowe miary tendencji centralnej: średnia arytmetyczna (average value) kwantyle oraz kwartyle, a w tym mediana (median) dominanta lub wartość modalna (mode) Wśród miar rozproszenia, najważniejsze są: wariancja (variance), odchylenie standardowe (standard deviation), rozstęp międzykwartylowy (Interquartile Range, IQR). Wśród mierników siły związku między zmiennymi (mierniki korelacji), podstawowe znaczenie mają: kowariancja i tzw. współczynnik korelacji liniowej Pearsona (stosowany dla zmiennych mierzonych na skali interwałowej lub stosunkowej) współczynnik korelacji rang Spearmana (zmienne porządkowe) współczynnik korelacji \\(\\tau_b\\) Kendalla (zmienne porządkowe) Inne metody badania zależności między zmiennymi, to m.in.: analiza diagramów rozproszenia modele regresyjne, w tym model regresji logistycznej - najważniejsza, ale też najbardziej skomplikowana grupa metod stosowana w analizie zależności między zmiennymi (*) test niezależności \\(\\chi^2\\) (zmienne nominalne) "],["średnia.html", "3.19 Średnia", " 3.19 Średnia "],["wariancja-i-odchylenie-standardowe.html", "3.20 Wariancja i odchylenie standardowe", " 3.20 Wariancja i odchylenie standardowe Powyższy rysunek przedstawia trzy zbiory danych (1, 2, 3); każdy z nich charakteryzuje ta sama średnia i mediana. Jednak, przeciętne rozproszenie obserwacji (danych) względem średniej, tj. odchylenie standardowe jest największe dla dolnego zbioru (3) i najmniejsze dla zbioru (1). Rysunek 2.10 przedstawia rozkłady dochodów dla nauczycieli muzyki w USA i Danii - odchylenie standardowe dochodu w przypadku Danii jest znacznie mniejsze, przy tej samej wartość średniej. "],["średnia-mediana-czy-dominanta.html", "3.21 Średnia, mediana, czy dominanta", " 3.21 Średnia, mediana, czy dominanta Jeżeli dane mają charakter ilościowy, do opisania środka rozkładu należy zastosować średnią lub medianę. Jeżeli dane nie zawierają żadnych nietypowo dużych lub niezwykle małych wartości, do opisania środka rozkładu należy użyć średniej. Jeśli dane zawierają niezwykle duże lub niezwykle małe wartości, do opisania środka rozkładu należy użyć mediany. Jeżeli dane są czysto kategoryczne lub jakościowe, należy zastosować dominantę; arytmetyka nie jest możliwa. Jeśli jednak dane są porządkowe, można również użyć mediany. "],["średnia-arytmetyczna-i-odchylenie-standardowe.html", "3.22 Średnia arytmetyczna i odchylenie standardowe", " 3.22 Średnia arytmetyczna i odchylenie standardowe 3.22.1 Podstawowe formuły Lp. Szereg (rozkład) szczegółowy (dane nieuporządkowane) Dane - częstości względne lub absolutne Szereg rozdzielczy (rozkład częstości) 1 \\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\\] \\(n\\) = liczba obserwacji; \\[S^2(X) = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\] \\[S(X) = \\sqrt{S^2(X)}\\] Częstości absolutne - \\(f_i\\) lub \\(n_i\\) \\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{k}x_if_i\\] \\(n\\) = liczba obserwacji; \\(k\\) = liczba wyróżnionych wartości. \\[S^2(X) = \\frac{1}{n}\\sum_{i=1}^{k}(x_i - \\bar{x})^2f_i\\] \\[S(X) = \\sqrt{S^2(X)}\\] lub (gdy mamy częstości absolutne możemy obliczyć odpowiednie proporcje) \\[\\bar{x} = \\sum_{i=1}^{k}x_ip_i\\] \\[S^2(X) = \\sum_{i=1}^{k}(x_i - \\bar{x})^2p_i\\] \\[S(X) = \\sqrt{S^2(X)}\\] 2 - Dane są tylko częstości względne (proporcje, frakcje) - \\(p_i = \\frac{f_i}{n}\\) \\[\\bar{x} = \\sum_{i=1}^{k}x_ip_i\\] \\(n\\) = liczba obserwacji; \\(k\\) = liczba wyróżnionych wartości \\[S^2(X) = \\sum_{i=1}^{k}(x_i - \\bar{x})^2p_i\\] \\[S(X) = \\sqrt{S^2(X)}\\] 3.22.2 Parametry populacji i statystyki (estymatory) z próby - podstawowe symbole Populacja (Population - P) Próba (Sample - S) średnia \\(E(X)\\), \\(\\mu_X\\), \\(m_X\\) \\(\\bar{X}\\) odchylenie standardowe \\(\\sigma_X\\) \\(s_X\\), \\(S(X)\\) wariancja \\(\\sigma^2_X\\), \\(Var_X\\) \\(s^2_X\\), \\(S^2(X)\\) proporcja (frakcja, częstość względna) \\(p_X\\), \\(P(X)\\) \\(\\hat{p}_X\\) mediana \\(Md_X\\) \\(\\hat{Md}_X\\) dominanta \\(Mo_X\\) \\(\\hat{Mo}_X\\) Popularne symbole statystyczne stosowane do oznaczania ważnych miar statystycznych "],["obliczanie-średniej-wariancji-i-odchylenia-standardowego.html", "3.23 Obliczanie średniej, wariancji i odchylenia standardowego", " 3.23 Obliczanie średniej, wariancji i odchylenia standardowego Dla następującego zbioru nieuporządkowanych danych: \\(A = \\{1, 2, 1, 10, 12\\}\\), policz wartość średnią (wartość oczekiwaną) i odchylenie standardowe. Korzystamy z wzorów z tablicy 1.2. Obliczamy średnią arytmetyczną: \\[\\bar{x} = \\frac{1}{5}\\sum_{i=1}^{5}x_i = \\frac{1+2+1+10+12}{5} = 5.2\\] Następnie wyznaczamy wariancję: \\[S^2(X) = \\frac{1}{5}\\sum_{i=1}^{5}(x_i - 5.2)^2 = \\frac{(1-5.2)^2 + (2-5.2)^2 + (1-5.2)^2 + (10-5.2)^2 + (12-5.2)^2}{5} = 22.96\\] I liczymy odchylenie standardowe: \\[S(X) = \\sqrt{22.96} = 4.79\\] Dane nieuporządkowane ze zbioru \\(A\\) można przedstawić w postaci rozkładu częstości (szereg rozdzielczy). \\(i\\) \\(x_i\\) \\(f_i\\) \\(p_i\\) 1 1 2 2/5 2 2 1 1/5 3 10 1 1/5 4 12 1 1/5 Rozkład częstości \\(f_i\\) = częstości bezwzględne \\(p_i\\) = częstości względne/prawdopodobieństwa empiryczne/proporcje/wagi Dla tak jak w tabeli przedstawionych danych, średnią i odchylenie standardowe można policzyć trochę innym sposobem: \\[\\bar{x} = \\sum_{i=1}^{4}x_ip_i = 1*\\frac{2}{5}+2*\\frac{1}{5}+10*\\frac{1}{5}+12*\\frac{1}{5} = 5.2\\] \\[S^2(X) = \\sum_{i=1}^{4}(x_i - 5.2)^2*p_i = (1-5.2)^2*\\frac{2}{5} + (2-5.2)^2*\\frac{1}{5} + (10-5.2)^2*\\frac{1}{5} + (12-5.2)^2*\\frac{1}{5} = 22.96\\] \\[S(X) = \\sqrt{22.96} = 4.79\\] Tabela 1.4 zawiera szereg szczegółowy danych na temat wynagrodzeń w Polsce, w dwóch, losowo wybranych, grupach osób (w tysiącach złotych) (zmienne X i Y). \\[table:tally\\] i \\(x_i\\) \\(y_i\\) 1 1 4 2 3 3 3 4 3 4 5 4 5 3 5 6 4 3 7 6 3 8 5 4 9 4 5 10 2 3 11 1 2 12 3 3 \\(\\Sigma\\) 42 42 Szereg szczegółowy dla zmiennych X i Y Oblicz wartość średnią (wartość oczekiwaną) (oznaczamy \\(E(X)\\) lub \\(\\mu\\) dla populacji i \\(\\bar{x}\\) dla próby) dla zarobków w każdej próbie. Ponadto wyznacz wariancję i odchylenie standardowe zmiennych X i Y. Dane na tym etapie są nieuporządkowane (szereg szczegółowy), więc korzystamy z następujących wzorów: \\[E(X) = \\bar{x} = \\frac{1}{n}(\\sum_{i=1}^{n}x_i)\\] \\[E((X - \\bar{X})^2) = S^2(X) = \\frac{1}{n}(\\sum_{i=1}^{n}(x_i - \\bar{x})^2)\\] \\[S(X) = \\sqrt{S^2(X)}\\] gdzie: \\(n\\) = liczba obserwacji Przedstaw dane dla zmiennej \\(X\\) z tabeli 1.2 w postaci szeregu rozdzielczego punktowego (rozkład częstości) i ponownie wyznacz średnią i odchylenie standardowe. Po przekształceniu zbioru danych w szereg rozdzielczy wzory trzeba zmodyfikować: \\[E(X) = \\bar{x} = \\frac{1}{n}(\\sum_{i=1}^{k}x_if_i)\\] \\[E((X - \\bar{X})^2f_i) = S^2(X) = \\frac{1}{n}(\\sum_{i=1}^{k}(x_i - \\bar{x})^2f_i)\\] \\[S(X) = \\sqrt{S^2(X)}\\] gdzie: \\(n\\) = liczba obserwacji; \\(k\\) = liczba wyróżnionych wartości/wierszy Stosując wzory, zawsze pamiętaj o kolejności wykonywania działań: Kolejność jest następująca: działania w nawiasach potęgowanie i pierwiastkowanie mnożenie i dzielenie dodawanie i odejmowanie Warto pamiętać, że dzielenie zawsze można zastąpić mnożeniem przez odwrotność. \\[table:tally\\_comp\\] i \\(x_i\\) \\(x_i - \\bar{x}\\) \\((x_i - \\bar{x})^2\\) 1 1 -2.5 6.25 2 3 -0.5 0.25 3 4 0.5 0.25 4 5 1.5 2.25 5 3 -0.5 0.25 6 4 0.5 0.25 7 6 2.5 6.25 8 5 1.5 2.25 9 4 0.5 0.25 10 2 -1.5 2.25 11 1 -2.5 6.25 12 3 -0.5 0.25 \\(\\Sigma\\) 42 0 27 Obliczenia pomocnicze dla \\(\\bar{x}\\) i \\(S(X)\\) Zobacz tabelę 1.2, w której znajdują się potrzebne wzory. Obliczenia pomocnicze przedstawiono w tabelach 1.5 (szereg szczegółowy) i 1.7 (szereg rozdzielczy). Odpowiedź: Wartość przeciętna wynosi \\(\\bar{x} = 42/12 = 3.5\\), a średnie odchylenie obserwacji w zbiorze danych względem średniej \\(S(X)\\) jest równe \\(\\sqrt{27/12} = 1.5\\) tysiąca złotych (1500 zł). Tabela 1.6 przedstawia dane z tabeli 1.4 w postaci szeregu rozdzielczego, gdzie \\(f_i\\) oznacza bezwzględną częstość występowania. Dane statystyczne są czasami przedstawione w postaci szeregu szczegółowego, czyli tak jak w tabeli 1.4, a czasami w postaci szeregu rozdzielczego, który powstaje z szeregu szczegółowego po uporządkowaniu danych. \\[table:freq\\_X\\] i \\(x_i\\) \\(f_i\\) 1 1 2 2 2 1 3 3 3 4 4 3 5 5 2 6 6 1 \\(\\Sigma\\) - 12 Szereg rozdzielczy dla X W tabeli, 1.6 dane z tabeli 1.4 zostały przedstawione po przekształceniu do postaci szeregu rozdzielczego punktowego. Sposób prezentacji danych nie zmienia wartości wskaźników takich jak średnia arytmetyczna lub wariancja, ale sposób liczenia może ulec zmianie - odpowiednie wzory znajdziesz w tabeli 1.2. \\[table:freq\\_comp\\] i \\(x_i\\) \\(f_i\\) \\(x_if_i\\) \\(p_i\\) \\((x_i-\\bar{x})^2\\) \\((x_i-\\bar{x})^2 * p_i\\) \\((x_i-\\bar{x})^2 * f_i\\) 1 1 2 2 2/12 6.25 1.04 12.5 2 2 1 2 1/12 2.25 0.19 2.25 3 3 3 9 3/12 0.25 0.06 0.75 4 4 3 12 3/12 0.25 0.06 0.75 5 5 2 10 2/12 2.25 0.38 4.5 6 6 1 6 1/12 6.25 0.52 6.25 \\(\\Sigma\\) - 12 42 1 - 2.25 27 Obliczenia pomocnicze \\(\\bar{x}\\) i \\(S(X)\\) Odpowiedź: Wartość przeciętna wynosi \\(\\bar{x} = 42/12 = 3.5\\), a średnie odchylenie obserwacji w zbiorze danych wokół średniej \\(S(X)\\) jest równe \\(\\sqrt{27/12} = 1.5\\) tysiąca złotych (1500 zł). Po wykonaniu obliczeń w zadaniach ze statystyki, zawsze należy podać odpowiedź słowną i zinterpretować wyniki. "],["dominanta.html", "3.24 Dominanta", " 3.24 Dominanta Dominantą lub wartością modalną nazywamy najczęściej występującą wartość liczbową. Oblicz dominantę liczb: 2, 2, 2, 6, 6, 6. W tym przypadku wartość modalna (moda) nie istnieje. "],["miary-pozycyjne-kwartyle-mediana-oraz-rozstęp-międzykwartylowy.html", "3.25 Miary pozycyjne - kwartyle, mediana oraz rozstęp międzykwartylowy", " 3.25 Miary pozycyjne - kwartyle, mediana oraz rozstęp międzykwartylowy Średnia arytmetyczna jest tzw. klasyczną miarą tendencji centralnej. Stosowana jest ona często, ale dla niektórych zmiennych nie można jej wyznaczyć (zmienne mierzone na skalach jakościowych - nominalnej lub porządkowej), a ponadto, czasami jej wartości mogą być mylące (np. gdy liczymy średni dochód mieszkańców danego państwa). W niektórych przypadkach, lepszymi miarami tendencji centralnej są miary pozycyjne takie jak mediana. Mediana to wartość cechy w szeregu uporządkowanym, powyżej i poniżej której znajduje się jednakowa liczba obserwacji. Mediana jest kwantylem rzędu 1/2, czyli drugim kwartylem. Jeżeli mamy wyznaczyć medianę jakiegoś zbioru liczb, to musimy najpierw wypisać te liczby w kolejności niemalejącej, a następnie wybrać liczbę środkową (w przypadku gdy mamy nieparzystą liczbę liczb w zbiorze). Jeżeli mamy parzystą liczbę elementów w zbiorze, to mediana jest równa średniej arytmetycznej dwóch środkowych liczb. Np., dla ciągu \\(1, 2, 4, 6, 8, 9\\), mediana wynosi: \\(\\frac{4+6}{2} = 5\\) Mediana to tzw. drugi kwartyl (\\(Q_2\\)). Kwartyle dzielą zbiór danych na 4, równe, części w następujący sposób: Dla ciągu \\((3, \\textbf{4}, 4, \\textbf{5}, 6, \\textbf{8}, 8)\\), liczba 5 to mediana, pierwsza 4 to pierwszy kwartyl \\(Q_1\\), a pierwsza 8 to trzeci kwartyl \\(Q_3\\). 3.25.1 Kwartyle Wyznaczając kwartyle (\\(Q\\)), należy obserwacje uporządkować niemalejąco/nierosnąco. A = {2, 4, 4, 5, 6, 7, 8} \\(Q_1 = 4\\) \\(Q_2 (mediana) = 5\\) \\(Q_3 = 7\\) A = {1, 3, 3, 4, 5 | 6, 6, 7, 8, 8} \\(Q_1 = 3\\) \\(Q_2 (mediana) = (5+6)/2 = 5.5\\) \\(Q_3 = 7\\) "],["rozstęp-międzykwartylowy.html", "3.26 Rozstęp międzykwartylowy", " 3.26 Rozstęp międzykwartylowy \\(IQR = Q_3 - Q_1\\) Wartości nietypowe (outliers) to wszystkie zaobserwowane wartości zmiennej, które nie należą do przedziału: \\[[Q_1 - 1.5 \\times IQR, Q_3 + 1.5 \\times IQR]\\] Rozstępem międzykwartylowym (IQR) nazywamy różnicę \\(Q_3 - Q_1\\) Oblicz medianę liczb: 1, -1, 6, 6, 8, 10, 5 Rozwiązanie: Najpierw wypisujemy liczby w kolejności niemalejącej: \\[-1, 1, 5, 6, 6, 8, 10\\] Mediana to liczba środkowa i jest równa 6. Oblicz dominantę liczb: -7, 2, 3, -7, 3, 4, 5. W tym przypadku mamy dwie dominanty: -7 oraz 3. Obie liczby występują dwa razy. Oblicz średnią i medianę dla danych o dochodach netto zgromadzonych w tabeli, dla dwóch przypadkowo wybranych grup ludzi. Porównaj wyniki. Która miara tendencji centralnej lepiej opisuje przeciętne dochody netto? \\[my-label\\] Lp. X Y 1 1 2,5 2 1 3,2 3 1,5 3,5 4 2 3,5 5 2 4 6 2,5 4,2 7 2,8 4,5 8 10 4,5 9 30 5 Dla przykładu 1 z sekcji 1.3 wyznacz dla zmiennych X i Y medianę i dominantę. "],["miary-pozycji-względnej.html", "3.27 Miary pozycji względnej", " 3.27 Miary pozycji względnej 3.27.1 Percentyl i pozycja/ranga percentylowa (centylowa) System percentyli jest szeroko stosowany do pokazania, jak dana osoba radziła sobie w stosunku do grupy odniesienia. Opiera się na skumulowanym rozkładzie procentowym. Percentyl to punkt na skali pomiaru, poniżej którego znajduje się określony procent obserwacji w rozkładzie. Powszechnie nazywany jest percentylem. Jeśli na przykład 50% studentów na kierunku historia ma wyniki niższe niż 81, 50. percentyl to 81. Ranga percentylowa to odsetek przypadków, które wypadają poniżej danego punktu na skali pomiaru. W naszym przykładzie ranga percentylowa wyniku 81 wynosi 50. Nie myl centyli z rangami centylowymi: rangi percentylowe mogą przyjmować wartości tylko z zakresu od 0 do 100, podczas gdy percentyl (punkt) może mieć dowolną wartość, jaką mogą mieć wyniki. Na przykład możliwe jest, że wartość percentyla wynosi 143. Załóżmy, że Maria uzyskała wynik 143 na teście wstępnym do college’u, a 75% kandydatów uzyskało wynik niższy. 75. percentyl to 143; Ranga percentylowa Mary wynosi 75. Standaryzowane testy, takie jak SAT (Scholastic Aptitude Test) i GRE (Graduate Record Exam), publikują swoje wyniki w postaci percentyli lub rang percentylowych. 3.27.2 Wynik standardowy (z-score, standaryzacja zmiennych) W statystyce wynik standardowy to liczba odchyleń standardowych, o które zaobserwowany punkt danych różni się od średniej wartości tego, co jest obserwowane lub mierzone. Surowe wyniki powyżej średniej mają pozytywne wyniki standardowe, podczas gdy te poniżej średniej mają ujemne wyniki standardowe. Oblicza się ją, odejmując średnią populacji od indywidualnego surowego wyniku, a następnie dzieląc różnicę przez odchylenie standardowe populacji. Ten proces zamiany wyniku surowego na wynik standardowy nazywa się standaryzacją lub normalizacją. Jednak „normalizowanie\" może odnosić się do wielu typów przekształceń; na przykład unitaryzacja służy do sprowadzenia wszystkich wartości do zakresu [0,1]. Można to uogólnić, aby ograniczyć zakres wartości w zbiorze danych między dowolnymi punktami a i b. 3.27.2.1 Z-score jako miara względnej pozycji Z-score dla obserwacji to liczba odchyleń standardowych, o jaką różni się ona od średniej. Dodatni wynik z wskazuje, że obserwacja jest powyżej średniej. Ujemny wynik z wskazuje, że obserwacja jest poniżej średniej. Z-score jest obliczany jako: \\[\\text{z-score}_X = \\frac{x_i - \\mu_X}{\\sigma_X} = \\frac{\\text{value} - \\text{mean}}{\\text{standard deviation}}\\] Reguła empiryczna mówi nam, że dla rozkładu w kształcie dzwonu niezwykłe jest, aby obserwacja różniła się o więcej niż 3 odchylenia standardowe od średniej. Obserwacja w rozkładzie dzwonowym jest uważana za potencjalną wartość odstającą (wartość nietypową), jeśli spada o więcej niż 3 odchylenia standardowe od średniej. Z-score pozwala nam szybko powiedzieć, jak zaskakująca lub ekstremalna jest obserwacja. Z-score konwertuje obserwację (niezależnie od jednostki miary obserwacji) na wspólną skalę pomiaru, która umożliwia porównania (jednostką tej nowej skali staje się odchylenie standardowe). Ponadto, z-score może być wykorzystany do konstrukcji testów statystycznych (testowanie hipotez). "],["wizualizacja-rozkładów-danych-histogramy-i-wykresy-pudełkowe.html", "3.28 Wizualizacja rozkładów danych (histogramy i wykresy pudełkowe)", " 3.28 Wizualizacja rozkładów danych (histogramy i wykresy pudełkowe) 3.28.1 Ważne typy wykresów statystycznych: wykres słupkowy (bar plot) - wizualizuje rozkład obserwacji dla danych nominalnych lub porządkowych, histogram (dla częstości bezwzględnych, względnych i dla tzw. gęstości [ang. density] - tylko dla danych ilościowych, wykres pudełkowy (box plot) - tylko dla danych ilościowych. "],["wykres-słupkowy.html", "3.29 Wykres słupkowy", " 3.29 Wykres słupkowy # Rysowanie wykresu słupkowego z użyciem języka R knitr::opts_chunk$set(fig.width=4, fig.height=4) # Ustawienia wyświetlania library(ggplot2) # Ładowanie pakietu funkcji data = data.frame( x = c(1,1,5,5,5,5,5,3,3,3,3,4,4,5) ) # Wektor danych barplot &lt;- ggplot(data = data) + geom_bar( aes(x = x), stat = &quot;count&quot; ) # Funkcja pakietu ggplot2 tworząca wykres słupkowy "],["wykres-słupkowy-2.html", "3.30 Wykres słupkowy (2)", " 3.30 Wykres słupkowy (2) # Rysowanie wykresu słupkowego z użyciem języka R print(barplot) "],["wykres-słupkowy-3.html", "3.31 Wykres słupkowy (3)", " 3.31 Wykres słupkowy (3) knitr::include_graphics(rep(&#39;images/refugee_count.svg&#39;, 2)) Źródło: Eurobarometer 87.3 "],["wykres-słupkowy-4.html", "3.32 Wykres słupkowy (4)", " 3.32 Wykres słupkowy (4) Źródło: Eurobarometer 87.3 "],["szereg-rozdzielczy-i-histogram.html", "3.33 Szereg rozdzielczy i histogram", " 3.33 Szereg rozdzielczy i histogram Histogram wykreślamy na podstawie danych z szeregu rozdzielczego z przedziałami: Lp. Przedział klasowy (bin) \\(h_k\\) dla \\(x_i\\) Częstość \\(f_i\\) Częstość względna (frakcja) \\(p_i = f_i/n\\) Gęstość \\(d_i = p_i/\\Delta x_i\\) 1 [1, 6) 12 12/120 = 0.1 0.1/(6 - 1) = 0.02 2 [6, 11) 6 0.05 0.01 … … … … … 20 [96, 101) 3 0.025 0.005 \\(\\Sigma\\) - \\(n\\) = 120 1 - "],["histogram.html", "3.34 Histogram", " 3.34 Histogram Podobnie jak wykresy słupkowy i kropkowy, histogram ilustruje rozkład obserwacji i wskazuje na poziom rozproszenia danych. 3.34.0.1 Używa się trzech typów histogramów: histogram częstości bezwzględnych (należy używać tylko w uzasadnionych przypadkach); histogram częstości względnych - suma wysokości wszystkich słupków jest równa 1 (lub 100%); histogram gęstości (tzw. prawdziwy histogram) - suma pól powierzchni wszystkich słupków równa jest 1 (lub 100%). "],["histogram-gęstości.html", "3.35 Histogram gęstości", " 3.35 Histogram gęstości "],["konstrukcja-histogramu-gęstości.html", "3.36 Konstrukcja histogramu gęstości", " 3.36 Konstrukcja histogramu gęstości # Rysowanie histogramu z użyciem języka R knitr::opts_chunk$set(fig.width=4, fig.height=4) # Ustawienia wyświetlania library(lattice) # Ładowanie pakietu funkcji data = c(140,145,200,325,320,285,283,280,248,246,242,240,240,204,201) # Wektor danych histogram &lt;- histogram(data, nint = 5, type = &quot;density&quot;, endpoints = c(140, 340), right = F) # Tworzy histogram print(histogram) # Wyświetla histogram histogram$panel.args.common$breaks # Wyświetla krańce przedziałów klasowych ## [1] 140 180 220 260 300 340 "],["histogram-częstości-bezwzględnych.html", "3.37 Histogram częstości bezwzględnych", " 3.37 Histogram częstości bezwzględnych histogram &lt;- histogram(data, nint = 5, type = &quot;count&quot;) # Tworzy histogram print(histogram) # Wyświetla histogram "],["histogram-częstości-względnych.html", "3.38 Histogram częstości względnych", " 3.38 Histogram częstości względnych histogram &lt;- histogram(data, nint = 5, type = &quot;percent&quot;) # Tworzy histogram print(histogram) # Wyświetla histogram "],["histogram-dla-funkcji-prawdopodobieństwa-rozkład-dwumianowy-1.html", "3.39 Histogram dla funkcji prawdopodobieństwa - rozkład dwumianowy (1)", " 3.39 Histogram dla funkcji prawdopodobieństwa - rozkład dwumianowy (1) library(ggplot2) # Generujemy próbę. Z &lt;- seq(0,4,by = 1) # Dla próby obliczamy prawdopodobieństwa. P &lt;- dbinom(Z,4,0.25) binom_data &lt;- data.frame(Z, P) # Łączymy zmienne Z i P head(binom_data) ## Z P ## 1 0 0.31640625 ## 2 1 0.42187500 ## 3 2 0.21093750 ## 4 3 0.04687500 ## 5 4 0.00390625 "],["histogram-dla-funkcji-prawdopodobieństwa-rozkład-dwumianowy-2.html", "3.40 Histogram dla funkcji prawdopodobieństwa - rozkład dwumianowy (2)", " 3.40 Histogram dla funkcji prawdopodobieństwa - rozkład dwumianowy (2) # Rysyjemy rozkład ggplot(data = binom_data) + geom_bar( aes(x = Z, y = P), stat = &quot;identity&quot; ) "],["wykres-pudełkowy.html", "3.41 Wykres pudełkowy", " 3.41 Wykres pudełkowy Podobnie jak wykres słupkowy i histogram, wykres pudełkowy używany jest w celu prezentacji rozkładu danych. Ten typ wykresu ilustruje podstawowe cechy rozkładu danych i jest często używany, gdy badacze chcą sprawdzić jak na rozkład badanej zmiennej ilościowej wpływa jakaś zmienna jakościowa (lub dyskretna ilościowa) (np.: oczekiwane trwanie życia \\(\\sim\\) kontynent). "],["wykres-pudełkowy-przykład-1.html", "3.42 Wykres pudełkowy - przykład (1)", " 3.42 Wykres pudełkowy - przykład (1) # Rysowanie wykresu pudełkowego z użyciem języka R data &lt;- data.frame( men = c(143, 160, 165, 168, 172, 173, 175, 176, 177, 178, 179, 180, 180, 181, 181, 182, 182, 183, 183, 184, 186, 188, 190, 191, 200), women = c(140, 150, 155, 158, 160, 163, 163, 165, 166, 166, 168, 170, 170, 171, 172, 173, 173, 173, 175, 176, 177, 181, 182, 183, 196) ) # Zbiór danych head(data) # Wyświetla pierwsze wiersze zbioru danych ## men women ## 1 143 140 ## 2 160 150 ## 3 165 155 ## 4 168 158 ## 5 172 160 ## 6 173 163 library(dplyr) library(tidyr) # Pakiet funkcji przydatny do transformacji danych data &lt;- gather(data = data, key = &quot;plec&quot;, value = &quot;wzrost&quot;, men:women ) # Format szeroki danych --&gt; format długi danych head(data) ## plec wzrost ## 1 men 143 ## 2 men 160 ## 3 men 165 ## 4 men 168 ## 5 men 172 ## 6 men 173 box &lt;- ggplot(data = data) + geom_boxplot( aes( x = plec, y = wzrost ) ) + coord_flip() # Rysuje wykres pudełkowy print(box) # Wyświetla wykres "],["wykres-pudełkowy-przykład-2.html", "3.43 Wykres pudełkowy - przykład (2)", " 3.43 Wykres pudełkowy - przykład (2) Prawda/fałsz: Kobiety w badanej próbie są przeciętnie wyższe od mężczyzn (F); Wzrost mężczyzn jest bardziej rozproszony względem mediany (…); Najniższa osoba to kobieta (…); Oba zbiory danych ujawniają asymetrię lewostronną (…); Połowa kobiet mierzy co najmniej 170 cm (…). "],["histogram-a-wykres-pudełkowy-przykład-3.html", "3.44 Histogram a wykres pudełkowy - przykład (3)", " 3.44 Histogram a wykres pudełkowy - przykład (3) # Dla tych samych danych, dla porównania, rysujemy histogram i krzywe gęstości hist &lt;- ggplot(data = data) + geom_histogram( aes( x = wzrost, y = ..density.., fill = plec ), bins = 6, alpha = 0.7 ) + geom_density( aes( x = wzrost, y = ..density.., colour = plec ) ) + theme_classic() # Rysuje histogram print(hist) "],["wykres-pudełkowy-jeszcze-jeden-przykład.html", "3.45 Wykres pudełkowy - jeszcze jeden przykład", " 3.45 Wykres pudełkowy - jeszcze jeden przykład # Dla następujących danych, narysuj wykres pudełkowy X = c(215, 140, 290, 300, 300, 320, 330, 340, 415, 480) # Definiuje zbiór danych boxplot(X, horizontal = T) # Rysuje wykres "],["wykres-pudełkowy-a-histogram.html", "3.46 Wykres pudełkowy a histogram", " 3.46 Wykres pudełkowy a histogram "],["skośnośćasymetria-rozkładu-skewness-rozkłady-lewostronnie-i-prawostronnie-asymetryczne.html", "3.47 Skośność/asymetria rozkładu (skewness) - rozkłady lewostronnie i prawostronnie asymetryczne", " 3.47 Skośność/asymetria rozkładu (skewness) - rozkłady lewostronnie i prawostronnie asymetryczne "],["miary-korelacji.html", "3.48 Miary korelacji", " 3.48 Miary korelacji Ważne mierniki korelacji, których interpretację i warunki stosowania należy znać to: kowariancja i wskaźnik korelacji liniowej Pearsona (tylko dane ilościowe); wskaźnik korelacji rang Spearmana (dane mierzone na skali porządkowej); wskaźnik korelacji dla danych porządkowych Kendall \\(\\tau_b\\) (dane mierzone na skali porządkowej); test niezależności chi-kwadrat \\(\\chi^2\\) (dla danych nominalnych). Wszystkie spośród wskazanych wyżej mierników korelacji najłatwiej obliczyć wykorzystując oprogramowanie statystyczne takie jak język R. Dla przykładu przedstawiony zostanie tylko algorytm liczenia wskaźnika korelacji liniowej Pearsona. W przypadku pozostałych mierników, ich wartości obliczymy za pomocą języka R i podamy jak należy interpretować wyniki. Należy pamiętać, że wskaźnik korelacji liniowej ocenia siłę związku liniowego, jeżeli związek między zmiennymi ma kształt np. paraboliczny, to wartość wskaźnika będzie myląca. Innymi słowy, niska wartość wskaźnika nie musi implikować braku zależności. 3.48.1 Współczynnik korelacji liniowej \\(\\rho\\) Pearsona Aby policzyć wartość współczynnika korelacji, wpierw należy wyznaczyć tzw. kowariancję. Kowariancja, podobnie jak współczynnik korelacji liniowej Pearsona jest miarą siły liniowego związku między parą zmiennych. Przyjmijmy, że \\((X_1,Y_1),\\ldots,(X_n,Y_n)\\) jest dwuwymiarową (para X i Y) próbą losową. Kowariancja z próby \\(\\widehat \\sigma_{X,Y}\\), która jest estymatorem nieznanej wartości kowariancji z populacji, jest określona następująco (Przy obliczeniach najłatwiej skorzystać z formuły pierwszej od prawej): \\[\\widehat{\\mbox{Cov}}(X,Y) = \\frac{1}{n-1}\\sum_{i=1}^n\\left(X_i-\\overline X \\right)\\left(Y_i-\\overline Y \\right) = \\frac1{n-1}\\left[\\sum_{i=1}^n X_iY_i -\\frac1n\\left(\\sum_{i=1}^nX_i\\right)\\left(\\sum_{i=1}^nY_i \\right) \\right],\\] Współczynnik korelacji liniowej Pearsona definiuje się w następujący sposób: \\[\\widehat \\rho _{X,Y} =\\frac{\\widehat \\sigma_{X,Y}}{S_XS_Y},\\] gdzie \\(S_X\\) and \\(S_Y\\) są oszacowaniami odchyleń standardowych dla zmiennych \\(X\\) i \\(Y\\). Rozważmy \\(n=10\\) par \\((X,Y)\\) wartości: X-values: 4.9681, 2.1757, 3.47928, 2.2873, 1.7415, 4.0740, 2.3046, Y-values: 95.2380, 0.5249, 21.4913, 0.7289, 0.1404, 75.8636, 0.7781, X-values: 3.6008, 2.2666, 0.7241 Y-values: 28.2765, 0.6569, -0.0068 Dla tych danych, \\(\\sum X_i=27.622\\), \\(\\sum Y_i=223.692\\), \\(\\sum X_iY_i = 965.142\\). Zatem, \\[\\widehat\\sigma_{X,Y}=\\frac19\\left[965.142 -\\frac1{10}(27.622)(223.692)\\right]= 38.5844,\\] i \\[\\rho_{X,Y}=\\frac{38.5844 }{(1.2483)(35.0952)}=0.881.\\] Wartość współczynnika korelacji mieści się w przedziale domkniętym \\([-1, 1]\\). Im większa jego wartość bezwzględna, tym silniejsza jest zależność liniowa między zmiennymi. \\(\\rho_{xy} = 0\\) oznacza brak liniowej zależności między cechami, \\(rho_{xy} = 1\\) oznacza dokładną dodatnią liniową zależność między cechami, natomiast \\(rho_{xy} =-1\\) oznacza dokładną ujemną liniową zależność między cechami, tzn. jeżeli zmienna x rośnie, to y maleje i na odwrót. 3.48.1.1 Współczynnik korelacji rangowej \\(\\rho\\) Spearmana i \\(\\tau_b\\) Kendalla W przypadku zmiennych jakościowych (porządkowych lub nominalnych), nie są adekwatne metody analizy związku między zmiennymi, które stosuje się do badania cech ilościowych, czyli np. omawiany wskaźnik korelacji liniowej Pearsona. Dla przykładu, gdy badacza interesuje odpowiedź na pytanie, czy poziom religijności człowieka (zmienna jakościowa) wpływa jakoś na jego autoidentyfikację na skali lewica - prawica (zmienna jakościowa), to po pierwsze należy stworzyć definicje operacyjne pojęć “poziom religijności” oraz “skala lewica - prawica”, a następnie wybrać do pomiaru zależności między takimi zmiennymi miernik, który jest odpowiedni dla pomiaru zależności między zmiennymi porządkowymi. Na przykład, operacjonalizując wskazane pojęcia, można przyjąć założenie, że: pomiar religijności będzie polegał na odpowiedzi na pytanie: Jaki jest Pana/Pani stosunek do religii? Proszę wybrać jeden z poziomów na skali od 0 (nie jestem w ogóle religijny) do 10 (jestem bardzo religijny). Zmienną zakodujmy symbolem lr pomiar autoidentyfikacji na skali Lewica - Prawica będzie polegał na odpowiedzi na pytanie: Jak określiłby Pan/Pani swoje poglądy społeczno-polityczne na osi Lewica - Prawica? Proszę wybrać jeden z poziomów na skali od 0 (Lewica) do 10 (Prawica). Zmienną zakodujmy symbolem rel Przyjmijmy, że w próbie zaobserwowano następujące odpowiedzi. zmienna lr: 1, 1, 3, 3, 4, 5, 6, 6, 7, 8, 8, 8, 9, 10, 10, 1, 1, 2, 2, 3 zmienna rel: 1, 2, 4, 4, 3, 5, 5, 6, 8, 7, 7, 8, 10, 9, 9, 2, 2, 1, 2, 3 Oba wskaźniki przyjmują wartości z przedziału \\(-1, 1\\), przy czym wartości mniejsze od zera oznaczają korelację różnokierunkową, a dodatnie jednokierunkową. Im wyższa wartość bezwzględna wskaźników, tym korelacja silniejsza. Można przyjąć, że wartość wskaźnika przekraczająca, co do wartości bezwzględnej, \\(0.7\\) oznacza silną korelację. Do policzenia wskaźników wykorzystamy instrukcje języka programowania R. # Definiujemy zbiór danych lr &lt;- c(1, 1, 3, 3, 4, 5, 6, 6, 7, 8, 8, 8, 9, 10, 10, 1, 1, 2, 2, 3) rel &lt;- c(1, 2, 3, 4, 5, 5, 5, 6, 8, 8, 9, 10, 10, 9, 10, 4, 3, 6, 0, 2) # Wyznaczamy współczynnik korelacji rangowej rho Spearmana cor.test(lr, rel, method=&quot;spearman&quot;) # Wywołanie funkcji liczącej wskaźnik ## Warning in cor.test.default(lr, rel, method = &quot;spearman&quot;): Cannot compute exact p-value with ties ## ## Spearman&#39;s rank correlation rho ## ## data: lr and rel ## S = 162.64, p-value = 3.695e-07 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.8777174 # data: lr and rel # S = 162.64, p-value = 3.695e-07 # alternative hypothesis: true rho is not equal to 0 # sample estimates: # rho # 0.8777174 # Wyznaczamy współczynnik korelacji tau Kendalla cor.test(lr, rel, method=&quot;kendall&quot;) # Wywołanie funkcji liczącej wskaźnik ## Warning in cor.test.default(lr, rel, method = &quot;kendall&quot;): Cannot compute exact p-value with ties ## ## Kendall&#39;s rank correlation tau ## ## data: lr and rel ## z = 4.3882, p-value = 1.143e-05 ## alternative hypothesis: true tau is not equal to 0 ## sample estimates: ## tau ## 0.7535683 # data: lr and rel # z = 4.3882, p-value = 1.143e-05 # alternative hypothesis: true tau is not equal to 0 # sample estimates: # tau # 0.7535683 Raport, który język R drukuje po wywołaniu instrukcji corr.test można zinterpretować następująco. Po pierwsze, R zwraca wartości wskaźników korelacji \\(\\rho\\) i \\(\\tau\\), które odpowiednio wynoszą, w przybliżeniu: 0.88 i 0.75, czyli wskazują silną korelację dodatnią (jednokierunkową). Ponadto, R zwraca tzw. p-value. Pojęcie p-wartości (p-value) lub tzw. prawdopodobieństwa testowego nie będzie tutaj wyjaśniane, ale trzeba zapamiętać, że, zwykle, gdy p-wartość przyjmuje wartość co najmniej 0.05 (jest to tzw. poziom istotności testu weryfikującego tzw. hipotezę zerową), to wówczas uprawdopodabnia się prawdziwość tzw. hipotezy alternatywnej, która zakłada, że prawdziwa wartość wskaźnika korelacji (\\(\\tau\\) lub \\(\\rho\\)) jest istotnie różna od zera (istotna statystycznie). Co to oznacza? Otóż, jednym z działów wnioskowania statystycznego (statystyka matematyczna) jest tzw. testowanie hipotez statystycznych. Testuje się układ dwóch hipotez (zerową i alternatywną): np. wartość wskaźnika korelacji \\(\\rho\\) jest równa 0 (nieistotna) np. wartość wskaźnika korelacji \\(\\rho\\) jest istotnie różna od zera (istotna statystycznie) Zagadnienie testowania hipotez będzie omówione dalej, ale na tym etapie należy pamiętać, że p-value wskazuje, czy możemy odrzucić hipotezę zerową. Jeżeli H0 jest odrzucana, to wówczas można stwierdzić, że uogólnienie wartości wskaźnika korelacji obliczonego na podstawie próby, na jego wartość w populacji jest uprawnione - tak właśnie jest w powyższym przykładzie, gdyż wartość prawdopodobieństwa testowego jest mniejsza od 0.05. 3.48.2 Test niezależności chi-kwadrat \\(\\chi^2\\) Test niezależności chi-kwadrat jest relatywnie prostą metodą weryfikowania istotności związku między zmiennymi mierzonymi na skali nominalnej. Załóżmy, że chcemy zbadać zależność między zmienną identyfikacja z partią polityczną i zmienną stosunek do demokracji. Wskazane zmienne to zmienne jakościowe, przy czym zmienna identyfikacja z partią jest zmienną nominalną, a zmienna stosunek do demokracji może być potraktowana jako zmienna nominalna lub porządkowa (gdy przyjmiemy, że w zbiorze wszystkich wartości zmiennej można określić relację porządku). Ponieważ co najmniej jedna ze zmiennych jest zmienną nominalną, to musimy użyć metody, która jest adekwatna do badania związków między zmiennymi tego typu. Jedną z nich jest test niezależności \\(\\chi^2\\). Można by też użyć wielomianowej regresji logistycznej, ale jest to metoda zbyt skomplikowana, aby omawiać ją w trakcie podstawowego kursu statystyki. Przeprowadzenie testu chi-kwadrat wymaga utworzenia tzw. tabeli kontyngencji (tabeli krzyżowej). Tabela kontyngencji przedstawia zależność między dwiema zmiennymi. Dla przykładu: Załóżmy, że przebadano wyborców, którzy deklarowali identyfikację z jedną z dwóch głównych partii politycznych w Polsce (PO lub PiS) w kontekście ich stosunku do demokracji. Tak więc, mamy dwie zmienne jakościowe w bazie danych zawierającej wyniki (dwie kolumny danych): 1) Partia polityczna (PO albo PiS); 2) Stosunek do demokracji (Demokracja jest najlepszą formą rządów, …). Następnie budujemy tabelę krzyżową podsumowującą związek miedzy tymi zmiennymi. Czy w świetle danych z próby istnieje istotna statystycznie zależność między stosunkiem do demokracji i identyfikacją z partią? Aby to sprawdzić, trzeba policzyć wartość tzw. statystyki testowej chi-kwadrat i zweryfikować, czy hipotezę, że zależność między zmiennymi jest nieistotna w sensie statystycznym można odrzucić. Demokracja jest najlepszą formą rządów Są lepsze formy rządów Forma rządów jest nieistotna Nie mam zdania \\(f_j\\) 35 17 39 9 59 24 14 3 \\(f_i\\) 94 41 53 12 \\(\\Sigma f_{ij} =\\) Stosunek do demokracji a identyfikacja z PO lub PIS - dane z fikcyjnej próby Polaków Procedura testu chi-kwadrat przedstawiona będzie w wykładzie dotyczącym testowania hipotez statystycnzych. "],["wykład-4-podstawy-rachunku-prawdopodobieństwa-wersja-robocza-0-3.html", "4 Wykład 4. Podstawy rachunku prawdopodobieństwa [wersja robocza, 0.3] ", " 4 Wykład 4. Podstawy rachunku prawdopodobieństwa [wersja robocza, 0.3] "],["wprowadzenie.html", "4.1 Wprowadzenie", " 4.1 Wprowadzenie 4.1.1 Podstawowe spójniki logiczne Negacja, oznaczamy \\(\\sim\\), Alternatywa (suma logiczna), oznaczamy \\(\\vee\\), Koniunkcja (iloczyn logiczny), oznaczamy \\(\\wedge\\), Implikacja, oznaczamy symbolem \\(\\Longrightarrow\\) lub \\(\\longrightarrow\\), np. \\(p \\longrightarrow q\\), czytamy \\(p\\) implikuje \\(q\\), Równoważność, oznaczamy \\(\\Longleftrightarrow\\). 4.1.2 Zbiory Zbiory są oznaczane nawiasami klamrowymi \\(\\{ \\}\\), na przykład \\(A = \\{0, 1\\}\\). Zbiór jest dowolną kolekcją składającą się z dobrze określonych i rozróżnialnych elementów. Zbiory oznaczamy wielkimi literami alfabetu, np. \\(A, B, C,\\) natomiast elementy zbioru małymi literami, np. \\(x, y, z\\). Elementy zbioru wypisujemy w nawiasach klamrowych, np. \\(A = \\{1, 2, 3, 4, ...\\}\\) lub \\(X = \\{x \\in N: x &gt; 5\\}\\). Zbiór jednoelementowy nazywamy singletonem, a zbiór dwuelementowy, np. \\(\\{a, b\\}\\) parą nieuporządkowaną. Zbiory \\(\\{a, b\\}\\) i \\(\\{b, a\\}\\) są równe, gdyż w przypadku zbiorów kolejność występowania elementów nie jest istotna. Zbiór \\(\\{a, b\\}\\) należy odróżnić od ciągu \\(\\langle a, b \\rangle\\). Ciągi \\(\\langle a, b \\rangle\\) i \\(\\langle b, a \\rangle\\) są różne i dlatego ciąg dwuelementowy można nazwać parą uporządkowaną. Jeśli element \\(x\\) należy do zbioru \\(X\\) to piszemy \\(x \\in X\\). Dwa zbiory są równe, jeśli zawierają dokładnie te same elementy. Zbiór, który nie zawiera żadnych elementów, nazywany jest zbiorem zerowym lub zbiorem pustym, \\(\\emptyset\\) lub \\(\\{\\}\\). Jeśli każdy element w zbiorze A jest również w zbiorze B, to zbiór A jest podzbiorem zbioru B. Jeżeli a jest elementem (należy do) zbioru A, to wówczas piszemy symbolicznie: \\(a \\in A\\), natomiast, gdy chcemy wskazać, że a nie należy do zbioru A, to napiszemy \\(a \\notin A\\). Zbiór lub podzbiór liczb rzeczywistych \\(R\\) może być wyrażony jako przedział \\((-\\infty, \\infty)\\). Przedział (oznaczony nawiasami zwykłymi) to zbiór liczb rzeczywistych z tą właściwością, że każda liczba znajdująca się między dwiema liczbami w zbiorze jest również zawarta w tym zbiorze. Przedział liczb między a i b, zawierający liczby a i b, jest często oznaczany jako \\([a, b]\\) (nawias kwadratowy). Te dwie liczby nazywane są punktami końcowymi przedziału. Singleton to zbiór zawierający dokładnie jeden element. UWAGA: W kontekście rachunku prawdopodobieństwa, upewnij się, że rozumiesz różnicę między wynikiem (an outcome) -8 a zdarzeniem (an event) {- 8}, które jest zbiorem składającym się z pojedynczego wyniku −8. **Liczność* (lub rozmiar) zbioru \\(A\\), oznaczona \\(|A|\\), to liczba elementów zbioru. Ta liczba może być skończona lub nieskończona. Zbiór skończony to zbiór, który ma skończoną liczbę elementów. Innymi słowy, jest to albo zbiór pusty, singleton lub zbiór, którego elementy można wymienić w postaci \\({a1, a2, . . . , an}\\) dla \\(n \\in N\\). Zbiór, który nie jest skończony, nazywany jest nieskończonym. Te zbiory mają więcej niż \\(n\\) elementów dla dowolnej liczby całkowitej \\(n\\). Podstawowe zbiory liczbowe: zbiór liczb naturalnych \\(N = \\{0, 1, 2, 3, ...\\}\\), zbiór liczb naturalnych dodatnich \\(N^{+} = \\{1, 2, 3, ...\\}\\), zbiór liczb całkowitych \\(Z = \\{..., -2, -1, 0, 1, 2, 3, ...\\}\\), zbiór liczb wymiernych \\(Q =\\) wszystkie liczby, które możemy przedstawić w postaci ułamka zwykłego \\(\\frac{p}{q}\\) i \\(q\\) jest różne od \\(0\\), zbiór liczb niewymiernych \\(NQ =\\) wszystkie ułamki, które mają rozwinięcie dziesiętne nieskończone i nieokresowe, np. liczba \\(\\pi \\approx 3,141592...\\), lub liczba oznaczana literą \\(e \\approx 2,718...\\), zbiór liczb rzeczywistych \\(R = Q + NQ\\). 4.1.2.1 Zbiory przeliczalne i nieprzeliczalne Bardzo ważne jest rozróżnienie między zbiorami nieskończonymi, ale przeliczalnymi, a zbiorami nieskończonymi, ale nieprzeliczalnymi. Co to oznacza? W przypadku zbiorów przeliczalnych, ich wszystkie elementy możemy ponumerować liczbami naturalnymi. Jednakże, istnieją zbiory, np. zbiór liczb niewymiernych, zbiór liczb R, które są bardziej liczne od zbioru liczb naturalnych, dlatego nie jest możliwe, aby ich elementy ponumerować liczbami 1, 2, 3, 4, …, n. Niezależnie od tego, czy są one skończone, czy nieskończone, elementy zbioru policzalnego można zawsze policzyć pojedynczo i, chociaż liczenie może nigdy się nie zakończyć, każdy element zbioru jest powiązany z liczbą naturalną. Zbiory policzalne stanowią podstawę gałęzi matematyki zwanej matematyką dyskretną. Tabela 1.1. Terminologia teorii zbiorów i teorii prawdopodobieństwa (analogie) Teoria zbiorów Prawdopodobieństwo Zbiór Zdarzenie Uniwersum Przestrzeń zdarzeń elementarnych Element Zdarzenie elementarne (Outcome, simple event) Tabela 1.2. Terminologia rachunku prawdopodobieństwa oparta na teorii zbiorów - Język zdarzeń \\(A\\) Zaszło zdarzenie A \\(A^c\\) Zaszło zdarzenie przeciwne do A \\(A \\cup B\\) Zrealizowało się zdarzenie A lub B (suma zdarzeń) \\(A \\cap B\\) Zaszło zdarzenie A i B (iloczyn zdarzeń) Zbiór, którego nie można policzyć, nazywany jest zbiorem niepoliczalnym (lub zbiorem niepoliczalnie nieskończonym, lub zbiorem ciągłym). Zawiera zbyt wiele elementów, aby można je było policzyć, np. przedział o dodatniej długości: \\([0, 1]\\). 4.1.3 Podstawowe działania na zbiorach (zdarzeniach) Na zbiorach można wykonywać różne działania. Przede wszystkim, definiujemy: sumę (\\(A\\cup B\\)), iloczyn lub przekrój (\\(A\\cap B\\)), różnicę zbiorów (\\(B \\setminus A\\)). Niech X będzie ustalonym zbiorem. Dopełnieniem zbioru \\(A \\subseteq U\\) do przestrzeni (uniwersum) \\(U\\) nazywamy zbiór \\(A^c = U \\setminus A\\). Ponadto, zbiory rozłączne można przedstawić następująco: Zbiory rozłączne Np. dla zbiorów \\(A = \\{\\emptyset\\} \\text{ i } B = \\{\\{\\emptyset\\}\\}\\) powiemy, że zbiór \\(A \\in B\\) Zbiór \\(A\\) jest podzbiorem zbioru (zawiera się w zbiorze) \\(B\\), wtedy i tylko wtedy, gdy każdy element zbioru \\(A\\) jest jednocześnie elementem zbioru \\(B\\) (należy do zbioru B). Piszemy wtedy \\(A \\subseteq B\\). A zawiera się w B Jeżeli zbiór \\(A = \\{1, \\{2, 3\\}, 4\\}\\) i zbiór \\(B = \\{\\{2, 3\\}, 1\\}\\), to zbiór \\(B \\subseteq A\\). Natomiast, zbiór \\(B = \\{\\{2, 3\\}, 1\\} \\notin A\\) Za pomocą zbiorów możemy określić zbiory będące przedziałami liczbowymi. Przedział otwarty: \\((a, b) = \\{x\\in R: x&gt;a \\wedge x&lt;b\\}\\), przedział otwarty lewostronnie: \\((a, b] = \\{x\\in R: x&gt;a \\wedge x\\leq b\\}\\). 4.1.4 Zbiory przeliczalne i nieprzeliczalne Typy zbiorów: przeliczalne i skończone: np. \\(A = \\{1, 2, 3\\}\\); przeliczalne i nieskończone, np. zbiór liczb naturalnych N; nieskończone i nieprzeliczalne, np. przedziały liczbowe \\((A = [0, 1] = \\{x: 0\\leq x \\leq 1\\})\\). Różnica między policzalnymi i niepoliczalnymi zbiorami jest ważna dla statystyki i prawdopodobieństwa. Bardzo ważne jest rozróżnienie między zbiorami nieskończonymi, ale przeliczalnymi, a zbiorami nieskończonymi, ale nieprzeliczalnymi. Co to oznacza? Ze względu na matematykę wymaganą do określenia prawdopodobieństw, metody probabilistyczne dzielą się na dwa różne typy, dyskretne i ciągłe. Podejście dyskretne jest stosowane, gdy liczba wyników eksperymentu jest skończona (lub nieskończona, ale policzalna). Podejście ciągłe jest stosowane, gdy wyniki są ciągłe (a zatem nieskończone). W przypadku zbiorów przeliczalnych, ich wszystkie elementy możemy ponumerować liczbami naturalnymi. Jednakże, istnieją zbiory, np. zbiór liczb niewymiernych, zbiór liczb R, które są bardziej liczne od zbioru liczb naturalnych, dlatego nie jest możliwe, aby ich elementy ponumerować liczbami 1, 2, 3, 4, …, n. Jeżeli jakaś zmienna statystyczna przyjmuje wartości z dowolnych przedziałów zbioru liczb R, to tę zmienną określamy jako zmienną ciągłą przedziałami. Zmienne, które nie są ciągłe nazywa się zmiennymi dyskretnymi lub skokowymi. 4.1.4.1 WAŻNE Bycie podzbiorem zbioru (\\(\\subseteq\\) lub \\(\\subset\\)) nie jest tym samym co bycie elementem zbioru (\\(\\in\\)): \\(\\subseteq\\) \\(\\neq\\) \\(\\in\\) \\(\\emptyset \\subseteq \\emptyset\\), ale \\(\\emptyset \\notin \\emptyset\\) \\(\\emptyset \\subseteq \\{1,2,3,4,5\\}\\), \\(\\emptyset \\notin \\{1,2,3,4,5\\}\\) \\(\\{3\\} \\subseteq \\{1,2,3,4,5\\}\\), \\(3 \\nsubseteq \\{1,2,3,4,5\\}\\), ale \\(3 \\in \\{1,2,3,4,5\\}\\) 4.1.5 Zbiór potęgowy (Power set) - dla danego zbioru X zbiór wszystkich jego podzbiorów Ile podzbiorów ma zbiór A = {a, b, c}? Liczbę podzbiorów zbioru S określa następująca formuła: \\[2^n\\] gdzie: \\(n = |S| =\\) liczba elementów zbioru (moc tego zbioru). Zatem, liczba podzbiorów A jest równa \\(2^3 = 8\\) Mamy następujący zbiór (przestrzeń) podzbiorów A: \\[\\{ \\emptyset, \\{a\\}, \\{b\\}, \\{c\\}, \\{a, b\\}, \\{a, c\\}, \\{b, c\\}, \\{a, b, c\\} \\}\\] 4.1.6 Liczność (moc, kardynalność) zbioru [ang. cardinality] W matematyce liczność zbioru jest miarą „liczby elementów\" zbioru. Na przykład zbiór \\(A = \\{2,4,6\\}\\) zawiera 3 elementy, a zatem A ma liczność 3. Począwszy od końca XIX wieku pojęcie to zostało uogólnione na zbiory nieskończone, co pozwala rozróżnić różne typy nieskończoności i wykonywać na nich działania arytmetyczne. Kardynalność zbioru nazywana jest również jego rozmiarem. Liczność (moc) zbioru A jest zwykle oznaczana jako \\(|A|\\), z pionową kreską po każdej stronie; jest to ta sama notacja, co wartość bezwzględna, a znaczenie zależy od kontekstu. Liczność zbioru A można alternatywnie oznaczyć np. \\(n(A)\\), \\(\\#A\\). Jeśli zachodzi tak zwany aksjomat wyboru, prawo trychotomii obowiązuje dla kardynalności: Każdy zbiór X o liczności mniejszej niż liczebność liczb naturalnych jest zbiorem skończonym. Każdy zbiór X, który ma taką samą liczność jak zbiór liczb naturalnych, jest zbiorem policzalnym nieskończonym. Każdy zbiór X o mocy większej niż liczebność liczb naturalnych jest nazywany nieprzeliczalnym. "],["podstawowe-reguły-kombinatoryczne-basic-counting-methods.html", "4.2 Podstawowe reguły kombinatoryczne (basic counting methods)", " 4.2 Podstawowe reguły kombinatoryczne (basic counting methods) Podstawowe reguły kombinatoryczne, które wykorzystuje się w rachunku prawdopodobieństwa do wyznaczania liczebności przestrzeni zdarzeń elementarnych (\\(|S|\\) lub \\(|\\Omega|\\)): reguła sumy, reguła mnożenia, permutacje (nPk). kombinacje (nCk). 4.2.1 Reguła sumy Jeśli pierwsze zadanie można wykonać na \\(n1\\) sposobów (\\(n1\\) opcji), podczas gdy drugie zadanie można wykonać na \\(n2\\) sposoby, a dwa zadania nie mogą być wykonane jednocześnie, to wykonanie któregokolwiek z zadań można wykonać na dowolny z \\(n1 + n2\\) sposobów. Ćwiczenie: Wydział przyzna darmowy komputer studentowi lub profesorowi CS (informatyki). Ile jest różnych opcji, jeśli jest 530 studentów i 15 profesorów? Przykład: Bruce chce każdego dnia spróbować innego posiłku. Ile czasu zajmuje mu jednorazowe spróbowanie każdego posiłku? W menu jest 9 rodzajów pizzy i 6 rodzajów makaronów. W sumie jest 9 + 6 = 15 rodzajów posiłków. Tak więc Bruce potrzebuje 15 dni. Rozszerzmy regułę sumy na dowolną liczbę zestawów: Jeśli \\(A_1, \\ldots, A_n\\) są rozłączne parami, to \\(| A_1 \\cup \\ldots \\cup A_n | = | A_1 | + | A_2 | + \\ldots + | A_n |\\). 4.2.1.1 Zasada włączenia-wykluczenia Co jeśli zestawy nie są rozłączne? Np. Kierunki matematyczne i CS (informatyki), gdzie niektórzy specjalizują się w obu? Najpierw rozważ dwa zbiory. Jeśli \\(A\\) i \\(B\\) są dowolnymi zbiorami (niekoniecznie rozłącznymi), to \\(| A \\cup B | = | A | + | B | - | A \\cap B |\\). Zasada włączenia-wykluczenia wyraża fakt, że suma rozmiarów obu zbiorów może być zbyt duża, ponieważ niektóre elementy mogą być liczone dwukrotnie. Elementy liczone podwójnie to te, które znajdują się na przecięciu dwóch zestawów, a liczba jest korygowana przez odjęcie rozmiaru przecięcia. Przykład. Załóżmy, że ankieta obejmująca 100 osób zapyta, czy mają kota lub psa jako zwierzaka. Wyniki są następujące: 55 osób odpowiedziało tak dla kota, 58 tak dla psa, a 20 osób odpowiedziało tak zarówno dla kota, jak i psa. Ile osób ma kota lub psa? - Rozwiązanie: Ponieważ 55 ma kota, a 58 psa, na początku możesz pomyśleć, że 55 + 58 = 113 mają jedno lub drugie. To rozumowanie pomija fakt, że niektórzy ludzie - 20 - mają jedno i drugie zwierzę, a my policzyliśmy te osoby dwukrotnie, dodając 55 i 58. Aby poprawić naszą odpowiedź, mysimy odjąć od tej sumy liczbę 20: 55 + 58 - 20 = 93 mieć kota lub psa. To jest przykład zasady włączenia-wykluczenia. Zasada jest wyraźniej widoczna w przypadku trzech zbiorów, co dla zbiorów A, B i C daje \\(|A\\cup B\\cup C|=|A|+|B|+|C|-|A\\cap B|-|A\\cap C|-|B\\cap C|+|A\\cap B\\cap C|\\) 4.2.2 Reguła iloczynu Jeśli daną czynność wykonujemy w dwóch etapach; na pierwszym etapie mamy n możliwości, a na drugim etapie m sposobów wykonania tej czynności, to cała czynność może być wykonana n * m sposobów. Ogólniej, jeśli jakaś czynność składa się z kilku etapów (np. wieloetapowy eksperyment losowy składający się z losowań z populacji n osób do próby), na pierwszym etapie mamy \\(k_1\\) możliwości, na drugim \\(k_2, ...,\\) na n-tym etapie \\(k_n\\) możliwości, to wtedy łączna liczba sposobów wykonania czynności (np. łączna liczba możliwych prób) jest równa \\(k = k_1 \\times k_2 \\times ... \\times k_n\\) Dla przykładu, jeśli rzucamy dwa razy monetą, to łączna liczba wyników jest równa 4. Gdy rzucamy dwa razy kostką sześcienną, to łączna liczba wyników jest równa 36. Przykład. W New Hampshire tablice rejestracyjne składają się z dwóch liter, po których następowały 3 cyfry. Ile jest możliwych tablic rejestracyjnych? Odpowiedź: 26 opcji dla pierwszej litery, 26 dla drugiej, 10 opcji dla pierwszej liczby, drugiej liczby i trzeciej liczby: 262 × 103 = 676000 W przykładach niżej zakładamy, że alfabet ma 26 liter [wyłączamy polskie znaki diakrytyczne] Ćwiczenie. Ile można utworzyć tablic rejestracyjnych formatu: [3 cyfry | 2 litery]? Składowe nie mogą się powtarzać, pierwsza cyfra różna od zera. Przykład. Ile jest możliwych tablic rejestracyjnych w formacie - 3 litery i następnie 3 cyfry: \\(26 \\times 26 \\times 26 \\times 10 \\times 10 \\times 10\\). Przykład. Power set, zbiór potęgowy. Jaka jest liczba podzbiorów zestawu elementów \\(n\\)? To jest \\(2 ^n\\). Każdy podzbiór odpowiada ciągowi bitów o długości \\(n\\), gdzie \\(1\\) na pozycji \\(k\\) oznacza, że \\(k\\)-ty element znajduje się w podzbiorze. Przykład . Ile jest możliwych 4-cyfrowych kodów PIN? Można to rozwiązać jako \\(10 · 10 · 10 · 10 = 104 = 10000\\). Tak więc istnieje jedna na dziesięć tysięcy szans, że złodziej może odgadnąć Twój kod PIN (losowo). Rozważmy silniejszy przypadek, w którym musisz użyć każdej cyfry dokładnie raz, więc kod PIN ma dokładnie 10 różnych cyfr. Ile istnieje takich kodów PIN? Mamy 10 wyborów dla pierwszej cyfry, 9 wyborów dla drugiej cyfry i tak dalej, aż mamy tylko 2 wybory dla dziewiątej cyfry i 1 dla dziesiątej cyfry. Oznacza to, że istnieje 362880 możliwych numerów PIN w tym scenariuszu. Mamy: \\[10 \\times 9 \\times \\ldots \\times 2 \\times 1 = \\prod_{i = 1}^{n = 10} i = 362880\\] Ogólniej: \\[N! = N \\times (N − 1) \\times (N − 2) \\times \\ldots \\times 3 \\times 2 \\times 1 = \\prod_{j=1}^n j\\] \\(N!\\) Jest odczytywane jako „N silnia\". Należy pamiętać, że \\(0! = 1\\), ponieważ istnieje jeden sposób na uporządkowanie 0 obiektów. Wiemy z absolutną pewnością, że \\(1! = 1, (n = 1)\\). W ten sposób otrzymujemy: Wiemy, że \\(n! = n \\times (n-1)!\\), wynika z tego, że \\(1! = 1 \\times (1-1)!\\), Wynika z tego, że \\(1! = 1 \\times 0!\\), Więc musi być \\(0! = 1\\). Aby równanie było prawdziwe, musimy wymusić zerową silnię równą 1. W przeciwnym razie \\(1! \\neq 1\\) co prowadzi do sprzeczności. 4.2.3 Reguła iloczynu (2) Załóżmy, że tworzymy 10-cyfrowy kod PIN, ale teraz przynajmniej jedna cyfra musi zostać powtórzona przynajmniej raz. Ile istnieje takich kodów PIN? Niektóre przykłady tego kodu PIN to 1111111111, 01234556788 lub 9876598765, ale lista jest długa! W tym przypadku dobrym podejściem może być policzenie, ile PINów nie spełnia tej właściwości i następnie odjęcie uzyskanej liczby od łącznej liczby kodów PIN. Ta strategia nazywa się liczeniem uzupełniającym (ang. complementary counting), ponieważ liczymy wielkość dopełnienia zbioru będącego przedmiotem zainteresowania. Liczba możliwych 10-cyfrowych kodów PIN, bez żadnych zastrzeżeń, wynosi \\(10^{10}\\) (z reguły iloczynu mnożąc przez siebie 10 wyborów dla każdej z 10 pozycji). Stwierdziliśmy powyżej, że 10-cyfrowe kody PIN bez powtórzeń mają 10! możliwości (każda cyfra używana dokładnie raz). Weź pod uwagę, że 10-cyfrowe kody PIN z co najmniej jednym powtórzeniem będą wszystkimi innymi możliwościami. Problem można rozwiązać obliczając różnicę wszystkich możliwych 10-cyfrowych PIN-ów i tych bez powtórzeń. To znaczy: \\(10^{10} - 10!\\) 4.2.4 Permutacje bez powtórzeń (bez zwracania) Wzór pozwalający wyznaczyć liczbę \\(P_r^n\\) r-permutacji bez powtórzeń ze zbioru n-elementów jest następujący \\[P_r^n = \\frac{n!}{(n-r)!}\\] przy czym \\(n! = n \\times (n-1) \\times (n-2) \\times ... \\times 2 \\times 1\\), oraz \\(0! = 1\\). Ile jest dwuelementowych permutacji bez powtórzeń ze zbioru \\(S = \\{R, O\\}\\)? Odpowiedź: \\[P_2^2 = \\frac{2!}{(2-2)!} = 2! = 1 \\times 2 = 2\\] Zbiór permutacji jest następujący: \\(\\{(R,O), (O, R)\\}\\). Zbiór ten liczy dwa elementy - \\(|\\{(R,O), (O, R)\\}| = 2\\). Pamiętaj, że zbiór pusty \\(\\emptyset\\) jest podzbiorem każdego zbioru, ale \\(|\\emptyset| = |\\{\\}| = 0\\). 4.2.5 Kombinacje bez powtórzeń (bez zwracania) Wzór pozwalający wyznaczyć liczbę \\(C_x^n\\) x-kombinacji bez powtórzeń ze zbioru n-elementów jest następujący: \\[C_x^n = \\binom{n}{x} = \\frac{n!}{(n-x)!x!}\\] Ile można utworzyć 6-kombinacji (6-elementowych zbiorów) ze zbioru liczb 1, …, 49? \\[C_6^{49} = \\binom{49}{6} = \\frac{49!}{(49-6)!6!} = 13 983816\\] Ile jest równe prawdopodobieństwo wylosowania dowolnego zbioru 6 liczb (kolejność jest bez znaczenia) ze zbioru 49 liczb? \\[P(\\text{6-elementowy zbiór różnych liczb ze zbioru 49 liczb}) = \\frac{\\binom{6}{6}}{13983816} = 1/13983816\\] Ile jest dwuelementowych kombinacji bez powtórzeń ze zbioru \\(S = \\{R, O\\}\\)? Odpowiedź: \\[C_2^2 = \\frac{2!}{(2-2)!2!} = 2!/2! = 1\\] Zbiór kombinacji jest następujący: \\(\\{\\{0, 1\\}\\}\\) - jest to zbiór jednoelementowy. 4.2.6 Permutacje z powtórzeniami (elementy mogą się powtarzać) Wzór na liczbę \\(P_r^n\\) r-permutacji (elementy mogą się powtarzać) z zbioru n-elementów jest jest następujący: \\[P_r^n = n^r\\] Liczba trójelementowych permutacji ze zbioru dwuelementowego jest równa \\(2^3 = 8\\). \\(S = \\{ (R, R, R), (R, R, O), (R, O, O), (O, O, O), (O, O, R), (O, R, R), (O, R, O), (R, O, R) \\}\\). 4.2.7 Kombinacje z powtórzeniami Teraz przechodzimy od permutacji z powtórzeniami do kombinacji z powtórzeniami. Niech \\(S\\) będzie zbiorem \\(\\{A, B, C \\}\\). Ten zbiór ma trzy kombinacje dwuelementowe. Oznacza to, że istnieją trzy sposoby, aby wybrać dwa różne elementy \\(S\\), gdzie kolejność nie ma znaczenia. Poniżej przedstawiono trzy \\(2\\)-kombinacje ze zbioru \\(S\\). \\[\\{\\{ A, B \\}, \\{ A, C \\}, \\{ B, C \\}\\}\\] Załóżmy, że nie musimy wybierać różnych elementów z \\(S\\), ale możemy wybierać wielokrotnie ten sam element. Wynikowe zbiory nazywane są \\(r\\)-kombinacjami z powtórzeniami ze zbioru \\(S\\). Poniżej wymienione jest sześć kombinacji dwuelementowych z powtórzeniami z \\(S\\). \\[\\{\\{ A, B \\}, \\{ A, C \\}, \\{ B, C \\}, \\{ A, A \\}, \\{ B, B \\}, \\{ C, C \\}\\}\\] Ściśle mówiąc, są to multizbiory, a nie zbiory, ponieważ element może występować wielokrotnie. 4.2.7.1 Obliczanie \\(r\\)-kombinacji z powtórzeniami Liczba \\(r\\)-kombinacji z powtórzeniami ze zbioru elementów \\(n\\) wynosi \\[\\binom{n + r - 1}{r}\\] W powyższym przykładzie znaleźliśmy sześć sposobów wyboru dwóch elementów ze zbioru \\(S = \\{A, B, C\\}\\) z dozwolonymi powtórzeniami. Oczywiście twierdzenie mówi, że liczba kombinacji 2 w zestawie 3-elementowym wynosi \\(\\binom{3 + 2 - 1}{2} = 6\\). Dla porównania, pamiętaj, że liczba zwykłych kombinacji \\(r\\) zestawu elementów \\(n\\) wynosi \\(\\binom{n}{r}\\). Każda zwykła kombinacja \\(r\\) jest również poprawną \\(r\\)-kombinacją z powtórzeniami. "],["prawdopodobieństwo.html", "4.3 Prawdopodobieństwo", " 4.3 Prawdopodobieństwo 4.3.1 Definicja prawdopodobieństwa Jak można interpretować pojęcie prawdopodobieństwa? Są trzy podstawowe interpretacje pojęcia prawdopodobieństwa: prawdopodobieństwo klasyczne (logiczne), lub prawdopodobieństwo a priori, prawdopodobieństwo statystyczne, częstościowe (doświadczalne), lub a posteriori, prawdopodobieństwo subiektywne. Intuicyjnie, prawdopodobieństwo utożsamiamy z szansą zrealizowania się określonego zdarzenia losowego, np. z szansą wyrzucenia 3 oczek na symetrycznej kostce do gry. 4.3.2 Podstawowe pojęcia Doświadczenie losowe to eksperyment, którego wynik zależy od pewnego mechanizmu losowego. Np. rzut monetą lub kostką do gry. Przestrzeń (zbiór) zdarzeń elementarnych, oznaczamy \\(S\\) lub \\(\\Omega\\), to zbiór wszystkich możliwych wyników doświadczenia losowego. Zdarzenia elementarne są parami rozłączne i wspólnie tworzą zbiór \\(S\\). Zdarzenie losowe (np. zbiór \\(A\\)) to podzbiór przestrzeni zdarzeń elementarnych \\(S\\) składający się ze zdarzeń elementarnych. Np. \\(A = \\{e_1, e_2, ...\\}\\). \\(\\emptyset\\) - zbiór pusty, czyli zdarzenie niemożliwe. Zbiór \\(A^c\\) zbioru \\(A\\) zdarzeń elementarnych nazywamy zdarzeniem przeciwnym do zdarzenia \\(A\\). Doświadczenie losowe jest to eksperyment, którego wyniku nie możemy z góry przewidzieć. Wszystkie możliwe wyniki doświadczenia losowego tworzą zbiór zwany przestrzenią zdarzeń elementarnych \\(S = \\{e_1, e_2, ...\\}\\). Ten zbiór może być: skończony; nieskończony, ale przeliczalny (zbiory nieciągłe, skokowe); lub nieskończony i nieprzeliczalny (zbiór ciągły, np. przedział liczbowy). Dowolny podzbiór zbioru \\(S\\), np. zbiór \\(\\{e_2, e_4\\}\\), nazywa się po prostu zdarzeniem (nie mylić ze zdarzeniem elementarnym). \\(A\\cup B\\) - suma zdarzeń losowych, która odpowiada zajściu co najmniej jednego ze zdarzeń A, B (suma zbiorów A i B). \\(A\\cap B\\) - iloczyn zdarzeń losowych A i B odpowiada jednoczesnemu zajściu zdarzeń A i B (przekrój zbiorów A i B). Literą \\(F\\) oznaczamy zbiór wszystkich podzbiorów przestrzeni zdarzeń elementarnych \\(S\\) (zbiór wszystkich zdarzeń losowych) - dla przeliczalnych przestrzeni zdarzeń będzie to ich Power set (\\(2^{|S|}\\)). Trójkę \\((S, F, P)\\) nazywamy przestrzenią probabilistyczną. Często nie interesuje nas konkretne zdarzenie elementarne (np. wyciągnięcie asa ze standardowej talii 52 kart), ale ich pewien zbiór, czyli pewne zdarzenie losowe (np. prawdopodobieństwo otrzymania fulla w pokera, prawdopodobieństwo prawidłowego wytypowanie szóstki w Lotto itp.). Mówimy, że zaszło zdarzenie A, gdy wynik doświadczenia losowego należy do zbioru zdarzeń elementarnych A, przy czym zbiór \\(A \\subseteq S\\). W rachunku prawdopodobieństwa zdarzenia losowe są utożsamiane ze zbiorami, dlatego rachunek zdarzeń jest tożsamy z rachunkiem zbiorów. Podstawowe operacje na zdarzeniach, czyli np. sumę, iloczyn lub dopełnienie zbioru (podobnie jak operacje na zbiorach) możemy przedstawić graficznie za pomocą tzw. diagramów Venna. Prawdopodobieństwo zdarzenia \\(A =\\) wyrzucenie co najmniej 4 oczek na kostce do gry oznaczamy \\(P(A) = P(\\{e_1 = 4, e_2 = 5, e_3 = 6\\})\\). 4.3.3 Zmienna losowa i rozkład prawdopodobieństwa - wprowadzenie Zmienna losowa jest to funkcja określona na zbiorze zdarzeń elementarnych S i odwzorowująca elementy tego zbioru w zbiór liczb rzeczywistych R. Zmienne losowe, podobnie jak zbiory, oznaczamy wielkimi literami. Np. dla eksperymentu polegającego na rzucie dwiema sześciennymi kostkami możemy zdefiniować zmienne: X = liczba oczek na pierwszej kostce + liczba oczek na drugiej lub np. Y = średnia liczba oczek, które wyrzucono podczas rzutu dwiema kostkami. Funkcja rozkładu prawdopodobieństwa (rozkład prawdopodobieństwa) - odwzorowanie przyporządkowujące wszystkim wartościom zmiennej losowej, odpowiadające tym wartościom prawdopodobieństwa P. Doświadczenie losowe: Rzut monetą; \\[S = \\{R, O\\}\\] \\[f: S \\rightarrow X \\in \\{0, 1\\}\\] \\[R \\rightarrow 0, O \\rightarrow 1\\] Rozkład prawdopodobieństwa: \\(0 \\rightarrow 0.5 \\wedge 1 \\rightarrow 0.5\\) Podobnie jak wiele innych funkcji, rozkład prawdopodobieństwa można też obrazowo przedstawić na wykresie w układzie współrzędnych. Innym przykładem rozkładu prawdopodobieństwa zmiennej losowej będzie rozkład zmiennej X = liczba oczek, które wypadły podczas rzutu sześcienną kostką. Przedstawione wyżej rozkłady prawdopodobieństwa są rozkładami zmiennej skokowej. W statystyce duże znaczenie mają też rozkłady prawdopodobieństwa zmiennych ciągłych. Funkcje rozkładu prawdopodobieństwa dla zmiennych ciągłych nazywamy funkcjami gęstości prawdopodobieństwa. W przypadku zmiennych skokowych, wartości funkcji rozkładu prawdopodobieństwa są prawdopodobieństwami odpowiadającymi argumentom funkcji (wartościom zmiennej losowej). W przypadku zmiennych ciągłych wartości funkcji rozkładu są wielkościami określanymi mianem gęstości prawdopodobieństwa, natomiast prawdopodobieństwa liczymy wyznaczając pola powierzchni pod krzywą funkcji gęstości rozkładu prawdopodobieństwa dla wybranych przedziałów. Np. dla powyższego przykładu, gęstość prawdopodobieństwa jest stała (funkcja prawdopodobieństwa jest stała) i równa \\(\\frac{1}{6}\\), a przedział zmienności \\(X = [0, 6]\\). Wprowadzenie funkcji gęstości i pojęcia gęstości jest niezbędne dla wyznaczenia prawdopodobieństw, gdy badamy zmienne ciągłe, gdyż w ich przypadku nie jest możliwe wyznaczanie prawdopodobieństw w taki sam sposób jak np. w przykładach dotyczących rzutów monetą lub kostką do gry (przeliczalny zbiór zdarzeń elementarnych), co wynika z faktu, że zmienne ciągłe przyjmują nieskończoną i nieprzeliczalną liczbę wartości z pewnych przedziałów zbioru R. Nie wolno mylić pojęcia gęstości prawdopodobieństwa z pojęciem prawdopodobieństwa. 4.3.4 Aksjomaty (pewniki) teorii prawdopodobieństwa Funkcja rozkładu prawdopodobieństwa jest to metoda przyporządkowania prawdopodobieństw zdarzeniom losowym w taki sposób, aby spełnione były następujące aksjomaty: \\(P(A) \\geq 0\\), dla dowolnego zdarzenia \\(A\\), \\(P(S) = 1\\), \\(P(A_1\\cup A_2 \\cup A_3 \\cup ...) = P(A_1) + P(A_2) + P(A_3) + ...\\), dla wykluczających się zdarzeń \\(A_1, A_2, A_3, ...\\) Ogólniej możemy napisać: \\(P(\\bigcup_{i=1}^\\infty A_i) = \\Sigma_{i=1}^{\\infty} P(A_i)\\). 4.3.5 Klasyczna definicja prawdopodobieństwa Definicja klasyczna ma zastosowanie, wtedy, gdy każde zdarzenie elementarne jest jednakowo prawdopodobne, np. w przypadku doświadczeń z kośćmi do gry lub monetą. \\(P(A) = \\frac{\\text{Liczba wyników sprzyjających zdarzeniu A}}{\\text{Liczba wszystkich możliwych wyników w S}} = \\frac{n(A)}{n(S)} = \\frac{|A|}{|S|}\\) Doświadczenie losowe: Rzut dwiema sześciennymi kostkami do gry. Zbiór zdarzeń elementarnych: \\(S = \\{(1, 1), (1, 2), ..., (6, 6)\\}\\). Zdarzenie losowe \\(A\\): Na kostkach wypadły liczby 1 i 6. Zdarzeniu \\(A\\) sprzyjają dwa wyniki (dwa zdarzenia elementarne), \\(A = \\{(1, 6), (6, 1)\\}\\). \\(P(A) = \\frac{2}{36} = \\frac{1}{18}\\). Zdarzenie losowe \\(B\\): Suma wyrzuconych oczek jest równa 1. Zdarzeniu \\(B\\) nie sprzyja żaden wynik, dlatego \\(B = \\emptyset\\). \\(P(B) = \\frac{0}{36} = 0\\). Klasyczna definicja prawdopodobieństwa może być zastosowana dla dyskretnych przestrzeni zdarzeń elementarnych, gdy wszystkie zdarzenia elementarne są jednakowoprawdopodobne i zbiór zdarzeń elementarnych jest skończony. Jednak, gdy zbiór zdarzeń elementrnych jest zbiorem ciągłym, podejście klasyczne (“naiwne”) nie działa poprawnie. Narysujmy koło o promieniu r = 4 i \\(S(0, 0)\\) oraz drugie koło o promieniu 3 i środku również \\(S(0, 0)\\). Jakie jest prawdopodobieństwo, że zrealizuje się zdarzenie losowe polegające na tym, że losowo wybrany punkt w obszarze koła o promieniu 4, należy jednocześnie do koła o promieniu r = 3? Oba koła to zbiory punktów, możemy pierwszy zbiór oznaczyć literą S, a drugi literą A, naszemu zdarzeniu losowemu sprzyja wynik doświadczenia losowego polegający na wylosowaniu dowolnego punktu należącego do zbioru A, wówczas zgodnie z prawdopodobieństwem klasycznym: \\[P(A) = \\frac{|A|}{|S|}\\] Niestety, zarówno, liczba wyników sprzyjających, jak i liczba wszystkich możliwych wyników doświadczenia jest nieskończona i nieprzeliczalna. Nie jesteśmy w stanie w powyższy sposób wyznaczyć poszukiwanego \\(P(A)\\). Jak rozwiązać ten problem? Zamiast rozważać liczebność nieprzeliczalnych zbiorów punktów, wykorzystajmy ich pola powierzchni. Wzory na pole koła i wielu innych figur geometrycznych są znane. Możemy też posłużyć się całkami do wyznaczenia pól bardziej skomplikowanych figur. \\[P(A) = \\frac{\\text{pole powierzchni }A}{\\text{pole powierzchni }S}\\] \\[P(A) = \\frac{9\\pi}{16\\pi} =\\frac{9}{16}\\] W powyższym przykładzie, przestrzeń zdarzeń losowych S jest zbiorem dwuwymiarowym, który zawiera nieprzeliczalną liczbę elementów, dlatego prawdopodobieństwo \\(&gt; 0\\) istnieje tylko dla zdarzeń, które też są zbiorami dwuwymiarowymi i nieprzeliczalnymi. Jeżeli S byłaby zbiorem nieprzeliczalnym jednowymiarowym (np. prostą lub odcinkiem), to prawdopodobieństwo \\(&gt; 0\\) jest określone dla zdarzeń jednowymiarowych (odcinków lub przedziałów zawartych w zbiorze S). Podobnie jest w przypadku objętości. Wybierzmy losowo punkt we wnętrzu koła o promieniu równym 1. W tym przypadku, \\(S = \\{(x, y): x^2 + y^2 &lt; 1 \\}\\) i \\[P(A) = \\frac{\\text{pole powierzchni A}}{\\pi}\\] Jeśli zbiór A jest tzw. singletonem (zbiór, którego jedynym elementem jest pojedynczy punkt), wówczas \\(P(A) = 0\\). Jeżeli przestrzeń zdarzeń elementarnych jest dwuwymiarowa, to nie możemy przyporządkować prawdopodobieństwa większego od 0 zdarzeniu A, którego elementem jest pojedynczy punkt lub nawet prosta, gdyż pola punktu lub dowolnej krzywej, odcinka są równe 0. 4.3.6 Definicja empiryczna lub statystyczna Prawdopodobieństwo statystyczne jest wyznaczane na podstawie obserwacji. Empiryczne prawdopodobieństwo zdarzenia A, to względna częstość występowania w ciągu doświadczeń losowych wyników, które sprzyjają zdarzeniu A. Np. jeśli w 100 rzutach monetą 55 razy wypadł orzeł, to częstość wypadania orła w 100 próbach wyniosła \\(0,55 = 55\\%\\). \\(P(A) = \\frac{\\text{Częstość wyników sprzyjających A}}{\\text{Liczba wszystkich obserwacji}} = \\frac{Fr(A)}{n}\\) Prawo wielkich liczb mówi, że wraz ze wzrostem liczby obserwacji (powtórzeń eksperymentu), prawdopodobieństwo empiryczne zbliża się do prawdopodobieństwa teoretycznego (faktycznego). Jeśli będziemy wielokrotnie powtarzać rzut kostką do gry i odnotowywać wyniki, to po bardzo wielu doświadczeniach okaże się, że częstość względna występowania poszczególnych wyników stopniowo zbliża się do \\(\\frac{1}{6}\\), czyli do prawdopodobieństwa klasycznego. Prawdopodobieństwo empiryczne jest metodą szacowania (estymacji) prawdopodobieństwa teoretycznego, którego wartość może być nieznana, np. w przypadku, gdy liczba możliwych wyników doświadczenia jest bardzo duża. W ciągu 100 rzutów monetą odnotowano następujące częstości wypadania orła (O) i reszki (R): odpowiednio 60 i 40. Jakie jest prawdopodobieństwo (w sensie empirycznym) zdarzenia \\(A = \\{\\text{wypadł orzeł}\\}\\) w doświadczeniu polegającym na rzucie monetą? Odpowiedź: \\(P(A = \\{O\\}) = \\frac{60}{100} = 0.6\\) Empiryczną definicję prawdopodobieństwa można wykorzystać do oszacowania rozkładu prawdopodobieństwa zmiennej losowej (empiryczny rozkład prawdopodobieństwa zmiennej losowej). Estymatorami prawdopodobieństw są częstości (liczebności) względne. Oszacowanie jest tym lepsze, im większa jest liczba przeprowadzonych doświadczeń losowych n. 4.3.7 Prawdopodobieństwo subiektywne Prawdopodobieństwo subiektywne jest oparte na intuicji. Np. lekarz może przypisać pacjentowi prawdopodobieństwo wyleczenia na podstawie swojej wiedzy, doświadczenia i intuicji. 4.3.8 Empiryczny rozkład prawdopodobieństwa Jeżeli do przyporządkowania prawdopodobieństw wartościom zmiennej losowej możemy użyć klasycznej definicji prawdopodobieństwa, to znamy prawdziwy rozkład zmiennej losowej. Często analizujemy jednak zmienne losowe, których zbiór wartości jest bardzo duży lub nieskończony. Wtedy, możemy zwykle jedynie oszacować rozkład zmiennej wykorzystując statystyczne (częstościowe) rozumienie prawdopodobieństwa. Rozkład zmiennej X - wynik rzutu sześcienną kością do gry jest znany. Aby określić rozkład zmiennej Y - liczba osób popierających liberalizację prawa antyaborcyjnego w Polsce, musimy skorzystać z metod statystyki, wybrać losowo próbę z populacji Polaków i na tej podstawie określić jakie jest prawdopodobieństwo, że losowo wybrany Polak popiera liberalizację. Wskutek takiego badania otrzymujemy tzw. rozkład empiryczny (rozkład częstości względnej), który jest oszacowaniem prawdziwego rozkładu zmiennej. Jeżeli na podstawie badań empirycznych na losowych próbach wybranych z populacji uda się ustalić przybliżony kształt wykresu funkcji rozkładu prawdopodobieństwa, to na tej podstawie można do kształtu wykresu dopasować równanie funkcji, które dobrze modeluje prawdziwy rozkład pewnej zmiennej losowej. Np. rozkłady wielu zmiennych społecznych, np. zmiennej poziom IQ, modeluje się za pomocą funkcji tzw. rozkładu normalnego, której wykres przypomina kształtem dzwon. 4.3.9 Algebra prawdopodobieństw Prawdopodobieństwo iloczynu dwóch niezależnych zdarzeń \\(A\\cap B\\) jest równe prawdopodobieństwu zdarzenia składającego się z wyników doświadczenia, które sprzyjają jednocześnie zdarzeniu \\(A\\) i zdarzeniu \\(B\\) - iloczyn zbiorów A i B. \\(P(A\\cap B) = P(A)P(B)\\). Prawdopodobieństwo sumy zdarzeń jest równe prawdopodobieństwu zdarzenia składającego się z wyników doświadczenia, które sprzyjają zdarzeniu \\(A\\) lub/i zdarzeniu \\(B\\) - suma zbiorów A i B. \\(P(A\\cup B) = P(A) + P(B) - P(A\\cap B)\\). Prawdopodobieństwo zdarzenia przeciwnego dla dowolnego zdarzenia A jest równe \\(P(A^c) = 1 - P(A)\\). 4.3.10 Niezależność zdarzeń losowych a zdarzenia parami rozłączne Kiedy dwa zdarzenia A i B wzajemnie się wykluczają (zdarzenia rozłączne), nie mogą one zrealizować się jednocześnie. Zajście zdarzenia A wyklucza możliwość jednoczesnego zajścia zdarzenia B. Np. gdy w doświadczeniu polegającym na rzucie sześcienną kostką zdarzenie A polegałoby na wyrzuceniu parzystej liczby oczek, a zdarzenie B na wyrzuceniu nieparzystej liczby oczek, to te zdarzenia wykluczają się. Kiedy dwa zdarzenia wykluczają się wzajemnie, to: \\(P(A\\cap B) = 0\\) i \\(P(A \\cup B) = P(A) + P(B)\\). Pojęcie zdarzeń wykluczających się należy odróżnić od pojęcia niezależności zdarzeń losowych. Często interesuje nas prawdopodobieństwo zdarzenia, np. zdarzenia B, gdy wiemy, że zaszło pewne zdarzenie A. Prawdopodobieństwo takie oznaczamy \\(P(B|A)\\). Jeżeli dwa zdarzenia są zależne, to wówczas realizacja jednego ze zdarzeń modyfikuje prawdopodobieństwo zajścia drugiego zdarzenia i odwrotnie. 4.3.11 Prawdopodobieństwo warunkowe Prawdopodobieństwo warunkowe zdarzenia A pod warunkiem zajścia zdarzenia B jest równe \\[P(A|B) = \\frac{P(A\\cap B)}{P(B)} \\text{, i } P(B) \\neq 0\\] Podobnie, prawdopodobieństwo, że wystąpi B, biorąc pod uwagę, że wystąpiło A (B uwarunkowane A) jest równe \\[P(B|A) = \\frac{P(A\\cap B)}{P(A)} \\text{, i } P(A) \\neq 0\\] W większości przypadków \\(P(A | B) \\neq P(B | A)\\)!!! Jeżeli zdarzenia A i B są niezależne tj. gdy prawdopodobieństwo zdarzenia A nie zmienia się bez względu na to, czy zdarzenie B zrealizowało się, czy też nie, to: \\[P(A|B) = P(A)\\] \\[P(B|A) = P(B)\\] Ponadto, mamy: \\[P(A\\cap B) = P(A)P(B)\\] \\[P(A\\cup B) = P(A) + P(B) - P(A)P(B)\\] Zauważ, że dla wykluczających się zdarzeń A i B otrzymujemy \\(P(A|B) = 0\\) oraz \\(P(A\\cap B) = 0\\) i \\(P(A\\cup B) = P(A) + P(B)\\) W przypadku zdarzeń rozłącznych, realizacja jednego spośród zdarzeń wyklucza możliwość jednoczesnego zajścia drugiego zdarzenia, co dowodzi, że zdarzenia rozłączne są zawsze zdarzeniami wzajemnie zależnymi. Przekształcając formułę dla prawdopodobieństwa warunkowego, możemy obliczyć prawdopodobieństwo, że jednocześnie zaszły zdarzenia A i B (prawdopodobieństwo iloczynu zdarzeń), które wyraża sie ogólnie wzorem: \\[P(A\\cap B) = P(A)P(B|A)\\] lub \\[P(A\\cap B) = P(B)P(A|B)\\] Stąd, mamy ponadto \\[P(A|B) · P(B) = P(B|A) · P(A)\\] ### Prawdopodobieństwo warunkowe (tablica korelacyjna) Tabela 4.1: Wykształcenie a płeć (K, M) Podstawowe Średnie Wyższe Suma M 38 28 22 88 K 45 50 17 112 Suma 83 78 39 200 Prawdopodobieństwo zdarzenia A, pod warunkiem, że zaszło zdarzenie B jest równe: \\[P(A | B) = \\frac{P(A \\cap B)}{P(B)}\\] Z określenia prawdopodobieństwa warunkowego mamy definicję iloczynu (części wspólnej) zdarzeń A i B, t.j. \\(P(A \\cap B)\\): \\(P(A \\cap B) = P(A)\\times P(B|A) = P(B)\\times P(A|B)\\) Jakie jest prawdopodobieństwo, że kobieta ukończyła szkołę wyższą (dane z tablicy korelacyjnej), czyli P(A = Wyższe | B = Kobieta)? \\(P(A | B) = \\frac{17}{112} = 0.152 = \\frac{17/200}{112/200} = 0.152\\) 4.3.12 Zdarzenia parami niezależne Załóżmy, że \\(A\\), \\(B\\) są zdarzeniami, przy czym \\(P(B)&gt;0\\). Wówczas zdarzenia \\(A\\), \\(B\\) powinny być niezależne, jeśli informacja o tym, że zaszło zdarzenie \\(B\\) nie wpływa na prawdopodobieństwo zajścia zdarzenia \\(A\\); tzn. niezależność powinna być równoważna równości \\(P(A|B)=P(A)\\), czyli \\(P(A \\cap B)=P(A)P(B)\\). Przyjmujemy to jako definicję niezależności. Jeżeli A i B są zdarzeniami niezależnymi, to prawdopodobieństwo, że A i B wystąpią jednocześnie (przekrój zdarzeń A i B), jest równe iloczynowi prawdopodobieństwa A i prawdopodobieństwa B: \\[P(A ∩ B) = P(A)P(B)\\] Przykład. Rzucamy uczciwą monetą 3 razy. Niech \\(H1\\) = “reszka w pierwszym rzucie”, a \\(A\\) = “łącznie wypadły dwie reszki”. Czy \\(H14\\) i \\(A\\) są niezależne? Odpowiedź: Wiemy, że \\(P(A) = 3/8\\). Ponieważ nie jest to 0, możemy sprawdzić wynik testu na niezależność. Teraz \\(H1 = \\{HHH, HHT, HTH, HTT\\}\\) zawiera dokładnie dwa wyniki \\((HHT, HTH)\\) z A, więc mamy \\(P(A | H1) = 2/4\\). Ponieważ \\(P(A | H1)\\) nie jest równe \\(P(A)\\), zdarzenia te nie są niezależne. UWAGA: Tzw. zdarzenia wykluczające się są zawsze zależne. Np. Zdarzenia A - wyrzucenie reszki, B - wyrzucenie orła, wykluczają się, więc są zależne: \\[P(orzeł | reszka) = \\frac{P(orzeł \\cap reszka)}{P(reszka)} = \\frac{0}{0.5} = 0\\] Na podstawie danych z tabeli korelacyjnej 4.1, ustal czy wykształcenie jest niezależne od płci. Pierwszy sposób: Ponieważ P(Wyższe) = \\(\\frac{39}{200} = 0.195 \\neq\\) P(Wyższe | Kobieta) = \\(0.152\\), to stwierdzamy, że wykształcenie i płeć są zależne. Drugi sposób: \\[P(A \\cap B) = 17/200 = 0.085 \\neq\\] \\[P(A)\\times P(B) = 39/200 \\times 112/200 = 0.109\\] Ponieważ \\(P(A \\cap B) \\neq P(A) \\times P(B)\\) to konkludujemy, że zdarzenia są zależne. 4.3.12.1 Zdarzenia niezależne - zadanie 1 Rrzucamy kością sześciościenną i zakładamy, że wszystkie zdarzenia elementarne są jednakowo prawdopodobne. Jakie jest prawdopodobieństwo, że otrzymamy parzystą liczbę oczek (A) i jednocześnie większą lub równą 4 (B)? Czy zdarzenia A i B są niezależne? Rozwiązanie: \\(A = \\{2, 4, 6\\}, B = \\{4, 5, 6\\}\\), więc iloczyn \\(A \\cap B = \\{4, 6\\}\\). \\[ P(A \\cap B) = \\frac{|A \\cap B|}{|S|} = \\frac{2}{6} = \\frac{1}{3} \\] Ponadto, \\[ P(A) = \\frac{|A|}{|S|} = \\frac{3}{6} = \\frac{1}{2}, P(B) = \\frac{|B|}{|S|} = \\frac{3}{6} = \\frac{1}{2} \\] \\[ P(A)P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4} \\] Stwierdzamy więc, że A i B są zależne, ponieważ: \\(P(A)P(B) \\neq P(A \\cap B)\\) 4.3.12.2 Zdarzenia niezależne - zadanie 2 Rzucamy dwiema sześciościennymi kośćmi (n1 i n2). Jakie jest prawdopodobieństwo otrzymania sumy oczek równej 7 (\\(A\\)) i parzystej liczby oczek na drugiej kości (\\(B\\))? \\[ P(A) = \\frac{|A|}{|S|} = \\frac{6}{36} = \\frac{1}{6} \\] \\[ P(B) = \\frac{|B|}{|S|} = \\frac{6 \\times 3 = 18}{36} = \\frac{1}{2} \\] \\[ P(A \\cap B) = \\frac{|A \\cap B|}{|S|} = \\frac{3}{36} = \\frac{1}{12} \\] \\[ P(A)P(B) = \\frac{1}{6} \\times \\frac{1}{2} = \\frac{1}{12} \\] więc, \\(P(A)P(B) = P(A \\cap B)\\), co dowodzi, że zdarzenia A i B są niezależne. 4.3.13 Przykłady różne (*) 4.3.13.1 Przykład Rzucamy sześciościenną kostką do gry. Jakie jest prawdopodobieństwo wyrzucenia parzystej liczby oczek? Rozwiązanie. Szukamy prawdopodobieństwa zdarzenia \\(E = \\{2, 4, 6\\}\\). Przestrzeń zdarzeń elementarnych \\(S = \\{1, 2, 3, 4, 5, 6\\}\\), wtedy \\[P(E) = \\frac{3}{6} = \\frac{1}{2}\\] 4.3.13.2 Przykład Rzucamy dwukrotnie sześciościenną kostką do gry. Jakie jest prawdopodobieństwo, że podczas pierwszego rzutu wypadnie 1 oczko, a w drugim rzucie 2 oczka? Rozwiązanie. Szukamy prawdopodobieństwa zdarzenia \\(E = \\{(1, 2)\\}\\). Przestrzeń zdarzeń elementarnych \\(S = \\{(1, 1), (1, 2), (2, 1), ..., (6, 5), (6, 6)\\}\\). Wtedy, na podstawie klasycznej definicji prawdopodobieństwa, \\(P(\\{(1, 2)\\}) = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}\\) 4.3.13.3 Przykład Rzucamy dwukrotnie sześciościenną kostką do gry. Znajdź prawdopodobieństwo wyrzucenia 1 oczka i 2 oczek w dowolnej kolejności. Rozwiązanie. Szukamy prawdopodobieństwa zdarzenia \\(E = \\{(1, 2), (2, 1)\\}\\). Przestrzeń zdarzeń elementarnych \\(S = \\{(1, 1), (1, 2), (2, 1), ..., (6, 5), (6, 6)\\}\\), wówczas \\(P(\\{(1, 2), (2, 1)\\}) = 2 \\times \\frac{1}{6} \\times \\frac{1}{6} = \\frac{2}{36} = \\frac{1}{18}\\) Tłumaczenie na j. polski przykładów niżej pojawi się wkrótce. 4.3.13.4 Example You roll a fair die. What is the probability of getting an even number? Solution. \\(E = E_1 \\cup E_2 \\cup E_3\\). You can see that events \\(E_1, E_2, E_3\\) are disjoint, then \\(P(E = E_1 \\cup E_2 \\cup E_3) = P(E_1) + P(E_2) + P(E_3) = \\frac{3}{6}\\) You roll a fair die. What is the probability of getting an even number (A) and the number greater or equal to 4 (B)? Are events A and B independent? Solution. Let’s find the intersection of events A and B, \\(A \\cap B\\). \\(A = \\{2, 4, 6\\}, B = \\{4, 5, 6\\}\\), then \\(A \\cap B = \\{4, 6\\}\\). \\[P(A \\cap B) = \\frac{|A \\cap B|}{|S|} = \\frac{2}{6} = \\frac{1}{3}\\] Also, \\[P(A) = \\frac{|A|}{|S|} = \\frac{3}{6} = \\frac{1}{2}, P(B) = \\frac{|B|}{|S|} = \\frac{3}{6} = \\frac{1}{2}\\] then, \\[P(A)P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\] We conclude that events A and B are dependent, on the basis of the test for independence: \\[P(A)P(B) \\neq P(A \\cap B)\\] 4.3.13.5 Example Roll two fair dice. What is the probability of getting the sum of the two dice equal 7 and an even number on the second die? Let \\(A = \\{ (1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1) \\}\\) \\[P(A) = \\frac{|A|}{|S|} = \\frac{6}{36} = \\frac{1}{6}\\] Let \\(B = \\{ (1, 6), (1, 4), (1, 2), (2, 6), (2, 4), ... \\}\\) You can notice that, by product rule, we have \\(|B| = 6 \\times 3\\), Thus, \\[P(B) = \\frac{|B|}{|S|} = \\frac{6 \\times 3 = 18}{36} = \\frac{1}{2}\\] Then, \\[P(A \\cap B) = \\frac{|A \\cap B|}{|S|} = \\frac{3}{36} = \\frac{1}{12}\\] \\[P(A)P(B) = \\frac{1}{6} \\times \\frac{1}{2} = \\frac{1}{12}\\] Finally, from the test for independence of events, we have: \\[P(A)P(B) = P(A \\cap B)\\] Thus, events A and B are independent. 4.3.13.6 Example You roll three fair dice. What is the probability of rolling a combination of the numbers 1, 3, 5? Solution. We need to answer two questions. “What are the odds of getting any particular combination, in order, on three dice?”. The second is “How many orderings are there of the numbers 1, 3, and 5?”. The answer to the first question is that there is a 1 in 216 chance of getting a specific, particular ordering of results from three dice. For \\((1,3,5)\\), you have to get 1 on the first die (1 in 6 chance), 3 on the second (1 in 6 chance), and 5 on the third (1 in 6 chance). For \\((3,1,5)\\), the odds are the same. And so on. The answer to the second question is that there are 6 possible orderings of three distinct digits: \\((1,3,5), (1,5,3), (3,1,5), (3,5,1), (5,1,3), \\text{and } (5,3,1)\\). That’s because there are 3 possible choices for the first digit, 2 possible choices for the second digit, and 1 possible choice for the last digit. Combining these two answers, we find that for each of the 6 possible orderings, there is a 1 in 216 chance of getting that specific result. Since each possibility is distinct, we can just add them together to get a 6 in 216 chance of getting the numbers \\({1, 3, 5}\\) in some order on three dice. Finally, the probability is \\((1/6 \\times 1/6 \\times 1/6) \\times (3 \\times 2 \\times 1)\\) 4.3.13.7 Example Three dice are thrown. What is the probability that the same number appears on exactly two of the three dice? Solution. Since you need exactly two to be the same, there are three possibilities: (1) First and second, not third, (2) First and third, not second, (3) Second and third, not first. For the first possibility (1): The first die, you have probability of 6/6. The second die needs to be equal to the first, so you have probability of 1/6. Then the third die can’t be equal to the first and second die, so it’s 5/6. Finally you get \\(1\\times \\frac{1}{6} \\times \\frac{5}{6}\\). And since the next two possibilities (2) and (3) yield the same result, then the probability that the same number appears on exactly two of the three dice is \\[3 \\times (1 \\times \\frac{1}{6} \\times \\frac{5}{6}) = \\binom{3}{2}(1 \\times \\frac{1}{6} \\times \\frac{5}{6}) = \\frac{5}{12}\\] "],["wykład-5-zmienne-losowe-i-rozkłady-prawdopodobieństwa-ver-0-1.html", "5 Wykład 5. Zmienne losowe i rozkłady prawdopodobieństwa (ver. 0.1) ", " 5 Wykład 5. Zmienne losowe i rozkłady prawdopodobieństwa (ver. 0.1) "],["zmienna-losowa-i-rozkład-prawdopodobieństwa-definicje.html", "5.1 Zmienna losowa i rozkład prawdopodobieństwa - definicje", " 5.1 Zmienna losowa i rozkład prawdopodobieństwa - definicje Wynikiem doświadczenia losowego może być np. wyrzucenie orła lub reszki podczas pojedynczego rzutu monetą. Wtedy \\(S = \\{O, R\\}\\). Zwykle, dla wygody, chcemy, wszystkim możliwym wynikom pewnego doświadczenia losowego przypisać liczby ze zbioru R. W ten sposób określamy funkcję, która nazywana jest w statystyce zmienną losową. Zmienna losowa to funkcja, która przypisuje zdarzeniom elementarnym (zbiór argumentów funkcji) liczby (zbiór wartości funkcji). Zmienna losowa jest to funkcja, która elementom przestrzeni zdarzeń elementarnych S przyporządkowuje wartości ze zbioru liczb rzeczywistych R. Zmienne losowe oznaczamy wielkimi literami alfabetu np. X, Y, Z, natomiast konkretne wartości, które zmienna losowa może przyjąć literami małymi, x, y, z. Zmienne losowe zwykle oznaczamy wielkimi literami z końca alfabetu X, Y, Z etc. Realizacje zmiennej losowej \\(X\\) możemy oznaczyć np.: \\(X = \\{x_1, x_2, ...\\}\\) Zmienne losowe, w zależności od typu zbioru, który jest ich zbiorem wartości, dzielimy na skokowe lub ciągłe. 5.1.1 Przykład Wykonaj rzut dwiema monetami i odnotuj liczbę reszek (H). Wszystkie możliwe wyniki przedstawia tabela: Wynik doświadczenia losowego TT HT TH HH Liczba reszek 0 1 1 2 Powyższa tabela definiuje funkcję określoną na zbiorze zdarzeń elementarnych \\(S = \\{TT, HT, TH, HH\\}\\) (dziedzina funkcji) i z wartościami ze zbioru \\(X = \\{0, 1, 2\\} \\subseteq R\\). W ten sposób określona została zmienna losowa X - liczba wyrzuconych reszek podczas rzutu dwiema monetami. Np. dla wyniku \\(e = HH\\) przyjmuje ona wartość \\(x = 2\\). Jeżeli teraz zdefiniujemy nową funkcję \\(P(X = x)\\) lub po prostu \\(p(x)\\), w taki sposób, że każdej wartości zmiennej losowej X (argumenty nowej funkcji) przyporządkujemy odpowiednie prawdopodobieństwo jej zajścia, to powiemy, że określona została funkcja rozkładu prawdopodobieństwa lub po prostu rozkład prawdopodobieństwa zmiennej losowej X. Rozkład prawdopodobieństwa danej zmiennej losowej jest to funkcja przyporządkowująca wartościom zmiennej losowej prawdopodobieństwa przyjęcia danej wartości przez tę zmienną (zmienna skokowa) lub gęstości prawdopodobieństw odpowiadające poszczególnym wartościom zmiennej (zmienna ciągła). Rozkład prawdopodobieństwa może być dyskretny (gdy zmienna losowa jest skokowa) lub ciągły (gdy zmienna losowa jest ciągła). Rozkład prawdopodobieństwa jest to funkcja określona na zbiorze wartości pewnej zmiennej losowej, przypisująca prawdopodobieństwa lub gęstości prawdopodobieństwa wartościom tej zmiennej: \\(P: X_S \\rightarrow R\\) Dla przykładu, zdarzeniom elementarnym dla rzutu uczciwą monetą można przypisać wartości (zdefiniować zmienną losową) : \\(Reszka \\rightarrow 1\\) i \\(Orzeł \\rightarrow 0\\). Następnie, dla wartość 0 i 1 zmiennej losowej można określić prawdopodobienstwa (zdefiniować rozkład prawdopodobieństwa) : \\(1 \\rightarrow 0.5\\) oraz \\(0 \\rightarrow 0.5\\). 5.1.2 Zmienna losowa: dyskretna (skokowa) i ciągła "],["wybrane-skokowe-i-ciągłe-rozkłady-prawdopodobieństwa.html", "5.2 Wybrane (skokowe i ciągłe) rozkłady prawdopodobieństwa", " 5.2 Wybrane (skokowe i ciągłe) rozkłady prawdopodobieństwa W badaniach statystycznych stosuje się dwa podstawowe rodzaje rozkładów prawdopodobieństwa zmiennych losowych, a mianowicie rozkłady skokowe i rozkłady ciągłe. Rozkład zero-jedynkowy/Bernoulliego (skokowy) Rozkład jednostajny (skokowy lub ciągły) Rozkład dwumianowy (skokowy) Rozkład normalny (ciągły) 5.2.1 Rozkład zero-jedynkowy (Bernoulliego) 5.2.2 Rozkład zero-jedynkowy (Bernoulliego) Jest on związany z rezultatem doświadczenia (zwanego próbą Bernoulliego), w wyniku którego określone zdarzenie A wystąpi (1 = ‘sukces’) lub nie wystąpi (0 = ‘porażka’). Rozkład dwupunktowy jest funkcją przyporzadkowującą prawdopodobieństwa wynikom próby Bernoulliego. Rozkład ma jeden parametr p oznaczający prawdopodobieństwo ‘sukcesu’ : \\(X \\sim Bern(p)\\) 5.2.3 Rozkład Bernoulliego - równanie funkcji \\[f(k;p)=p^{k}(1-p)^{1-k} \\text{ dla } k\\in \\{0,1\\}\\] 5.2.4 Rozkład jednostajny (skokowy) 5.2.4.1 Rozkład jednostajny skokowy - równanie funkcji Jeśli \\(X \\sim U(a, b)\\), \\(a\\) i \\(b\\) \\(\\in \\{\\dots,-2,-1,0,1,2,\\dots\\}\\) \\(b \\geq a\\) \\(f(x) = \\frac{1}{n}\\), przy czym: \\(n=b-a+1\\) 5.2.5 Rozkład dwumianowy Jest to dyskretny rozkład prawdopodobieństwa opisujący prawdopodobieństwo liczby k ‘sukcesów’ w ciągu n niezależnych prób, z których każda ma stałe prawdopodobieństwo sukcesu równe p. Pojedynczy eksperyment nosi nazwę próby Bernoulliego. Rozkład ma dwa parametry : \\(X \\sim Bin(n, p)\\), przy czym n = liczba niezależnych prób, p = prawdopodobieństwo ‘sukcesu’. Zmienna losowa ma rozkład dwumianowy w następujących warunkach: wieoetapowy eksperyment losowy złożony ze skończonej liczby \\(n \\geq 1\\) prób (etapów), dokładnie dwa możliwe wyniki, zwyczajowo określane jako sukces (1) i porażka (0), prawdopodobieństwo sukcesu/porażki jest stałe na wszystkich etapach doświadczenia. 5.2.5.1 Rozkład dwumianowy - równanie funkcji Jeśli zmienna losowa ma rozkład dwumianowy: \\(X \\sim Bin(n, p)\\), \\(P\\)(k sukcesów w n próbach (trials)) = \\(C_k^n(p^k \\times (1-p)^{n-k})\\) gdzie: \\(p\\) = prawdopodobieństwo tzw. ‘sukcesu’ (oznaczane zwykle cyfrą \\(1\\)), czyli np. prawdopodbieństwo wyrzucenia dwóch szóstek w pięciu rzutach kością (\\(n = 5\\)); \\((1-p) = q\\) = prawdopodobieństwo tzw. ‘porażki’, oznaczane cyfrą \\(0\\). 5.2.5.2 Rozkład dwumianowy - wykres 5.2.5.3 Rozkład dwumianowy - przykład 1 Jakie jest prawdopodobieństwo \\(P\\), że przy 5 rzutach sześciościenną kością wypadną 2 szóstki? Jakie jest prawdopodobieństwo \\(P\\), że przy 5 rzutach sześciościenną kością otrzymamy 2 szóstki w następującej kolejności \\((6, 6&#39;, 6, 6&#39;,6&#39;)\\), czyli \\(P(6, 6&#39;, 6, 6&#39;,6&#39;) = ?\\) Przy czym, \\(6&#39;\\) oznacza, że nie wyrzucono \\(6\\) oczek. Odpowiedź na drugie (2.) pytanie: \\[P(6, 6&#39;, 6, 6&#39;,6&#39;) = \\frac{1}{6} \\times \\frac{5}{6} \\times \\frac{1}{6} \\times \\frac{5}{6} \\times \\frac{5}{6} = 0.0161\\] \\[P(6, 6&#39;, 6, 6&#39;,6&#39;) = (\\frac{1}{6})^2 \\times (\\frac{5}{6})^3 = 0.0161\\] Odpowiedź na pierwsze (1.) pytanie: Na ile możliwych sposobów można wyrzucić 2 szóstki w 5 rzutach kością (innymi słowy, w tzw. 5 próbach Bernoulliego)? \\(A = \\{(6&#39;, 6&#39;, 6, 6, 6), (6&#39;, 6, 6&#39;, 6, 6), (6&#39;, 6, 6, 6&#39;, 6), (6&#39;, 6, 6, 6, 6&#39;), (6, 6&#39;, 6&#39;, 6, 6), (6, 6&#39;, 6, 6&#39;, 6), (6, 6&#39;, 6, 6, 6&#39;), (6, 6, 6&#39;, 6&#39;, 6), (6, 6, 6&#39;, 6, 6&#39;), (6, 6, 6, 6&#39;, 6&#39;)\\}\\) \\[C_{2}^{5} = |\\{\\{1,2\\},\\{1,3\\},\\{1,4\\},\\{1,5\\},\\] \\[\\{2,3\\},\\{2,4\\},\\{2,5\\},\\{3,4\\},\\{3,5\\},\\{4,5\\}\\}| = 10\\] \\[P(\\text{dwie 6 w pięciu próbach}) = C_2^5((\\frac{1}{6})^2 \\times (\\frac{5}{6})^{5-2}) = \\] \\[= 10 \\times 0.0161 = 0.161\\] UWAGA (a) Zauważ, że ze zbioru \\(\\{6, 6&#39;\\}\\) można utworzyć \\(2^5 = 32\\) ciągów 5-wyrazowch. Zatem, zbiór zdarzeń elemenatrynych (\\(\\Omega\\)) w eksperycmecie polegającym na 5-krotnym rzucie sześciościenną kością do gry zawiera 32 elementy (np. \\((1,2,3,3,6) = (6&#39;,6&#39;,6&#39;,6&#39;,6)\\) t.j. wyrzucono jedną ‘szóstkę’ na pozycji nr 5). UWAGA (b) Rzucamy sześciościenną kością 2-razy. Ile jest wszystkich możliwych wyników? \\(6^2 = 36\\) (np. \\((1,6)\\)) UWAGA (c) \\(P(\\text{dwie 6 w pięciu próbach})\\) nie jest równe \\(\\frac{10}{32} = 0.3125\\). Dlaczego? 5.2.5.4 Rozkład dwumianowy - przykład 2 Załóżmy, że zdarzenia \\(A = 6\\) i \\(A&#39; = 6&#39;\\) są jednakowo prawdopodobne (sześciościenna kość ma na 3 ścianach 6 i na 3 pozostałych 6’). Wtedy: \\(P(\\text{dwie 6 w pięciu próbach})\\) = \\(\\frac{10}{32} = 0.3125\\) Korzystając z funkcji rozkładu dwumianowego: \\(P(\\text{dwie 6 w pięciu próbach}) = C_2^5((\\frac{1}{2})^2 \\times (\\frac{1}{2})^{5-2}) =\\) \\(= 0.3125 = 10/32 = 5/16\\) 5.2.5.5 Rozkład dwumianowy - przykład 3 Rzucamy \\(3\\) razy uczciwą monetą. Dla tego eksperymentu, określono zmienną losową Y = suma ‘sukcesów’, przyjmując, że wyrzucenie reszki (R) to ‘sukces’ (oznaczmy to zdarzenie cyfrą \\(1\\)). Zbuduj rozkład prawdopodbieństwa dla dla zmiennej Y. \\(X = \\{R, O\\}\\) i \\(X_1, X_2, X_3\\) \\(P_i\\) 1 ROO 0.125 2 ORO ? 3 OOR ? 4 ORR ? 5 RRO ? 6 ROR ? 7 RRR 0.125 8 OOO ? - - 1 Rozkład prawdopodobieństwa zmiennej Y przedstawia tabela: i Y \\(P_i\\) 1 3 0.125 2 2 ? 3 1 0.375 4 0 ? - - 1 5.2.6 Rozkład jednostajny ciągły 5.2.7 Rozkład jednostajny ciągły - równanie funkcji Jeśli: \\(X \\sim U(a, b)\\), \\(f(x)={\\begin{cases}{\\frac {1}{b-a}} &amp;\\mathrm {dla} \\ a\\leq x\\leq b, \\\\0 &amp;\\mathrm {dla} \\ x&lt;a\\ \\mathrm {lub} \\ x&gt;b\\end{cases}}\\) 5.2.7.1 Rozkład jednostajny ciągły - zadanie Można przyjąć, że rozkład prawdopodobieństwa zmiennej losowej X = czas oczekiwania na odjazd pociągu metra, jest rozkładem jednostajnym ciągłym. Jeśli pociąg metra linii A odjeżdża z przystanku dokładnie co 5 minut, to jakie jest prawdopodobieństwo, że pasażer po przybyciu na przystanek będzie czekał na odjazd więcej niż 3 minuty. 5.2.8 Rozkład normalny 5.2.8.1 Rozkład normalny - równanie funkcji Jeśli \\(X \\sim N(\\mu, \\sigma^2)\\), gdzie: \\(\\mu\\) - wartość oczekiwana zmiennej, \\(\\sigma^2\\) - wariancja zmiennej, \\[f(x; \\mu, \\sigma^2) = \\frac{1}{{\\sigma \\sqrt {2\\pi } }}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\] 5.2.9 Zmienna losowa i jej rozkład prawdopodobieństwa - przykłady 5.2.9.1 Przykład 1. Zmienna losowa W doświadczeniu losowym obejmującym rzut trzema uczciwymi monetami (\\(n = 3\\)), chcemy zapytać o prawdopodobieństwo wyrzucenia \\(k\\) reszek (R) - przyjmujemy umownie, że wyrzucenie reszki jest sukcesem, a wyrzucenie orła jest porażką. Zdefiniuj przestrzeń zdarzeń elementarnych i określ na tej przestrzeni zmienną losową Y. \\(Y\\) = suma wyników (“sukces” lub “porażka”) pojedynczych rzutów monetą oraz jej rozkład prawdopodobieństwa. Zauważ, że doświadczenie losowe z przykładu to tzw. doświadczenie (eksperyment) dwumianowy. Zmienna losowa, którą zdefiniujemy będzie zmienną dwumianową, a w konsekwencji powstanie dwumianowy rozkład prawdopodobieństwa. Eksperyment dwumianowy ma następujące cechy: Eksperyment składa się z n etapów (trials) - z tzw. prób (Bernoullego). Dwumianowa zmienna losowa (zmienna o rozkładzie dwumianowym) jest sumą zmiennych Bernoullego (zmiennych o rozkładzie Bernoullego/rozkładzie zero-jedynkowym z parametrem p = prawdopodobieństwo sukcesu): \\(Y = X_1 + X_2 + ... + X_n\\) Każda pojedyncza próba Bernoullego (pojedynczy rzut monetą, losowanie z populacji wyborców jednego wyborcy itp.) ma tylko dwa możliwe wyniki - sukces (1) i porażkę (0). Prawdopodobieństwo sukcesu oznaczamy p, jest identyczne na każdym etapie doświadczenia. Wyniki z poszczególnych etapów doświadczenia są od siebie niezależne (możemy więc korzystać z metod obliczania prawdopodobieństw dla zdarzeń niezależnych); tzn., że wyniki z poszczególnych etapów nie wpływają na siebie; np. wyrzucenie orła na pierwszym etapie doświadczenia nie modyfikuje prawdopodobieństwa wyrzucenia orła/reszki na pozostałych etapach. Zacznijmy od określenia przestrzeni zdarzeń elementarnych \\(S\\). \\(S = \\{ (R, R, R), (R, R, O), (R, O, O), (O, O, O), (O, O, R), (O, R, R), (O, R, O), (R, O, R) \\}\\). Liczebność zbioru \\(S\\) (\\(|S|\\)) możemy wyznaczyć stosując wzór na liczbę \\(r\\)-permutacji (liczbę r-wyrazowych ciągów) z powtórzeniami, ze zbioru \\(x\\) możliwych wartości: \\(P_r^x = x^r\\). W tym przykładzie mamy \\(2^3 = 8\\). Aby określić zmienną losowa na zbiorze \\(S\\) musimy poszczególnym wynikom przypisać liczby wg pewnej reguły. Np. możemy przyjąć, że wyrzucenie 1 reszki to 1, dwóch reszek 1 + 1 itd. I tak, możemy zdefiniować zmienną Y: \\((R, R, R) \\rightarrow 3\\); \\((R, R, O) \\rightarrow 2\\); \\((O, R, R) \\rightarrow 2\\); \\((...) \\rightarrow ...\\); \\((O, O, O) \\rightarrow 0\\). Następnie, jeśli przypiszemy każdej ustalonej wartości zmiennej losowej Y odpowiednie prawdopodobieństwa, \\(P(Y = ...) = ...\\), zbudujemy odpowiadający tej zmiennej rozkład prawdopodobieństwa. W rozważanym przypadku, wartości prawdopodobieństwa znajdziemy korzystając z funkcji rozkładu dwumianowego z parametrami \\(p = 0.5 \\text{ i } n = 3\\) - jak wynika z opisu doświadczenia losowego, zmienna Y ma rozkład dwumianowy, \\(Y = \\{0, 1, 2, 3\\}\\). Możemy ten rozkład przedstawić np. tabelarycznie (Zob. tablica nr 1). y f(y) = p formuła 1 0 1/8 \\(f(x; n=3, p=0.5) = \\binom{3}{0}0.5^0(1-0.5)^3\\) 2 1 3/8 \\(f(x; n=3, p=0.5) = \\binom{3}{1}0.5^1(1-0.5)^2\\) 3 2 3/8 \\(f(x; n=3, p=0.5) = \\binom{3}{2}0.5^2(1-0.5)^1\\) 4 3 1/8 \\(f(x; n=3, p=0.5) = \\binom{3}{3}0.5^3(1-0.5)^0\\) - - 1 - Rozkład prawdopodobieństwa zmiennej Y Dlaczego prawdopodobieństwo wyrzucenia, na przykład, 1 reszki (1 sukces) jest równe 3/8? W tym przykładzie, prawdopodobieństwo sukcesu p (wyrzucenia reszki) jest równe \\(1/2\\), dlatego prawdopodobieństwo porażki (zdarzenia przeciwnego) też wynosi \\(1/2\\), bo \\(1-1/2 = 1/2\\). Eksperyment losowy z przykładu jest tzw. złożonym (wieloetapowym) eksperymentem - składa się z trzech etapów (lub prób (trials)) - pierwszy rzut, drugi rzut i trzeci rzut monetą - dlatego n = 3 (liczba etapów/rozmiar próby (sample)). W przypadku eksperymentu złożonego, stosujemy regułę mnożenia (w tym przykładzie możemy użyć reguły mnożenia dla niezależnych zdarzeń losowych) do obliczenia prawdopodobieństw. Rozpocznijmy od obliczenia prawdopodobieństwa otrzymania w eksperymencie 3-etapowym jednej reszki w pewnym z góry ustalonym porządku (np. prawdopodobieństwo pojawienia się ciągu (R,O,O)): \\[P((R,O,O)) = P((1,0,0)) = p^1 \\times (1-p)^2 = (1/2)^1 \\times (1/2)^2 = 1/8\\] Ponadto, \\[P((O,R,O)) = P((0,1,0)) = (1-p) \\times p \\times (1-p) = (1/2) \\times (1/2) \\times (1/2) = 1/8\\] \\[P((O,O,R)) = P((0,0,1)) = (1-p)^2 \\times p^1 = (1/2)^2 \\times (1/2)^1 = 1/8\\] Wtedy, prawdopodobieństwo wyrzucenia reszki na jednym z 3 etapów w dowolnej kolejności wynosi: \\[P(\\{(R,O,O), (O,R,O), (O,O,R)\\}) = P((R,O,O)) + P((O,R,O)) + P((O,O,R)) =\\] \\[= 1/8 + 1/8 + 1/8 = 3/8 =\\] \\[= \\binom{3}{1} \\times (1/2)^1 \\times (1/2)^2 = 3 \\times (1/2)^1 \\times (1/2)^2 = 3/8\\] Ogólnie, prawdopodobieństwo wylosowania x reszek w n próbach (trials) w dowolnej kolejności jest równe: \\[P(X = x) = f(x; n = \\text{liczba prób}, p = \\text{prawdopodobieństwo sukcesu}) = \\\\ = \\binom{n}{x} p^x(1-p)^{n-x} = \\frac{n!}{(n-x)!x!} p^x(1-p)^{n-x}, \\text{ dla } x = 0, 1, 2, ..., n\\] Zauważ, że \\(\\binom{3}{1} = |\\{\\{1\\}, \\{2\\}, \\{3\\}\\}| = 3\\) - jest to liczba 1-elementowych kombinacji ze zbioru 3-elementowego. W przypadku tzw. eksperymentu dwumianowego, można myśleć o każdej pojedynczej kombinacji ze zbioru n-elementów jak o zbiorze zawierającym współrzędne wskazujące miejsce sukcesu/sukcesów w ciągu wyników. W analizowanym przykładzie, zbiory \\(\\{1\\}, \\{2\\}, \\{3\\}\\) wskazują, że sukces (reszka) może się pojawić tylko na pierwszym, tylko na drugim lub tylko na trzecim etapie. Jeśli mielibyśmy współczynnik dwumianowy \\(\\binom{3}{2} = 3 = |\\{\\{1,2\\}, \\{1,3\\}, \\{2,3\\}\\}|\\), to elementy zbiorów \\(\\{1,2\\}, \\{1,3\\}, \\{2,3\\}\\) wskazują, że reszka (sukces) może się pojawić tylko na pierwszym i jednocześnie na drugim etapie, tylko na pierwszym i trzecim, albo tylko na drugim i trzecim etapie. Nie wolno mylić ciągu np. \\((H, T, H)\\) ze zbiorem \\(\\{H, T, H\\} = \\{H, T\\} = \\{T, H\\}\\). 5.2.9.2 Przykład 2. Rozkład dwumianowy i jego przybliżenie rozkładem normalnym Zmienna losowa X - liczba wyrzuconych reszek w n rzutach dobrze wywarzoną monetą - ma rozkład dwumianowy. Jeżeli prawdopodobieństwo wyrzucenia reszki \\(p\\) jest równe \\(0.5\\), to jakie jest prawdopodobieństwo, że w 10 rzutach monetą wypadnie co najmniej 7 reszek. Dane: \\(X \\sim Bin(10, 0.5)\\) Rozwiązanie: Stosujemy równanie funkcji rozkładu dwumianowego: \\[P(X = x) = f(x; n, p) = \\binom{n}{x} p^x(1-p)^{n-x}, \\text{dla } x = 0, 1, 2, ..., n\\] Skumulowana postać funkcji rozkładu dwumianowego dana jest równaniem: \\[F(x) = P(X \\leq x) = \\sum_{a=0}^x \\binom{n}{a} p^a(1-p)^{n-a}, \\text{dla } x = 0, 1, 2, ..., n\\] Podstawiając do wzoru odpowiednie wartości otrzymujemy: \\[P(X \\geq 7 | n = 10, p = 0.5) = P(X = 7) + P(X = 8) + P(X = 9) + P(X = 10) =\\] \\[= \\sum_{a = 7}^{10} \\binom{10}{a} 0.5^a(1-0.5)^{10-a} =\\] \\[\\binom{10}{7}(\\frac{1}{2})^7(\\frac{1}{2})^3 + \\binom{10}{8}(\\frac{1}{2})^8(\\frac{1}{2})^2 + \\binom{10}{9}(\\frac{1}{2})^9(\\frac{1}{2})^1 + \\binom{10}{10}(\\frac{1}{2})^{10}(\\frac{1}{2})^0 = \\frac{176}{1024}\\] Jeżeli zmienna losowa \\(X \\sim Bin(100, 0.6)\\). Jakie jest \\(P(X \\geq 65) = P(\\frac{X}{n} \\geq 0.65)\\)? Z teorii statystyki wiadomo, że rozkład zmiennej X można przybliżyć rozkładem normalnym z parametrami \\(\\mu = np\\) i \\(\\sigma = \\sqrt{np(1-p)}\\), co zapisujemy \\(N(np, \\sqrt{np(1-p)})\\). Ogólnie mówiąc, z twierdzeń rachunku prawdopodobieństwa (tzw. twierdzeń granicznych) wynika, że im większa jest wartość n, tym bardziej kształt rozkładu dwumianowego przypomina kształt rozkładu normalnego, przy założeniu, że \\(np &gt; 5\\) i \\(n(1-p) &gt; 5\\). Dla proporcji \\(\\frac{X}{n}\\), przy czym X ma rozkład dwumianowy, mamy następujący układ parametrów: \\(\\mu = p\\) i \\(\\sigma = \\sqrt{\\frac{p(1-p)}{n}}\\), co zapisujemy \\(N(p, \\sqrt{\\frac{p(1-p)}{n}})\\). W przykładzie mamy \\(p = 0.6\\) i \\(n = 100\\), więc \\(\\frac{X}{n} \\sim N(0.6, 0.0489)\\). Teraz możemy zastosować przybliżenie rozkładu dwumianowego (rozkład zmiennej dyskretnej) rozkładem normalnym (rozkład zmiennej ciągłej). Wartości prawdopodobieństw obliczonych dla zmiennych o rozkładzie normalnym z parametrami \\(\\mu = 0\\) i \\(\\sigma = 1\\) zostały stablicowane, dlatego łatwo można szukane prawdopodobieństwa znaleźć. Jednak, żeby wykorzystać tablice i nie liczyć wartości całek funkcji gęstości rozkładu normalnego musimy wartości zmiennej \\(\\frac{X}{n} \\sim N(0.6, 0.0489)\\) przekształcić w taki sposób, aby utworzona w wyniku tego przekształcenia zmienna pomocnicza, zwyczajowo określana jako zmienna Z, miała rozkład \\(N(0, 1)\\). Takie przekształcenie nazywamy standaryzacją zmiennej losowej. Korzystamy z faktu, że jeśli zmienna \\(X \\sim N(\\mu, \\sigma)\\), to zmienna \\(Z = \\frac{(X-\\mu)}{\\sigma} \\sim N(0, 1)\\). Czyli, dla rozważanego przykładu mamy \\(Z = \\frac{\\frac{X}{n} – p}{\\sqrt{\\frac{p(1-p)}{n}}}\\), a konkretnie dla wartości \\(\\frac{X}{n} = 0.65\\) otrzymujemy wartość \\(Z = 1.02\\), czyli \\(P(\\frac{X}{n} \\geq 0.65) = P(Z \\geq 1.02)\\). Po standaryzacji można teraz prawidłową wartość odczytać z tablic rozkładu normalnego. Otrzymujemy ostatecznie, że \\(P(\\frac{X}{n} \\geq 0.65) = P(Z \\geq 1.02) = 1 – P(Z \\leq 1.02)\\), odczytując bezpośrednio z tablic otrzymujemy wynik \\(= 1 – 0.8461 = 0.1539 = 15.39\\%\\). Odp.: \\(P(\\frac{X}{n} \\geq 0.65) = 15.39\\%\\) Uzyskane przybliżenie jest dość dobre, ale z praktyki i teorii statystyki wynika, że lepsze przybliżenie uzyskamy jeżeli zamiast poszukiwać \\(P(X \\geq 65) = P(\\frac{X}{n} \\geq 0.65)\\), obliczymy \\(P(X \\geq 64.5) = P(\\frac{X}{n} \\geq 0.645)\\). Taka korekta zadania gwarantuje uzyskanie lepszego przybliżenia. Ogólnie, przybliżając (aproksymując) rozkład dwumianowy rozkładem normalnym, do wartości zmiennej np. \\(X\\) dodajemy (gdy szukamy np. \\(P(X \\leq x)\\)) lub odejmujemy 0.5 (gdy poszukujemy \\(P(X \\geq x)\\)). Sprawdź, czy rzeczywiście wynik będzie bardziej dokładny, jeżeli wiadomo, że prawidłowa szukana wartość prawdopodobieństwa dla \\(X \\geq 65\\) i obliczona za pomocą funkcji rozkładu dwumianowego \\(= 0.1795\\). Badania na reprezentatywnych próbach pozwoliły ustalić, że 55% ankietowanych deklaruje chęć oddania głosu na polityka A w zbliżających się wyborach do rady miejskiej. Kandydat jednak prognozuje lepszy wynik wyborczy i uważa, że poprze go co najmniej 65% wyborców. Przyjmując, że zmienna losowa \\(X\\sim Binom(n, 0.55)\\), jakie jest prawdopodobieństwo, że poparcie polityka w grupie liczącej 100 losowo wybranych wyborców wyniesie przynajmniej 65% = 0.65 (tj. prawdopodobieństwo, że \\(X \\geq 65\\))? Dane: \\(X\\sim Binom(100, 0.55)\\) Rozwiązanie: Szukamy prawdopodobieństwa \\(P(\\frac{X}{n}\\geq 0.65) = P(X\\geq 65)\\). \\[P(X \\geq 65 | n = 100, p = 0.55) = \\sum_{a = 65}^{100} \\binom{100}{a} 0.55^a(1-0.55)^{100-a} = 0.0272\\] Niestety, jeżeli nie mamy dostępu do dobrego oprogramowania statystycznego, wyznaczenie wartości szukanego prawdopodobieństwa z zastosowaniem rozkładu dwumianowego może się okazać bardzo uciążliwe. Należy pamiętać, że rozkład zmiennych o rozkładzie dwumianowym oraz rozkład proporcji \\(\\frac{X}{n}\\) można przybliżyć rozkładem normalnym, gdy \\(np\\) i \\(n(1-p) \\geq 5\\). Wówczas \\(X \\sim N(\\mu = np, \\sigma = \\sqrt{np(1-p)})\\) lub \\(\\widehat{p} = \\frac{X}{n} \\sim N(\\mu = p, \\sigma = \\sqrt{\\frac{p(1-p)}{n}})\\). W celu skorzystania z rozkładu normalnego należy na podstawie dostępnych danych ustalić wartość parametrów tego rozkładu, a więc wartość średniej \\(\\mu\\) i odchylenia standardowego \\(\\sigma\\). Żeby obliczyć wartość prawdopodobieństwa dokonujemy standaryzacji zmiennej X. Nie wiemy ile wynosi p, więc korzystamy z oszacowania na podstawie wcześniejszych badań. Otrzymujemy \\(Z = \\frac{0.65-0.55}{\\sqrt{\\frac{0.55(1-0.55)}{100}}} = 2.01\\). Otrzymana liczba, to wartość 65 na skali zmiennej \\(Z \\sim N(0, 1)\\). Ostatni krok to odczytanie wartości całki funkcji gęstości rozkładu normalnego dla zmiennej standaryzowanej Z w przedziale \\((2.01, +\\infty)\\). Całka ta jest równa 1 - 0.9778 = 0.0222. Szukane P wynosi ok. 2.2%. Warto pamiętać, że lepsze przybliżenie otrzymamy, gdy od wartości zmiennej dwumianowej odejmiemy 0.5, czyli, gdy będziemy szukać prawdopodobieństwa w rozkładzie normalnym dla liczby 64.5 zamiast 65. Wtedy mamy \\(Z = 1.91\\) i \\(P = 2.8\\%\\). Na podstawie wcześniejszych badań na reprezentatywnej próbie ustalono, że proporcja (frakcja, częstość względna) Polaków, którzy mają zaufanie do prezydenta RP wynosi 0.6 = 60%. Przyjmując, że zmienna losowa X = liczba osób ufająca urzędującemu prezydentowi, ma rozkład dwumianowy, \\(X \\sim Bin(n, 0.6)\\), jakie jest prawdopodobieństwo, że w 15 osobowej grupie losowo wybranych Polaków, co najwyżej 3 (czyli \\(\\widehat{p} = 0.2 = \\frac{3}{15}\\)) ufa prezydentowi RP? Dane: \\(X \\sim Bin(15, 0.6)\\) Rozwiązanie: Ponieważ zmienna ma rozkład dwumianowy, więc korzystamy w obliczeniach z równania funkcji rozkładu dwumianowego. W tym przypadku nie jest konieczne korzystanie z przybliżenia rozkładu dwumianowego rozkładem normalnym (chociaż spełniony jest dla danych z przykładu warunek \\(np\\) i \\(n(1-p) &gt; 5\\)), gdyż dla rozważanego przykładu obliczenia można wykonać przy użyciu kalkulatora naukowego. Jeżeli zdecydujemy się wykonać dokładne obliczenia za pomocą rozkładu dwumianowego, to dla rozważanego przykładu należy stosować przybliżenie otrzymywanych w obliczeniach wartości do co najmniej 7 miejsca po przecinku, gdyż otrzymywane prawdopodobieństwa są bardzo małe i licząc z mniejszą dokładnością wynik nie będzie wystarczająco dokładny. Ponieważ szukamy sumy wartości funkcji dla X = 0, 1, 2 i 3, to wykorzystujemy tzw. skumulowaną postać funkcji rozkładu: \\[F(x) = P(X \\leq x) = \\sum_{a=0}^x \\binom{n}{a} p^a(1-p)^{n-a}, \\text{dla } x = 0, 1, 2, ..., n\\] Podstawiając otrzymujemy: \\[P(X \\leq 3 | n = 15, p = 0.6) = \\sum_{x=0}^{3}\\binom{15}{x}0.6^x(1-0.6)^{15-x} =\\] \\[= \\sum_{x=0}^{3}\\frac{15!}{(15-x)!x!}0.6^x(1-0.6)^{15-x} =\\] \\[= \\binom{15}{0}0.6^0(1-0.6)^{15-0} + \\binom{15}{1}0.6^1(1-0.6)^{15-1} +\\] \\[+ \\binom{15}{2}0.6^2(1-0.6)^{15-2} + \\binom{15}{3}0.6^3(1-0.6)^{15-3} =\\] \\[= \\frac{15!}{(15)!0!}0.6^0(0.4)^{15-0} + \\binom{15}{1}0.6^1(0.4)^{15-1} +\\] \\[+ \\binom{15}{2}0.6^2(0.4)^{15-2} +\\] \\[\\frac{1\\times2\\times3\\times...\\times15}{(1\\times2\\times3\\times...\\times12)1\\times2\\times3}0.6^3(1-0.6)^{15-3} =\\] \\[= \\frac{15!}{(15)!0!}0.6^0(0.4)^{15-0} + \\binom{15}{1}0.6^1(0.4)^{15-1} +\\] \\[+ \\binom{15}{2}0.6^2(0.4)^{15-2} + \\frac{13\\times14\\times15}{1\\times2\\times3}0.6^3(0.4)^{15-3} = 0.0019.\\] Inna metoda* pozwalająca obliczyć szukane prawdopodobieństwo polega na wykorzystaniu rozkładu normalnego. Stosując metodę przybliżenia rozkładu dwumianowego rozkładem normalnym musimy skorygować wartość zmiennej \\(X\\) i dodać liczbę \\(\\frac{1}{2}\\). Zamiast \\(X = 3\\), obliczenia wykonujemy dla \\(X = 3.5\\) lub dla \\(\\widehat{p} = 0.233(3) = \\frac{7}{30}\\). \\[P(X \\leq 3.5 | n = 15, p = 0.6) = \\int_{t_0(-\\infty)}^{t_1(x = 3.5)}\\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-(t-\\mu)^2/(2 \\sigma^2)}dt =\\] \\[= P(Z &lt; \\frac{3.5-np}{\\sqrt{p(1-p)n}}) = P(Z &lt; -2.9) = \\int_{t_0(-\\infty)}^{t_1(z = -2.9)}\\frac{1}{\\sigma \\sqrt{2\\pi}}e^{\\frac{-t^2}{2}}dt = 0.0019.\\] Dla zmiennych ciągłych \\(P(Z &lt; z) = P(Z \\leq z)\\) oraz \\(P(Z &gt; z) = P(Z \\geq z)\\). Możemy też zmienną X przekształcić dzieląc przez n i wykonywać obliczenia dla frakcji z próby \\(\\frac{X}{n} = \\widehat{p}\\). Wynik nie ulegnie zmianie. Trzeba jedynie pamiętać o modyfikacji wzorów dla \\(\\mu\\) i \\(\\sigma\\). \\[P(\\frac{X}{n} \\leq \\frac{3.5}{15} = \\frac{7}{30} | n = 15, p = 0.6) = \\int_{t_0(-\\infty)}^{t_1(\\frac{7}{30})}\\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-(t-\\mu)^2/(2 \\sigma^2)}dt =\\] \\[= P(Z &lt; \\frac{\\frac{7}{30}-p}{\\sqrt{\\frac{p(1-p)}{n}}}) = P(Z &lt; -2.9) = P(Z &gt; 2.9) = 1 - P(Z &lt; 2.9) = 0.0019.\\] Otrzymane przybliżenie jest bardzo dokładne. Oczywiście nie musimy liczyć całek funkcji gęstości prawdopodobieństwa rozkładu normalnego. Wartości te dla zmiennej standaryzowanej Z zostały stablicowane i szukane prawdopodobieństwo odczytujemy z tablic mając świadomość, że rozkład normalny jest rozkładem symetrycznym (oś symetrii wyznacza wartość \\(\\mu\\)). Odp.: Prawdopodobieństwo, że w 15 osobowej grupie losowo wybranych Polaków, co najwyżej 3 ufa prezydentowi RP wynosi w przybliżeniu 0.0019 = 0.19%, czyli jest bardzo małe. 5.2.9.3 Przykład 3. Rozkłady zmiennych ciągłych - rozkład jednostajny i rozkład normalny Przybywasz na peron metra w pewnym mieście nie znając rozkładu jazdy. Jeżeli zmienna losowa X - czas oczekiwania na pociąg metra w minutach - ma rozkład jednostajny z parametrami \\(a = 0\\) i \\(b = 6\\), \\(X \\sim U(0, 6)\\), jakie jest prawdopodobieństwo, że czas oczekiwania na przyjazd wyniesie co najmniej 4 minuty? Rozwiązanie: Z treści zadania wiadomo, że czas oczekiwania na pociąg metra może wynieść maksymalnie 6 minut. W najlepszym przypadku pociąg wjedzie na peron dokładnie w chwili, gdy ty się na nim pojawisz - czas oczekiwania = 0. Równanie funkcji gęstości rozkładu jednostajnego: \\[P(X = x) = f(x; a, b) = \\frac{1}{b - a}, \\text{ dla } 0 \\leq x \\leq 6\\] Całkując funkcję gęstości w przedziale \\([0, x]\\), otrzymujemy: \\(P(X &lt; x) = \\frac{x}{b-a}\\), dlatego, \\[P(X \\geq 4) = 1 - P(Z &lt; 4) = 1 - \\frac{4}{6-0} = \\frac{1}{3}\\] Odp: Prawdopodobieństwo, że czas oczekiwania na przyjazd wyniesie co najmniej 4 minuty = \\(\\frac{1}{3}\\). Dla X będącej zmienną losową mającą normalny rozkład gęstości prawdopodobieństwa z parametrami \\(E(X) = 72\\) i \\(Var(X) = 144\\), oblicz: \\(P(X &lt; 84)\\) \\(P(60 &lt; X &lt; 69)\\) \\(P(X \\geq 102)\\) Rozwiązanie: Ponieważ chcemy rozwiązać zadanie korzystając z tablicy wartości całki funkcji gęstości rozkładu normalnego, to wpierw wartości zmiennej X, dla których prawdopodobieństwo chcemy wyznaczyć musimy poddać standaryzacji tworząc pomocniczą zmienną losową Z. Stosujemy ogólną formułę: \\(Z = \\frac{Y - \\mu_Y}{\\sigma_Y}\\) i obliczamy wartości zmiennej Z dla poszczególnych wartości Y. a) Jest mniejsza od 84 \\([P(X &lt; 84)]\\). Oblicz \\(P(X &lt; x) = P(Z &lt; \\frac{X – \\mu_X}{\\sigma_X}) \\rightarrow P(Z &lt; z)\\) – w tym przypadku bezpośrednio odczytujemy z tablic prawdopodobieństwo dla Z = jakaś liczba z uzyskana w wyniku standaryzacji \\(Z = \\frac{X – \\mu_X}{\\sigma_X}\\). Trzeba tutaj napisać, że \\(P(X &lt; 84) = P(Z &lt; [(84 – 72) / 12] = 1)\\) i wówczas odczytujemy wartość z tablic dla Z = 1. Otrzymujemy 0.8413. b) Należy do przedziału (60, 69). Oblicz \\(P(x_1 &lt; X &lt; x_2) \\rightarrow P(z_1 &lt; Z &lt; z_2)\\), czyli Z należy do przedziału \\((z_1, z_2)\\) – w tym przypadku liczymy w następujący sposób: \\(P(Z &lt; z_2) – P(Z &lt; z_1)\\). Zatem, \\(P(60 &lt; X &lt; 69) = P(-1 &lt; Z &lt; -0.25) = P(Z &lt; -0.25) – P(Z &lt; -1)\\), odczytujemy wartości prawdopodobieństwa z tablic i mamy 0.4013 – 0.1587 = 0.2426. c) Jest większa lub równa od 102. Oblicz \\(P(X &gt; x) \\rightarrow P(Z &gt; z)\\) – w tym przypadku przekształcamy zadanie do postaci \\(1 – P(Z &lt; z)\\). Zatem, \\(P(X &lt; 102) = P(Z &lt; 2.5)\\), odczytujemy z tablic prawdopodobieństwo dla \\(Z = 2.5\\) i mamy 0.9938, dalej mamy \\(1 – 0.9938 = 0.0062\\). 5.2.10 Podstawowe rozkłady prawdopodobieństwa - podsumowanie Dwa podstawowe rozkłady skokowe to: rozkład Bernoulliego (dwupunktowy), \\[X\\sim Bern(\\text{parametr: p = prawdopodobieństwo sukcesu})\\] Dla X, która ma rozkład dwupunktowy prawdziwe są następujące wzory: \\[E(X) = p\\] \\[Var(X) = p(1-p)\\] rozkład dwumianowy, \\[X\\sim Bin(\\text{parametry: p = prawdopodobieństwo sukcesu, n = liczba prób (trials)})\\] Dla Y, która ma rozkład dwumianowy prawdziwe są następujące wzory: \\[E(Y) = np\\] \\[Var(Y) = np(1-p)\\] Ponadto, jeżeli \\(Y = X_1 + X_2 + ... + X_n\\), gdy zmienne \\(X_i \\sim Bern(p)\\) oraz \\(\\mu_{X_i} = p, \\sigma_{X_i} = \\sqrt{p(1-p)}\\), to dla zmiennej \\[\\bar{Y} = \\frac{Y}{n} = \\hat{p}\\] prawdziwe są wzory \\[E(\\hat{p}) = \\mu_{\\hat{p}} = p\\] \\[\\sigma_{\\hat{p}} = \\sqrt{\\frac{p(1-p)}{n}}\\] Dwa podstawowe rozkłady ciągłe to: rozkład jednostajny, \\[X\\sim U(\\text{parametry: a = wartość najmniejsza zmiennej, b = wartość największa zmiennej})\\] rozkład normalny, \\[X\\sim N(\\text{parametry}: \\mu = \\text{wartość przeciętna}, \\sigma = \\text{odchylenie standardowe})\\] Należy też pamiętać, że rozkład jednostajny występuje też w postaci skokowej, np. rozkład zmiennej losowej X = liczba oczek, które wypadły podczas rzutu sześcienną, symetryczną kością. "],["wykład-6-podstawy-wnioskowania-statystycznego.html", "6 Wykład 6. Podstawy wnioskowania statystycznego ", " 6 Wykład 6. Podstawy wnioskowania statystycznego "],["rozkład-statystyki-z-próby-i-centralne-twierdzenie-graniczne.html", "6.1 Rozkład statystyki z próby i centralne twierdzenie graniczne", " 6.1 Rozkład statystyki z próby i centralne twierdzenie graniczne Statystyka (a sample statistic): Wielkość obliczona na podstawie obserwacji z próby statystycznej (np. średnia lub proporcja z próby). Statystyką (z próby) nazywamy zmienną losową, np. Z, będącą funkcją zmiennych losowych \\(X_1, X_2, ..., X_n\\) stanowiących prostą próbę losową. Statystyka jako funkcja zmiennych losowych sama jest zmienną losową, która posiada pewien rozkład prawdopodobieństwa. We wnioskowaniu statystycznym chcemy wykorzystać charakterystyki próby (tj. statystyki) do oszacowania cech populacji (tj. parametrów populacji). Jeśli otrzymamy próbkę losową i obliczymy statystykę z próby z tej próbki, to statystyka z próby jest zmienną losową. Rozkład statystyki z próby (a sampling distribution): obserwowana wartość statystyki zależy od konkretnej próby wybranej z populacji i będzie się różnić w zależności od próbki. Tę zmienność statystyki z próby opisuje jej rozkład prawdopodobieństwa z próby. "],["rozkład-statystyki-z-próby-średnia-próbki-proporcja-próbki-itp-.html", "6.2 Rozkład statystyki z próby (średnia próbki, proporcja próbki itp.)", " 6.2 Rozkład statystyki z próby (średnia próbki, proporcja próbki itp.) Statystyka z próby, taka jak średnia z próby lub odchylenie standardowe próbki, to wskaźnik obliczony na podstawie próbki. Ponieważ próbka jest losowa, każda statystyka jest zmienną losową: różni się w zależności od próby w sposób, którego nie można przewidzieć z pewnością. Jako zmienna losowa, statystyka ma wartość oczkiwaną (średnią), odchylenie standardowe i rozkład prawdopodobieństwa. Rozkład prawdopodobieństwa statystyki nazywany jest rozkładem statystyki z próby. Zwykle statystyki próby są obliczane w celu oszacowania odpowiednich parametrów populacji. Rozkład statystyki z próby to rozkład prawdopodobieństwa statystyki z próby, który jest tworzony, gdy próbki o rozmiarze \\(n\\) są wielokrotnie pobierane z populacji. Jeśli statystyka z próby jest średnią z próby, to taki rozkład nazywamy rozkładem średniej z próby. Każda statystyka, jako zmienna losowa, ma rozkład z próby (a sampling distribution of a statistic). Rozkład statystyki z próby to rozkład tej statystyki dla wszystkich możliwych prób z tej samej populacji o danej wielkości próby. Odchylenie standardowe rozkładu statystyki z próby nazywane jest błędem standardowym tej statystyki Rozważ poniższy diagram Venna (rysunek 6.1). Rysunek 6.1. Pojęcie rozkładu statystyki (np. średniej) z próby (a sampling distribution) Prostokąt na diagramie 6.1 przedstawia dużą populację, a każdy okrąg reprezentuje próbkę o rozmiarze n. Ponieważ obserwacje wybrane do próby mogą się różnić, przykładowe średnie z próby również mogą się różnić. Średnia z Próbki 1 (S1) wynosi \\(\\bar{x}_1 = 3,5\\); średnia z Próbki 2 wynosi \\(\\bar{x}_2\\); i tak dalej. Rozkład średniej z próby dla prób o rozmiarze n dla tej populacji tworzą średnie z wszystkich możliwych prób \\(\\bar{x}_1, \\bar{x}_2, \\bar{x}_3\\) itd. Jeśli próbki są pobierane ze zwracaniem (sampling with replacement), wówczas z populacji można pobrać nieskończoną liczbę próbek. 6.2.1 Rozkład próbkowania średniej próby Załóżmy, że populacja składa się z czterech domów (N = 4), gdzie wartość rv. X, liczba pokojów do wynajęcia w każdej jednostce, jest podana poniżej: dom pierwszy (2 pokoje), dom drugi (3 pokoje), dom trzeci (4 pokoje), dom czwarty (5 pokojów). Rozważ losowanie próby rozmiaru 2 (losowanie z powtórzeniami/ze zwracaniem). Istnieją cztery możliwości przy pierwszym losowaniu z populacji, a także cztery możliwości przy drugim losowaniu z populacji. Oznacza to, że wybieramy losowo jednostkę, odkładamy ją, a następnie wybieramy losowo inną jednostkę. Oznaczmy obserwacje na zmiennej X jako X1 (wynik pierwszego losowania) i X2 (wynik drugiego losowania). Rozkład z populacji zmiennej \\(X\\) (a population distribution of \\(X\\)) przedstawiono w tabeli 6.1. Table 6.1. Rozkład X w populacji i X Prawdopodobieństwo 1 2 1/4 2 3 1/4 3 4 1/4 4 5 1/4 Suma - 1 Znajdź rozkład średniej z próbki \\(\\bar{X} = (X1 + X2) / 2\\). W praktyce z populacji zostanie pobrana tylko jedna próba losowa, a nie 16 możliwych próbek; w prawdziwym badaniu, wielkość próby byłaby bardzo mała w stosunku do znacznie większej liczebności populacji i oczywiście nie wszystkie obserwacje w populacji byłyby znane. Dla każdej z 16 możliwych próbek (patrz Tabela 6.2) również podano średnią z próby (uzyskaną przez dodanie dwóch obserwacji i podzielenie przez 2) oraz prawdopodobieństwo wystąpienia (wyrażone jako 1⁄16, ponieważ każda z 16 możliwych próbek jest jednakowo prawdopodobna). Po uwzględnieniu względnego rozkładu częstości lub prawdopodobieństwa, 16 średnich z próby tworzy rozkład średniej z próby, wcześniej zdefiniowany jako rozkład prawdopodobieństwa średnich dla wszystkich możliwych losowych próbek o danej wielkości z jakiejś populacji. Table 6.2. Wszystkie możliwe 2-elementowe próby i Wszystkie możliwe próby (4 * 4 = 16) Średnia (\\(\\bar{X}\\)) Prawdopodobieństwo (\\(P_i\\)) 1 2, 2 2 1/16 2 2, 3 2.5 1/16 3 2, 4 3 1/16 4 2, 5 3.5 1/16 5 3, 2 2.5 1/16 6 3, 3 3 1/16 7 3, 4 3.5 1/16 8 3, 5 4 1/16 9 4, 2 3 1/16 10 4, 3 3.5 1/16 11 4, 4 4 1/16 12 4, 5 4.5 1/16 13 5, 2 3.5 1/16 14 5, 3 4 1/16 15 5, 4 4.5 1/16 16 5, 5 5 1/16 Sum - - 1 Nie wszystkie wartości średniej z próby występują z równym prawdopodobieństwem, ponieważ niektóre wartości występują więcej niż raz spośród 16 możliwych próbek. Na przykład średnia próbka wynosząca 3,5 pojawia się wśród 4 z 16 możliwości i ma prawdopodobieństwo 4⁄16. W tabeli 6.3 przedstawiono rozkład losowania średniej dla prób o wielkości n = 2 z miniaturowej populacji N = 4. Table 6.3. Rozkład średniej z 2-elementowej próby (sampling distribution of the mean) i Średnia w próbie (\\(\\bar{x}\\)) Prawdopodobieństwo (\\(p_i\\)) 1 5 1/16 2 4.5 2/16 3 4 3/16 4 3.5 4/16 5 3 3/16 6 2.5 2/16 7 2 1/16 Sum - 1 Figure 6.2 przedstawia metodę konstrukcji rozkładu średniej z próby na przykładzie populacji liczącej 4 elementy {2, 3, 4, 5}. Figure 6.2. Rozkład średniej z próby dla próby 2-elementowej; f oznacza częstość bezwzględną 6.2.2 Rozkład z próby dla sumy zmiennych losowych (\\(S\\)) (Sampling distribution for a sample sum) Przeprowadźmy eksperyment polegający na rzucie dwiema sześciennymi kostkami do gry. Zdefiniujmy zmienną = suma oczek, które wypadły przy rzucie dwiema kostkami do gry. Rozkład prawdopodobieństwa zmiennej, która może przyjąć 6 wartości z identycznym prawdopodobieństwem jest rozkładem jednostajnym (rzut pojedynczą kostką sześcienną). Jaki będzie rozkład prawdopodobieństwa dla sumy oczek (lub średniej arytmetycznej wyniku) przy rzucie dwiema kostkami? W tabeli 6.4 przedstawiono wszystkie możliwe kombinacje wyników, czyli przestrzeń zdarzeń elementarnych: Table 6.4. Przestrzeń zdarzeń elementarnych dla sumy liczby oczek w doświadczeniu rzutu dwiema uczciwymi kośćmi (Sample space for the sum of outcomes in flipping two fair dice) Pierwsza kość (X1) Druga kość (X2) 1 2 3 4 5 6 1 S = 2 3 4 5 6 7 2 3 4 5 6 7 8 3 4 5 6 4 + 3 = 7 8 9 4 5 6 3 + 4 = 7 8 9 10 5 6 7 8 9 10 11 6 7 8 9 10 11 6+6 = 12 Rysunek 6.2 przedstawia rozkład prawdopodobieństwa sumy S z próby dwuelementowej (suma wyników dwóch rzutów sześciościenną kością), który kształtem przypomina rozkład normalny. Rozkład prawdopodobieństwa do gry (rozkład zmiennej \\(X_1\\)) był , ale przy rzucie dwiema (\\(X_1+X_2\\)) lub tym bardziej, co można pokazać, większą liczbą kostek, rozkład prawdopodobieństwa sumy wyników (\\(S = X_1+X_2+ ... +X_n\\)), lub wartości przeciętnej wyników (\\(\\overline{X}\\)) wraz z wzrostem liczby kostek (lub liczby rzutów kostką), coraz bardziej przypomina rozkład normalny. Figure 6.2. Rozkład z próby dla zmiennej losowej S = suma oczek uzyskanych przy rzucie dwiema kośćmi (Sampling distribution for the random variable S = sum of outcomes in flipping two fair dice (Source: Wikipedia.org)) "],["centralne-twierdzenie-graniczne-ctg-central-limit-theorem.html", "6.3 Centralne twierdzenie graniczne, CTG (Central Limit Theorem)", " 6.3 Centralne twierdzenie graniczne, CTG (Central Limit Theorem) Centralne twierdzenie graniczne (CTG) stwierdza, że rozkład średniej z próby (także sumy S oraz proporcji p z próby) dowolnej niezależnej zmiennej losowej będzie normalny lub prawie normalny, jeśli wielkość próby jest wystarczająco duża. „Centralne twierdzenie graniczne (CTG) jest prawdopodobnie najbardziej znanym twierdzeniem statystycznym, jest szeroko stosowane w każdej dziedzinie, która chce coś wywnioskować lub przewidzieć na podstawie zebranych danych. Pierwsza (prosta) wersja twierdzenia została wprowadzona w osiemnastym wieku, najpierw przez de Moivre, …”. - Javier Rodríguez Chatruc, Federico Carrone (czytaj więcej tutaj: https://lambdaclass.com/data_etudes/central_limit_theorem_misuse/) Centralne twierdzenie graniczne (CTG) stwierdza, że w wielu sytuacjach, gdy dodaje się niezależne zmienne losowe, ich odpowiednio znormalizowana suma S zmierza w kierunku rozkładu normalnego (nieformalnie krzywej dzwonowej), nawet jeśli same pierwotne zmienne nie mają rozkładu normalnego. Twierdzenie to jest kluczowym pojęciem w teorii prawdopodobieństwa, ponieważ sugeruje, że metody probabilistyczne i statystyczne, które działają dla rozkładów normalnych, mogą być stosowane do wielu problemów związanych z innymi typami rozkładów. Centralne twierdzenie graniczne stwierdza, że gdy nieskończona liczba kolejnych losowych próbek jest pobierana z populacji, rozkład średnich z tych próbek będzie w przybliżeniu normalny ze średnią \\(\\mu\\) i wariancją \\(\\sigma^2 / n\\); przybliżenie staje się coraz lepsze wraz z wzrostem wielkości próby (n), niezależnie od kształtu rozkładu populacji. Z CTG wynika, że zmienna losowa \\(\\Sigma X = X_1 + X_2 + ... + X_n\\), przy czym niech \\(X_i\\) będą niezależne i niech mają taki sam rozkład (tj. są i.i.d.), dla dostatecznie dużego n, ma w przybliżeniu rozkład normalny. W praktyce podobieństwo rozkładów sum zmiennych losowych obserwuje się zwykle, gdy n jest równe co najmniej 30. Zauważ, że dowolny ciąg zmiennych losowych \\(X_1, X_2, ..., X_n\\) można utożsamić z n-elementową próbą losową, gdzie \\(x_1, x_2, ... x_n\\) są realizacjami losowej próby (obserwacjami). Np. \\(x_2\\) może oznaczać respondenta nr 2, którego zapytano o to, czy popiera partię A lub np. zbadano jaki jest jego poziom IQ, itp. 6.3.0.1 Centralne twierdzenie graniczne dla estymatora średniej z próby Niech \\(X_1, X_2, ..., X_n\\) będzie ciągiem niezależnych zmiennych losowych o dowolnym rozkładzie, i.i.d, z wartością oczekiwaną \\(E(X_i) = \\mu\\) oraz z wariancją \\(Var(X_i) = \\sigma^2\\). Wtedy, dla dostatecznie dużego \\(n\\), \\[\\frac{\\sum_{i=1}^{n} X_i}{n} = \\overline{X} \\sim N(\\mu, \\frac{\\sigma^2}{\\sqrt{n}}) \\text{ oraz }\\] \\[\\frac{\\sum_{i=1}^{n} X_i - n\\mu}{\\sigma\\sqrt{n}} = \\frac{\\overline{X} - \\mu}{\\sigma/ \\sqrt{n}}\\longrightarrow Z, \\text{gdzie } Z\\sim N(0, 1)\\] Z CTG wynika, że dla prostej próby losowej \\(X_1, X_2, ..., X_n\\) z populacji o wartości oczekiwanej \\(\\mu\\) i odchyleniu standardowym \\(\\sigma\\), gdy n rośnie w nieskończoność, rozkład średniej \\(\\overline{X}\\) z próby, wraz z wzrostem n, upodabnia się do rozkładu normalnego \\(N(\\mu, \\frac{\\sigma}{\\sqrt{n}})\\). Ponadto, \\(\\mu_{\\overline{X}} = E(\\overline{X}) = \\mu\\), oraz \\(\\sigma_{\\overline{X}} = Var(\\overline{X}) = \\frac{\\sigma}{\\sqrt{n}}\\). CTG dostarcza nam wiedzy o rozkładzie z próby estymatorów nieznanych wartości parametrów populacji (parametry to liczby charakteryzujące daną populację, np. średnia arytmetyczna ocen uczniów pewnej klasy). Ta wiedza pozwala ustalić na podstawie analizy prostej próby losowej, które wartości określonych parametrów populacji są bardziej, a które mniej prawdopodobne. Średnią z próby \\(\\overline{X}\\), częstość (frakcję) \\(\\widehat{p}\\), odchylenie standardowe z próby \\(S(X)\\) i wiele innych estymatorów nieznanych wartości parametrów danej populacji generalnej określa się często w statystyce mianem statystyk z próby. Jak wiemy z CTG, dla dostatecznie dużych n, \\(\\overline{X} \\sim N(\\mu, \\frac{\\sigma}{\\sqrt{n}})\\) 6.3.0.2 CTG dla estymatora częstości (proporcji) z próby CTG można, dla estymatora frakcji \\(\\frac{\\Sigma X_i}{n} = \\widehat{p}\\), sformułować następująco: Jeżeli \\(X_i \\sim Bern(p)\\) oraz \\(E(X_i) = p, Var(X_i) = p(1-p)\\) i \\(\\Sigma X_i \\sim Bin(n, p)\\) oraz \\(E(\\Sigma X_i) = np, Var(\\Sigma X_i) = np(1-p)\\), to ponadto, gdy \\(n \\rightarrow \\infty\\), \\[\\Sigma X_i \\sim N(\\mu = np, \\sigma = \\sqrt{np(1-p)}) \\text{ oraz }\\] \\[\\frac{\\Sigma X_i}{n} \\sim N(\\mu = p, \\sigma = \\sqrt{\\frac{p(1-p)}{n}})\\] Ponadto, dla estymatora proporcji (frakcja z próby): Niech \\(X_1, X_2, ..., X_n\\) będzie ciągiem niezależnych zmiennych losowych o rozkładzie \\(Bern(p)\\), z wartością oczekiwaną \\(E(X_i) = p\\) oraz z wariancją \\(Var(X_i) = p(1-p)\\). Wtedy, gdy \\(n \\longrightarrow \\infty\\), \\[\\frac{\\sum_{i=1}^{n} X_i - np}{\\sqrt{np(1-p)}} = \\frac{\\frac{\\sum_{i=1}^{n} X_i}{n} - p}{\\sqrt{\\frac{p(1-p)}{n}}} = \\frac{\\widehat{p} - p}{\\sqrt{\\frac{p(1-p)}{n}}}\\longrightarrow Z, \\text{gdzie } Z\\sim N(0, 1)\\] Ze szczególnej wersji CTG wynika, że dla dostatecznie dużych n, \\(\\widehat{p} \\sim N(p, \\sqrt{\\frac{p(1-p)}{n}})\\), czyli \\(E(\\widehat{p}) = p, Var(\\widehat{p}) = \\frac{p(1-p)}{n}\\) Rozkład dwumianowy możemy dobrze przybliżyć rozkładem normalnym, gdy \\(np \\geq 5\\) i \\(nq \\geq 5\\) "],["estymacja-punktowa-i-przedziałowa.html", "6.4 Estymacja punktowa i przedziałowa", " 6.4 Estymacja punktowa i przedziałowa W próbie liczącej 985 wyborców, 592 zamierza głosować na kandydata Republikanów w najbliższych wyborach. Zbuduj 95% przedział ufności dla frakcji (proporcji) p wyborców deklarujących poparcie dla kandydata Republikanów. Podaj interpretację przedziału ufności. Rozwiązanie: Tzw. punktowym estymatorem frakcji jest oczywiście \\(\\hat{p} = \\frac{X}{n} = \\frac{592}{985} = 0.601\\) Odchylenie standardowe estymatora zwane błędem standardowym (\\(\\sigma_{\\hat{p}}\\)) obliczamy stosując znane wyrażenie \\(\\sqrt{\\frac{p(1-p)}{n}} = 0.016\\). W celu ustalenia tzw. 95% przedziału ufności dla proporcji p wygodnie jest posłużyć się zmienną standaryzowaną Z. Przyjmując tzw. poziom zaufania (ufności) 95%, można powiedzieć, że 95% przedziałów ufności, wygenerowanych na podstawie dowolnie dużej liczby prób reprezentatywnych wybranych z danej populacji, pokryje nieznaną wartość parametru populacji. Dla zmiennej standaryzowanej \\(Z\\sim N(0, 1)\\), 95% wszystkich obserwacji znajduje się w przedziale \\([-1.96 &lt; Z &lt; 1.96]\\). Wartości 1.96 można odczytać z tablic rozkładu normalnego szukając wartość zmiennej Z dla prawdopodobieństwa 0.975 = 97.5%. Dlaczego dla wartości 0.975? Otóż \\(1 - 0.95 = 0.05\\). Tę wartość dzielimy przez 2 i wówczas otrzymujemy 0.25 (0.25 na lewym krańcu rozkładu normalnego i 0.25 na prawym krańcu daje nam w sumie 0.05). Ostatecznie mamy \\(1 - 0.25 = 0.975\\). Te działania są niezbędne, żeby prawidłowo odczytać z tablic wartości zmiennej Z, które wyznaczą 95% przedział ufności. Ściślej, przedział ufności to taki przedział, że \\[P(- z_{\\alpha/2} &lt; Z &lt; z_{\\alpha/2}) = P(- z_{\\alpha/2} &lt; \\frac{\\hat{p} - \\mu_{\\hat{p}}}{\\sigma_{\\hat{p}}} = \\frac{\\hat{p} - p}{\\sqrt{ \\frac{p(1-p)}{n} }} &lt; z_{\\alpha/2}) = 1 - \\alpha\\] Po przekształceniach (wyprowadzamy p z nierówności) otrzymamy: \\[P(\\hat{p} - z_{\\alpha/2} \\sqrt{ \\frac{p(1-p)}{n} } &lt; p &lt; \\hat{p} + z_{\\alpha/2} \\sqrt{ \\frac{p(1-p)}{n} } ) = 1 - \\alpha\\] Dla 95% przedziału ufności współczynnik \\(\\alpha\\) - tzw. poziom istotności - jest równy 0.05, a \\(z_{\\alpha/2} = 1.96\\) Korzystając z wprowadzonych wzorów wyznaczamy przedział ufności dla proporcji p: \\[P( 0.601 - 1.96\\sqrt{\\frac{0.601(1-0.601)}{985}} &lt; p &lt; 0.601 + 1.96\\sqrt{\\frac{0.601(1-0.601)}{985}} ) = 0.95\\] \\[P( 0.601 - 0.0306 &lt; p &lt; 0.601 + 0.0306 ) = 0.95\\] Ponieważ nie znamy prawdziwej wartości proporcji p, zastępujemy wartość p jej oszacowaniem z próby. Piszemy, że dla 95% przedziału ufności: \\[\\hat{p} \\pm 1.96\\sqrt{ \\frac{p(1-p)}{n}}\\] \\[0.601 \\pm 0.0306\\] Wartość 0.0306 nazywamy marginesem błędu lub błędem statystycznym. Otrzymujemy ostatecznie, że p pokrywa przedział ufności \\(0.5704, 0.6316\\). Odpowiedź: Możemy powiedzieć, że, z prawdopodobieństwem 0.95, przedziałów ufności \\(0.5704, 0.6316\\) pokryje nieznaną wartość parametru proporcji poparcia wyborczego dla kandydata Republikanów. "]]
